{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"6u_j73SUfQxG","pycharm":{"name":"#%% md\n"}},"source":["## Physics Informed Neural Networks to Approximate Solution of PDEs"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16589,"status":"ok","timestamp":1686504186098,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"S41Q3MRbgNMB","outputId":"9284df0a-d475-463b-8fc3-1c9626fb7e7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1686506269155,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"NOPdRWmOfQxI","outputId":"84078558-b80b-4731-a344-5b9d1e7bc087","pycharm":{"name":"#%%\n"}},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x121770d50>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.optim as optim\n","import torch\n","from torch.utils.data import DataLoader\n","import sys\n","sys.path.append('/Users/timostroschein/Desktop/Deep Learning/DLSC')\n","from Common import NeuralNet, MultiVariatePoly\n","#from drive.MyDrive.DLSC.Common import NeuralNet, MultiVariatePoly\n","import time\n","import pandas as pd\n","torch.autograd.set_detect_anomaly(True)\n","torch.manual_seed(128)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686504191062,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"qXlo3aTTEA2E"},"outputs":[],"source":["dev = 'cpu' #'mps'  or 'cuda:0'\n","\n","device =torch.device(dev)\n","torch.set_default_device(dev)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":36902,"status":"ok","timestamp":1686504383933,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"31lkDZ3-fghR","outputId":"de1041f2-e4f4-4d94-a2b7-33bd18008d46"},"outputs":[{"ename":"NameError","evalue":"name 'files' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m uploaded \u001b[39m=\u001b[39m files\u001b[39m.\u001b[39mupload()\n","\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"]}],"source":["uploaded = files.upload() "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":270,"status":"ok","timestamp":1686508226331,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"jfw5Xm7bDyD0"},"outputs":[],"source":["alpha_f = 0.05; alpha_s= 0.08 ;h_f =5 ;h_s = 6 ; T_hot = 4; T0 = 1;  U_f =1\n","\n","#Hyperparams\n","Lambda = 1; Hidden_layers=4; Neurons=20; \n","\n","#Training optimizer\n","Adam_opt = False; n_epochs_A = 10\n","LBFGS_opt = True; n_epochs_L = 2"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1686508226871,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"HgRzd8_wfQxK","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["class Pinns:\n","    def __init__(self, n_int_, n_sb_, n_tb_):\n","        self.n_int = n_int_\n","        self.n_sb = n_sb_\n","        self.n_tb = n_tb_\n","        self.Final_loss = None;\n","\n","        # Extrema of the solution domain (t,x) in [0,0.1]x[-1,1]\n","        self.domain_extrema = torch.tensor([[0, 1],  # Time dimension\n","                                            [0, 1]])  # Space dimension\n","\n","        # Number of space dimensions\n","        self.space_dimensions = 1\n","\n","        # Parameter to balance role of data and PDE\n","        self.lambda_u = Lambda\n","\n","        # F Dense NN to approximate the solution of the underlying heat equation\n","        self.approximate_solution = NeuralNet(input_dimension=self.domain_extrema.shape[0], output_dimension=2,\n","                                              n_hidden_layers=Hidden_layers,\n","                                              neurons=Neurons,\n","                                              regularization_param=0.,\n","                                              regularization_exp=2.,\n","                                              retrain_seed=42)\n","        '''self.approximate_solution = MultiVariatePoly(self.domain_extrema.shape[0], 3)'''\n","\n","        # Generator of Sobol sequences\n","        self.soboleng = torch.quasirandom.SobolEngine(dimension=self.domain_extrema.shape[0])\n","\n","        # Training sets S_sb, S_tb, S_int as torch dataloader\n","        self.training_set_sb, self.training_set_tb, self.training_set_int = self.assemble_datasets()\n","\n","    ################################################################################################\n","    # Function to linearly transform a tensor whose value are between 0 and 1\n","    # to a tensor whose values are between the domain extrema\n","    def convert(self, tens):\n","        assert (tens.shape[1] == self.domain_extrema.shape[0])\n","        tens = tens.to(device)\n","        return tens * (self.domain_extrema[:, 1] - self.domain_extrema[:, 0]) + self.domain_extrema[:, 0]\n","\n","    # Initial condition to solve the heat equation u0(x)=-sin(pi x)\n","    def initial_condition(self, batch_size):\n","        return torch.full((batch_size,2), T0) #torch.full((self.n_tb,2), T0) \n","\n","    ################################################################################################\n","    # Function returning the input-output tensor required to assemble the training set S_tb corresponding to the temporal boundary\n","    def add_temporal_boundary_points(self):\n","        t0 = self.domain_extrema[0, 0]\n","        input_tb = self.convert(self.soboleng.draw(self.n_tb))\n","        input_tb[:, 0] = torch.full(input_tb[:, 0].shape, t0)\n","        output_tb = self.initial_condition(self.n_tb)\n","\n","        return input_tb, output_tb\n","    \n","    def boundary_x0_for_Tf(self, t):\n","        return ((T_hot-T0)/(1+ torch.exp(-200* (t -0.25))) + T0).view(-1,1)  \n","    \n","    # Function returning the input-output tensor required to assemble the training set S_sb corresponding to the spatial boundary\n","    def add_spatial_boundary_points(self):\n","        x0 = self.domain_extrema[1, 0]\n","        xL = self.domain_extrema[1, 1]\n","\n","        input_sb = self.convert(self.soboleng.draw(self.n_sb))\n","\n","        input_sb_0 = torch.clone(input_sb)\n","        input_sb_0[:, 1] = torch.full(input_sb_0[:, 1].shape, x0)\n","\n","        input_sb_L = torch.clone(input_sb)\n","        input_sb_L[:, 1] = torch.full(input_sb_L[:, 1].shape, xL)\n","        \n","        Tf_sb_0 = self.boundary_x0_for_Tf(input_sb_0[:,0])\n","        \n","        output_sb_0 = torch.cat([ Tf_sb_0,torch.zeros((input_sb.shape[0], 1))], 1)\n","        output_sb_L = torch.zeros((input_sb.shape[0], 2))\n","\n","        return torch.cat([input_sb_0, input_sb_L], 0), torch.cat([output_sb_0, output_sb_L], 0)\n","\n","    #  Function returning the input-output tensor required to assemble the training set S_int corresponding to the interior domain where the PDE is enforced\n","    def add_interior_points(self):\n","        input_int = self.convert(self.soboleng.draw(self.n_int))\n","        output_int = torch.zeros((input_int.shape[0], 2))\n","        return input_int, output_int\n","\n","    # Function returning the training sets S_sb, S_tb, S_int as dataloader\n","    def assemble_datasets(self):\n","        input_sb, output_sb = self.add_spatial_boundary_points()   # S_sb\n","        input_tb, output_tb = self.add_temporal_boundary_points()  # S_tb\n","        input_int, output_int = self.add_interior_points()         # S_int\n","\n","        training_set_sb = DataLoader(torch.utils.data.TensorDataset(input_sb, output_sb), batch_size=2*self.space_dimensions*self.n_sb, shuffle=False)\n","        training_set_tb = DataLoader(torch.utils.data.TensorDataset(input_tb, output_tb), batch_size=self.n_tb, shuffle=False)\n","        training_set_int = DataLoader(torch.utils.data.TensorDataset(input_int, output_int), batch_size=self.n_int, shuffle=False)\n","\n","        return training_set_sb, training_set_tb, training_set_int\n","\n","    ################################################################################################\n","    # Function to compute the terms required in the definition of the TEMPORAL boundary residual\n","    def apply_initial_condition(self, input_tb):\n","        u_pred_tb = self.approximate_solution(input_tb)\n","        return u_pred_tb\n","\n","    # Function to compute the terms required in the definition of the SPATIAL boundary residual\n","    def apply_boundary_conditions(self, input_sb):\n","        l = int(input_sb.shape[0]/2) \n","        \n","        input_sb.requires_grad = True\n","        u_pred_sb = self.approximate_solution(input_sb)\n","        \n","        Tf=u_pred_sb[:,0].view(-1,1)\n","        Ts=u_pred_sb[:,1].view(-1,1)\n","        \n","        grad_Ts= torch.autograd.grad(Ts.sum(), input_sb, create_graph=True)[0]\n","        grad_Ts_x = grad_Ts[:, 1].view(-1,1)\n","        \n","        l = int(input_sb.shape[0]/2)\n","        grad_Tf= torch.autograd.grad(Tf.sum(), input_sb, create_graph=True)[0]\n","        grad_Tf_x = grad_Tf[l:, 1].view(-1,1)\n","        \n","        boundary_0 = torch.cat([Tf[:l].view(-1,1),grad_Tf_x[:l]],1)\n","        boundary_L = torch.cat([grad_Tf_x,grad_Ts_x[l:]],1 )\n","        \n","        boundary_points = torch.cat([boundary_0,boundary_L],0)\n","        \n","        return boundary_points\n","\n","    # Function to compute the PDE residuals\n","    def compute_pde_residual(self, input_int):\n","        input_int.requires_grad = True\n","        u = self.approximate_solution(input_int)\n","        \n","        Tf=u[:,0].view(-1,1)\n","        Ts=u[:,1].view(-1,1)\n","        \n","        grad_Tf = torch.autograd.grad(Tf.sum(), input_int, create_graph=True)[0]\n","        grad_Tf_t = grad_Tf[:, 0].view(-1,1) #t in 0 coloumn \n","        grad_Tf_x = grad_Tf[:, 1].view(-1,1)\n","    \n","        grad_Tf_xx = torch.autograd.grad(grad_Tf_x.sum(), input_int, create_graph=True)[0][:, 1].view(-1,1)\n","        \n","        grad_Ts = torch.autograd.grad(Ts.sum(), input_int, create_graph=True)[0]\n","        grad_Ts_t = grad_Ts[:, 0].view(-1,1)  #t in 0 coloumn \n","        grad_Ts_x = grad_Ts[:, 1].view(-1,1)\n","        grad_Ts_xx = torch.autograd.grad(grad_Ts_x.sum(), input_int, create_graph=True)[0][:, 1].view(-1,1)\n","        \n","        residual_1 = grad_Tf_t + U_f * grad_Tf_x - alpha_f * grad_Tf_xx + h_f * ( Tf- Ts)\n","        residual_2 = grad_Ts_t - alpha_s * grad_Ts_xx - h_s * (Tf - Ts)\n","        residual = torch.cat( [residual_1 , residual_2],0)\n","        \n","        return residual.reshape(-1, )\n","\n","    # Function to compute the total loss (weighted sum of spatial boundary loss, temporal boundary loss and interior loss)\n","    def compute_loss(self, inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=True):\n","        u_pred_sb = self.apply_boundary_conditions(inp_train_sb)\n","        u_pred_tb = self.apply_initial_condition(inp_train_tb)\n","\n","        \n","        assert (u_pred_sb.shape[1] == u_train_sb.shape[1])\n","        assert (u_pred_tb.shape[1] == u_train_tb.shape[1])\n","\n","\n","        r_int = self.compute_pde_residual(inp_train_int)\n","        r_sb = u_train_sb - u_pred_sb\n","        r_tb = u_train_tb - u_pred_tb\n","\n","        loss_sb = torch.mean(abs(r_sb) ** 2)\n","        loss_tb = torch.mean(abs(r_tb) ** 2)\n","        loss_int = torch.mean(abs(r_int) ** 2)\n","\n","        loss_u = loss_sb + loss_tb\n","        \n","        loss = torch.log10(self.lambda_u * (loss_sb + loss_tb) + loss_int)\n","        if verbose: print(\"Total loss: \", round(loss.item(), 4), \"| PDE Loss: \", round(torch.log10(loss_u).item(), 4), \"| Function Loss: \", round(torch.log10(loss_int).item(), 4))\n","\n","        return loss\n","\n","    ################################################################################################\n","    def fit(self, num_epochs, optimizer, verbose=True):\n","        history = list()\n","\n","        # Loop over epochs\n","        for epoch in range(num_epochs):\n","            if verbose: print(\"################################ \", epoch, \" ################################\")\n","\n","            for j, ((inp_train_sb, u_train_sb), (inp_train_tb, u_train_tb), (inp_train_int, u_train_int)) in enumerate(zip(self.training_set_sb, self.training_set_tb, self.training_set_int)):\n","                def closure():\n","                    optimizer.zero_grad()\n","                    loss = self.compute_loss(inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=verbose)\n","                    loss.backward()\n","\n","                    history.append(loss.item())\n","                    return loss\n","\n","                optimizer.step(closure=closure)\n","\n","        print('Final Loss: ', history[-1])\n","        self.Final_loss = round(history[-1],4)\n","        return history\n","\n","    ################################################################################################\n","    def plotting(self):\n","        inputs = self.soboleng.draw(100000)\n","        inputs = self.convert(inputs)\n","\n","        outputs = self.approximate_solution(inputs)\n","\n","        outputs= outputs.to(\"cpu\")\n","        inputs= inputs.to(\"cpu\")\n","        \n","        output = outputs[:,1].reshape(-1, )\n","        exact_output = outputs[:,0].reshape(-1, )\n","        print(output.shape)\n","        \n","        # output= output.to(\"cpu\")\n","        # exact_output = exact_output.to(\"cpu\")\n","        # inputs = inputs.to(\"cpu\")\n","        \n","        fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n","        im1 = axs[0].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=exact_output.detach(), cmap=\"jet\")\n","        axs[0].set_xlabel(\"x\")\n","        axs[0].set_ylabel(\"t\")\n","        plt.colorbar(im1, ax=axs[0])\n","        axs[0].grid(True, which=\"both\", ls=\":\")\n","        im2 = axs[1].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=output.detach(), cmap=\"jet\")\n","        axs[1].set_xlabel(\"x\")\n","        axs[1].set_ylabel(\"t\")\n","        plt.colorbar(im2, ax=axs[1])\n","        axs[1].grid(True, which=\"both\", ls=\":\")\n","        axs[0].set_title(\"Approximate Tf solution\")\n","        axs[1].set_title(\"Approximate Ts solution\")\n","\n","\n","        plt.savefig(f'Data/Task_1_Regularizer_{Lambda}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{self.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.jpg')\n","        #files.download(f'Task_1_Regularizer_{Lambda}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{self.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.jpg')\n","        plt.show()\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1686508227543,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"M3ug4ztBfQxM","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["n_int = 256\n","n_sb = 64\n","n_tb = 64\n","\n","pinn = Pinns(n_int, n_sb, n_tb)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":713293,"status":"ok","timestamp":1686508941142,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"qub-M5jqfQxN","outputId":"2c3b805f-0ced-4681-e134-11fb19c4ac04","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["################################  0  ################################\n"]},{"name":"stderr","output_type":"stream","text":["/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/utils/_device.py:62: UserWarning: The operator 'aten::random_' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343668887/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n","  return func(*args, **kwargs)\n","/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/autograd/__init__.py:303: UserWarning: Error detected in torch::autograd::NotImplemented. Traceback of forward call that caused the error:\n"," (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343668887/work/torch/csrc/autograd/python_anomaly_mode.cpp:119.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/autograd/__init__.py:303: UserWarning: \n","\n","Previous calculation was induced by LinearBackward0. Traceback of forward call that induced the previous calculation:\n","  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n","    app.launch_new_instance()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n","    self.io_loop.start()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n","    self._run_once()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n","    handle._run()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n","    await self.process_one()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n","    await dispatch(*args)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n","    await result\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n","    reply_content = await reply_content\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n","    res = shell.run_cell(\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n","    result = self._run_cell(\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n","    result = runner(coro)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n","    if await self.run_code(code, result, async_=asy):\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/var/folders/wc/3dh9xbxn14ngxgbwmbg14dkm0000gn/T/ipykernel_66884/613044914.py\", line 28, in <module>\n","    hist_L = pinn.fit(num_epochs=n_epochs_L,\n","  File \"/var/folders/wc/3dh9xbxn14ngxgbwmbg14dkm0000gn/T/ipykernel_66884/404681127.py\", line 193, in fit\n","    optimizer.step(closure=closure)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n","    out = func(*args, **kwargs)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/optim/lbfgs.py\", line 312, in step\n","    orig_loss = closure()\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/var/folders/wc/3dh9xbxn14ngxgbwmbg14dkm0000gn/T/ipykernel_66884/404681127.py\", line 187, in closure\n","    loss = self.compute_loss(inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=verbose)\n","  File \"/var/folders/wc/3dh9xbxn14ngxgbwmbg14dkm0000gn/T/ipykernel_66884/404681127.py\", line 161, in compute_loss\n","    r_int = self.compute_pde_residual(inp_train_int)\n","  File \"/var/folders/wc/3dh9xbxn14ngxgbwmbg14dkm0000gn/T/ipykernel_66884/404681127.py\", line 129, in compute_pde_residual\n","    u = self.approximate_solution(input_int)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/timostroschein/Desktop/Deep Learning/DLSC/Common.py\", line 38, in forward\n","    x = self.activation(self.input_layer(x))\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n","    return F.linear(input, self.weight, self.bias)\n","  File \"/Users/timostroschein/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/utils/_device.py\", line 62, in __torch_function__\n","    return func(*args, **kwargs)\n"," (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343668887/work/torch/csrc/autograd/python_anomaly_mode.cpp:127.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"]},{"ename":"RuntimeError","evalue":"derivative for aten::linear_backward is not implemented","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     plot_hist(hist_A)\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m LBFGS_opt: \n\u001b[0;32m---> 28\u001b[0m     hist_L \u001b[39m=\u001b[39m pinn\u001b[39m.\u001b[39mfit(num_epochs\u001b[39m=\u001b[39mn_epochs_L,\n\u001b[1;32m     29\u001b[0m                     optimizer\u001b[39m=\u001b[39moptimizer_LBFGS,\n\u001b[1;32m     30\u001b[0m                     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m     plot_hist(hist_L)\n\u001b[1;32m     34\u001b[0m pinn\u001b[39m.\u001b[39mplotting()\n","Cell \u001b[0;32mIn[6], line 193\u001b[0m, in \u001b[0;36mPinns.fit\u001b[0;34m(self, num_epochs, optimizer, verbose)\u001b[0m\n\u001b[1;32m    190\u001b[0m             history\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m    191\u001b[0m             \u001b[39mreturn\u001b[39;00m loss\n\u001b[0;32m--> 193\u001b[0m         optimizer\u001b[39m.\u001b[39mstep(closure\u001b[39m=\u001b[39mclosure)\n\u001b[1;32m    195\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFinal Loss: \u001b[39m\u001b[39m'\u001b[39m, history[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFinal_loss \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(history[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\u001b[39m4\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/optim/lbfgs.py:312\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    309\u001b[0m state\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mn_iter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[39m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m orig_loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    313\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(orig_loss)\n\u001b[1;32m    314\u001b[0m current_evals \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","Cell \u001b[0;32mIn[6], line 187\u001b[0m, in \u001b[0;36mPinns.fit.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m():\n\u001b[1;32m    186\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 187\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m    188\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    190\u001b[0m     history\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n","Cell \u001b[0;32mIn[6], line 161\u001b[0m, in \u001b[0;36mPinns.compute_loss\u001b[0;34m(self, inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39massert\u001b[39;00m (u_pred_sb\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m u_train_sb\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m    158\u001b[0m \u001b[39massert\u001b[39;00m (u_pred_tb\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m u_train_tb\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 161\u001b[0m r_int \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_pde_residual(inp_train_int)\n\u001b[1;32m    162\u001b[0m r_sb \u001b[39m=\u001b[39m u_train_sb \u001b[39m-\u001b[39m u_pred_sb\n\u001b[1;32m    163\u001b[0m r_tb \u001b[39m=\u001b[39m u_train_tb \u001b[39m-\u001b[39m u_pred_tb\n","Cell \u001b[0;32mIn[6], line 138\u001b[0m, in \u001b[0;36mPinns.compute_pde_residual\u001b[0;34m(self, input_int)\u001b[0m\n\u001b[1;32m    135\u001b[0m grad_Tf_t \u001b[39m=\u001b[39m grad_Tf[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39m#t in 0 coloumn \u001b[39;00m\n\u001b[1;32m    136\u001b[0m grad_Tf_x \u001b[39m=\u001b[39m grad_Tf[:, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 138\u001b[0m grad_Tf_xx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(grad_Tf_x\u001b[39m.\u001b[39msum(), input_int, create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m][:, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m    140\u001b[0m grad_Ts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(Ts\u001b[39m.\u001b[39msum(), input_int, create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    141\u001b[0m grad_Ts_t \u001b[39m=\u001b[39m grad_Ts[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)  \u001b[39m#t in 0 coloumn \u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/autograd/__init__.py:269\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    267\u001b[0m overridable_args \u001b[39m=\u001b[39m t_outputs \u001b[39m+\u001b[39m t_inputs\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(overridable_args):\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    270\u001b[0m         grad,\n\u001b[1;32m    271\u001b[0m         overridable_args,\n\u001b[1;32m    272\u001b[0m         t_outputs,\n\u001b[1;32m    273\u001b[0m         t_inputs,\n\u001b[1;32m    274\u001b[0m         grad_outputs\u001b[39m=\u001b[39mgrad_outputs,\n\u001b[1;32m    275\u001b[0m         retain_graph\u001b[39m=\u001b[39mretain_graph,\n\u001b[1;32m    276\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    277\u001b[0m         only_inputs\u001b[39m=\u001b[39monly_inputs,\n\u001b[1;32m    278\u001b[0m         allow_unused\u001b[39m=\u001b[39mallow_unused,\n\u001b[1;32m    279\u001b[0m         is_grads_batched\u001b[39m=\u001b[39mis_grads_batched,\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m only_inputs:\n\u001b[1;32m    283\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39monly_inputs argument is deprecated and is ignored now \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m(defaults to True). To accumulate gradient for other \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mparts of the graph, please use torch.autograd.backward.\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[39mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1531\u001b[0m     \u001b[39m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m     \u001b[39m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m     \u001b[39mwith\u001b[39;00m _pop_mode_temporarily() \u001b[39mas\u001b[39;00m mode:\n\u001b[0;32m-> 1534\u001b[0m         result \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39m__torch_function__(public_api, types, args, kwargs)\n\u001b[1;32m   1535\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1536\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/envs/deep_learning_env/lib/python3.11/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[1;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n","\u001b[0;31mRuntimeError\u001b[0m: derivative for aten::linear_backward is not implemented"]}],"source":["def plot_hist(hist):\n","    plt.figure(dpi=150)\n","    plt.grid(True, which=\"both\", ls=\":\")\n","    plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n","    plt.xscale(\"log\")\n","    plt.legend()\n","\n","\n","optimizer_LBFGS = optim.LBFGS(pinn.approximate_solution.parameters(),\n","                              lr=float(0.5),\n","                              max_iter=50000,\n","                              max_eval=50000,\n","                              history_size=150,\n","                              line_search_fn=\"strong_wolfe\",\n","                              tolerance_change=1.0 * np.finfo(float).eps)\n","optimizer_ADAM = optim.Adam(pinn.approximate_solution.parameters(),\n","                            lr=float(0.001))\n","\n","\n","if Adam_opt:\n","\n","    hist_A = pinn.fit(num_epochs=n_epochs_A,\n","                    optimizer=optimizer_ADAM,\n","                    verbose=True)\n","    plot_hist(hist_A)\n","\n","if LBFGS_opt: \n","    hist_L = pinn.fit(num_epochs=n_epochs_L,\n","                    optimizer=optimizer_LBFGS,\n","                    verbose=True)\n","\n","    plot_hist(hist_L)\n","\n","pinn.plotting()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1686508941142,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"0wDSkgxEDyD3","outputId":"0d242ad0-741f-449f-91b0-0ab1f5637be5"},"outputs":[],"source":["\n","df = pd.read_csv('TestingData.txt')\n","testing_points = torch.tensor(df[['t', 'x']].values, dtype=torch.float)\n","\n","output_data= pinn.approximate_solution(testing_points).to('cpu')\n","testing_points= testing_points.to('cpu')\n","\n","output_f_np = output_data[:,0].detach().numpy()\n","output_s_np = output_data[:,1].detach().numpy()\n","\n","test_df = pd.DataFrame({'t': testing_points[:,0],'x': testing_points[:,1], 'tf': output_f_np, 'ts': output_s_np})\n","test_df.to_csv(f'Data/Task_1_Regularizer_{Lambda}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{pinn.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.txt',index=False) #save to file\n","#files.download(f'Task_1_Regularizer_{Lambda}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{pinn.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.txt')\n"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686508941142,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"UIxcd17jfw13"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
