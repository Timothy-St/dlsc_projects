{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u_j73SUfQxG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Physics Informed Neural Networks to Approximate Solution of PDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15986,
     "status": "ok",
     "timestamp": 1686497193704,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "S41Q3MRbgNMB",
    "outputId": "d9375607-8979-48c4-b442-10726b9085d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1495,
     "status": "ok",
     "timestamp": 1686497426250,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "NOPdRWmOfQxI",
    "outputId": "c247d3da-0795-47d1-8b6a-cc1225276a05",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f58a2fe8eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# import sys \n",
    "# sys.path.append('/Users/timostroschein/Desktop/Deep Learning/DLSC')\n",
    "from drive.MyDrive.DLSC.Common import NeuralNet, MultiVariatePoly\n",
    "import time\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1686497435954,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "qXlo3aTTEA2E"
   },
   "outputs": [],
   "source": [
    "device =torch.device('cuda:0')\n",
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1686497445369,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "jfw5Xm7bDyD0"
   },
   "outputs": [],
   "source": [
    "alpha_f = 0.05; alpha_s= 0.08 ;h_f =5 ;h_s = 6 ; T_hot = 4; T0 = 1;  U_f =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1686499612199,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "HgRzd8_wfQxK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Pinns:\n",
    "    def __init__(self, n_int_, n_sb_, n_tb_):\n",
    "        self.n_int = n_int_\n",
    "        self.n_sb = n_sb_\n",
    "        self.n_tb = n_tb_\n",
    "\n",
    "        # Extrema of the solution domain (t,x) in [0,0.1]x[-1,1]\n",
    "        self.domain_extrema = torch.tensor([[0, 1],  # Time dimension\n",
    "                                            [0, 1]])  # Space dimension\n",
    "\n",
    "        # Number of space dimensions\n",
    "        self.space_dimensions = 1\n",
    "\n",
    "        # Parameter to balance role of data and PDE\n",
    "        self.lambda_u = 1\n",
    "\n",
    "        # F Dense NN to approximate the solution of the underlying heat equation\n",
    "        self.approximate_solution = NeuralNet(input_dimension=self.domain_extrema.shape[0], output_dimension=2,\n",
    "                                              n_hidden_layers=4,\n",
    "                                              neurons=20,\n",
    "                                              regularization_param=0.,\n",
    "                                              regularization_exp=2.,\n",
    "                                              retrain_seed=42)\n",
    "        '''self.approximate_solution = MultiVariatePoly(self.domain_extrema.shape[0], 3)'''\n",
    "\n",
    "        # Generator of Sobol sequences\n",
    "        self.soboleng = torch.quasirandom.SobolEngine(dimension=self.domain_extrema.shape[0])\n",
    "\n",
    "        # Training sets S_sb, S_tb, S_int as torch dataloader\n",
    "        self.training_set_sb, self.training_set_tb, self.training_set_int = self.assemble_datasets()\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function to linearly transform a tensor whose value are between 0 and 1\n",
    "    # to a tensor whose values are between the domain extrema\n",
    "    def convert(self, tens):\n",
    "        assert (tens.shape[1] == self.domain_extrema.shape[0])\n",
    "        tens = tens.to(device)\n",
    "        return tens * (self.domain_extrema[:, 1] - self.domain_extrema[:, 0]) + self.domain_extrema[:, 0]\n",
    "\n",
    "    # Initial condition to solve the heat equation u0(x)=-sin(pi x)\n",
    "    def initial_condition(self, batch_size):\n",
    "        return torch.full((batch_size,2), T0)\n",
    "\n",
    "    # Exact solution for the heat equation ut = u_xx with the IC above\n",
    "    def exact_solution(self, inputs):\n",
    "        t = inputs[:, 0]\n",
    "        x = inputs[:, 1]\n",
    "\n",
    "        u = -torch.exp(-np.pi ** 2 * t) * torch.sin(np.pi * x)\n",
    "        return u\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function returning the input-output tensor required to assemble the training set S_tb corresponding to the temporal boundary\n",
    "    def add_temporal_boundary_points(self):\n",
    "        t0 = self.domain_extrema[0, 0]\n",
    "        input_tb = self.convert(self.soboleng.draw(self.n_tb))\n",
    "        input_tb[:, 0] = torch.full(input_tb[:, 0].shape, t0)\n",
    "        output_tb = self.initial_condition(self.n_tb)\n",
    "\n",
    "        return input_tb, output_tb\n",
    "    \n",
    "    def boundary_x0_for_Tf(self, t):\n",
    "        return ((T_hot-T0)/(1+ torch.exp(-200* (t -0.25))) + T0).view(-1,1)  \n",
    "    \n",
    "    # Function returning the input-output tensor required to assemble the training set S_sb corresponding to the spatial boundary\n",
    "    def add_spatial_boundary_points(self):\n",
    "        x0 = self.domain_extrema[1, 0]\n",
    "        xL = self.domain_extrema[1, 1]\n",
    "\n",
    "        input_sb = self.convert(self.soboleng.draw(self.n_sb))\n",
    "\n",
    "        input_sb_0 = torch.clone(input_sb)\n",
    "        input_sb_0[:, 1] = torch.full(input_sb_0[:, 1].shape, x0)\n",
    "\n",
    "        input_sb_L = torch.clone(input_sb)\n",
    "        input_sb_L[:, 1] = torch.full(input_sb_L[:, 1].shape, xL)\n",
    "        \n",
    "        Tf_sb_0 = self.boundary_x0_for_Tf(input_sb_0[:,0])\n",
    "        \n",
    "        output_sb_0 = torch.cat([ Tf_sb_0,torch.zeros((input_sb.shape[0], 1))], 1)\n",
    "        output_sb_L = torch.zeros((input_sb.shape[0], 2))\n",
    "\n",
    "        return torch.cat([input_sb_0, input_sb_L], 0), torch.cat([output_sb_0, output_sb_L], 0)\n",
    "\n",
    "    #  Function returning the input-output tensor required to assemble the training set S_int corresponding to the interior domain where the PDE is enforced\n",
    "    def add_interior_points(self):\n",
    "        input_int = self.convert(self.soboleng.draw(self.n_int))\n",
    "        output_int = torch.zeros((input_int.shape[0], 2))\n",
    "        return input_int, output_int\n",
    "\n",
    "    # Function returning the training sets S_sb, S_tb, S_int as dataloader\n",
    "    def assemble_datasets(self):\n",
    "        input_sb, output_sb = self.add_spatial_boundary_points()   # S_sb\n",
    "        input_tb, output_tb = self.add_temporal_boundary_points()  # S_tb\n",
    "        input_int, output_int = self.add_interior_points()         # S_int\n",
    "\n",
    "        training_set_sb = DataLoader(torch.utils.data.TensorDataset(input_sb, output_sb), batch_size=2*self.space_dimensions*self.n_sb, shuffle=False)\n",
    "        training_set_tb = DataLoader(torch.utils.data.TensorDataset(input_tb, output_tb), batch_size=self.n_tb, shuffle=False)\n",
    "        training_set_int = DataLoader(torch.utils.data.TensorDataset(input_int, output_int), batch_size=self.n_int, shuffle=False)\n",
    "\n",
    "        return training_set_sb, training_set_tb, training_set_int\n",
    "\n",
    "    ################################################################################################\n",
    "    # Function to compute the terms required in the definition of the TEMPORAL boundary residual\n",
    "    def apply_initial_condition(self, input_tb):\n",
    "        u_pred_tb = self.approximate_solution(input_tb)\n",
    "        return u_pred_tb\n",
    "\n",
    "    # Function to compute the terms required in the definition of the SPATIAL boundary residual\n",
    "    def apply_boundary_conditions(self, input_sb):\n",
    "        l = int(input_sb.shape[0]/2) \n",
    "        \n",
    "        input_sb.requires_grad = True\n",
    "        u_pred_sb = self.approximate_solution(input_sb)  \n",
    "        \n",
    "        Tf=u_pred_sb[:,0].view(-1,1)\n",
    "        Ts=u_pred_sb[:,1].view(-1,1)\n",
    "        \n",
    "        grad_Ts= torch.autograd.grad(Ts.sum(), input_sb, create_graph=True)[0]\n",
    "        grad_Ts_x = grad_Ts[:, 1].view(-1,1)\n",
    "        \n",
    "#         print(\"Ts shape\",Ts.shape )\n",
    "#         print(\"grad shape\",grad_Ts_x.shape )\n",
    "        \n",
    "        l = int(input_sb.shape[0]/2)\n",
    "        grad_Tf= torch.autograd.grad(Tf.sum(), input_sb, create_graph=True)[0]\n",
    "        grad_Tf_x = grad_Tf[l:, 1].view(-1,1)\n",
    "        \n",
    "        boundary_0 = torch.cat([Tf[:l].view(-1,1),grad_Tf_x[:l]],1)\n",
    "        boundary_L = torch.cat([grad_Tf_x,grad_Ts_x[l:]],1 )\n",
    "        \n",
    "        boundary_points = torch.cat([boundary_0,boundary_L],0)\n",
    "        \n",
    "        return boundary_points\n",
    "\n",
    "    # Function to compute the PDE residuals\n",
    "    def compute_pde_residual(self, input_int):\n",
    "        input_int.requires_grad = True\n",
    "        u = self.approximate_solution(input_int)\n",
    "        \n",
    "        Tf=u[:,0].view(-1,1)\n",
    "        Ts=u[:,1].view(-1,1)\n",
    "        \n",
    "        grad_Tf = torch.autograd.grad(Tf.sum(), input_int, create_graph=True)[0]\n",
    "        grad_Tf_t = grad_Tf[:, 0].view(-1,1) #t in 0 coloumn \n",
    "        grad_Tf_x = grad_Tf[:, 1].view(-1,1)\n",
    "    \n",
    "        grad_Tf_xx = torch.autograd.grad(grad_Tf_x.sum(), input_int, create_graph=True)[0][:, 1].view(-1,1)\n",
    "        \n",
    "        grad_Ts = torch.autograd.grad(Ts.sum(), input_int, create_graph=True)[0]\n",
    "        grad_Ts_t = grad_Ts[:, 0].view(-1,1)  #t in 0 coloumn \n",
    "        grad_Ts_x = grad_Ts[:, 1].view(-1,1)\n",
    "        grad_Ts_xx = torch.autograd.grad(grad_Ts_x.sum(), input_int, create_graph=True)[0][:, 1].view(-1,1)\n",
    "        \n",
    "        residual_1 = grad_Tf_t + U_f * grad_Tf_x - alpha_f * grad_Tf_xx + h_f * ( Tf- Ts)\n",
    "        residual_2 = grad_Ts_t - alpha_s * grad_Ts_xx - h_s * (Tf - Ts)\n",
    "        residual = torch.cat( [residual_1 , residual_2],0)\n",
    "        \n",
    "        return residual.reshape(-1, )\n",
    "\n",
    "    # Function to compute the total loss (weighted sum of spatial boundary loss, temporal boundary loss and interior loss)\n",
    "    def compute_loss(self, inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=True):\n",
    "        u_pred_sb = self.apply_boundary_conditions(inp_train_sb)\n",
    "        u_pred_tb = self.apply_initial_condition(inp_train_tb)\n",
    "\n",
    "        \n",
    "        assert (u_pred_sb.shape[1] == u_train_sb.shape[1])\n",
    "        assert (u_pred_tb.shape[1] == u_train_tb.shape[1])\n",
    "\n",
    "\n",
    "        r_int = self.compute_pde_residual(inp_train_int)\n",
    "        r_sb = u_train_sb - u_pred_sb\n",
    "        r_tb = u_train_tb - u_pred_tb\n",
    "\n",
    "        loss_sb = torch.mean(abs(r_sb) ** 2)\n",
    "        loss_tb = torch.mean(abs(r_tb) ** 2)\n",
    "        loss_int = torch.mean(abs(r_int) ** 2)\n",
    "\n",
    "        loss_u = loss_sb + loss_tb\n",
    "        \n",
    "        loss = torch.log10(self.lambda_u * (loss_sb + loss_tb) + loss_int)\n",
    "        if verbose: print(\"Total loss: \", round(loss.item(), 4), \"| PDE Loss: \", round(torch.log10(loss_u).item(), 4), \"| Function Loss: \", round(torch.log10(loss_int).item(), 4))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    ################################################################################################\n",
    "    def fit(self, num_epochs, optimizer, verbose=True):\n",
    "        history = list()\n",
    "\n",
    "        # Loop over epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            if verbose: print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "            for j, ((inp_train_sb, u_train_sb), (inp_train_tb, u_train_tb), (inp_train_int, u_train_int)) in enumerate(zip(self.training_set_sb, self.training_set_tb, self.training_set_int)):\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = self.compute_loss(inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=verbose)\n",
    "                    loss.backward()\n",
    "\n",
    "                    history.append(loss.item())\n",
    "                    return loss\n",
    "\n",
    "                optimizer.step(closure=closure)\n",
    "\n",
    "        print('Final Loss: ', history[-1])\n",
    "\n",
    "        return history\n",
    "\n",
    "    ################################################################################################\n",
    "    def plotting(self):\n",
    "        inputs = self.soboleng.draw(100000)\n",
    "        inputs = self.convert(inputs).to(\"cpu\")\n",
    "\n",
    "        outputs = self.approximate_solution(inputs).to(\"cpu\")\n",
    "        \n",
    "        output = outputs[:,1].reshape(-1, )\n",
    "        exact_output = outputs[:,0].reshape(-1, )\n",
    "        print(output.shape)\n",
    "        \n",
    "        # output= output.to(\"cpu\")\n",
    "        # exact_output = exact_output.to(\"cpu\")\n",
    "        # inputs = inputs.to(\"cpu\")\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
    "        im1 = axs[0].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=exact_output.detach(), cmap=\"jet\")\n",
    "        axs[0].set_xlabel(\"x\")\n",
    "        axs[0].set_ylabel(\"t\")\n",
    "        plt.colorbar(im1, ax=axs[0])\n",
    "        axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "        im2 = axs[1].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=output.detach(), cmap=\"jet\")\n",
    "        axs[1].set_xlabel(\"x\")\n",
    "        axs[1].set_ylabel(\"t\")\n",
    "        plt.colorbar(im2, ax=axs[1])\n",
    "        axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "        axs[0].set_title(\"Approximate Tf solution\")\n",
    "        axs[1].set_title(\"Approximate Ts solution\")\n",
    "\n",
    "        plt.savefig('Task_1_Train_plots')\n",
    "        plt.show()\n",
    "\n",
    "        err = (torch.mean((output - exact_output) ** 2) / torch.mean(exact_output ** 2)) ** 0.5 * 100\n",
    "        print(\"L2 Relative Error Norm: \", err.item(), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1686499614646,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "M3ug4ztBfQxM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_int = 256\n",
    "n_sb = 64\n",
    "n_tb = 64\n",
    "\n",
    "pinn = Pinns(n_int, n_sb, n_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1686499730601,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "0CPnHdKtfQxN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "optimizer_LBFGS = optim.LBFGS(pinn.approximate_solution.parameters(),\n",
    "                              lr=float(0.5),\n",
    "                              max_iter=50000,\n",
    "                              max_eval=50000,\n",
    "                              history_size=150,\n",
    "                              line_search_fn=\"strong_wolfe\",\n",
    "                              tolerance_change=1.0 * np.finfo(float).eps)\n",
    "optimizer_ADAM = optim.Adam(pinn.approximate_solution.parameters(),\n",
    "                            lr=float(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qub-M5jqfQxN",
    "outputId": "34511ecf-7559-4bea-ce49-caf47194864b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################  0  ################################\n",
      "Total loss:  2.9494 | PDE Loss:  1.1191 | Function Loss:  2.9429\n",
      "################################  1  ################################\n",
      "Total loss:  2.9033 | PDE Loss:  1.1057 | Function Loss:  2.8963\n",
      "################################  2  ################################\n",
      "Total loss:  2.8534 | PDE Loss:  1.0925 | Function Loss:  2.8458\n",
      "################################  3  ################################\n",
      "Total loss:  2.799 | PDE Loss:  1.0794 | Function Loss:  2.7906\n",
      "################################  4  ################################\n",
      "Total loss:  2.7396 | PDE Loss:  1.0663 | Function Loss:  2.7303\n",
      "################################  5  ################################\n",
      "Total loss:  2.6748 | PDE Loss:  1.0532 | Function Loss:  2.6643\n",
      "################################  6  ################################\n",
      "Total loss:  2.6037 | PDE Loss:  1.0401 | Function Loss:  2.5917\n",
      "################################  7  ################################\n",
      "Total loss:  2.5259 | PDE Loss:  1.0268 | Function Loss:  2.5119\n",
      "################################  8  ################################\n",
      "Total loss:  2.4406 | PDE Loss:  1.0135 | Function Loss:  2.4241\n",
      "################################  9  ################################\n",
      "Total loss:  2.3472 | PDE Loss:  1.0 | Function Loss:  2.3272\n",
      "################################  10  ################################\n",
      "Total loss:  2.245 | PDE Loss:  0.9863 | Function Loss:  2.2203\n",
      "################################  11  ################################\n",
      "Total loss:  2.1334 | PDE Loss:  0.9724 | Function Loss:  2.1024\n",
      "################################  12  ################################\n",
      "Total loss:  2.0129 | PDE Loss:  0.9583 | Function Loss:  1.9728\n",
      "################################  13  ################################\n",
      "Total loss:  1.885 | PDE Loss:  0.9438 | Function Loss:  1.8322\n",
      "################################  14  ################################\n",
      "Total loss:  1.7545 | PDE Loss:  0.9287 | Function Loss:  1.6843\n",
      "################################  15  ################################\n",
      "Total loss:  1.6308 | PDE Loss:  0.9124 | Function Loss:  1.5386\n",
      "################################  16  ################################\n",
      "Total loss:  1.5268 | PDE Loss:  0.8944 | Function Loss:  1.4115\n",
      "################################  17  ################################\n",
      "Total loss:  1.4514 | PDE Loss:  0.8741 | Function Loss:  1.3179\n",
      "################################  18  ################################\n",
      "Total loss:  1.3984 | PDE Loss:  0.8514 | Function Loss:  1.2534\n",
      "################################  19  ################################\n",
      "Total loss:  1.35 | PDE Loss:  0.8269 | Function Loss:  1.1953\n",
      "################################  20  ################################\n",
      "Total loss:  1.2892 | PDE Loss:  0.8015 | Function Loss:  1.1183\n",
      "################################  21  ################################\n",
      "Total loss:  1.2052 | PDE Loss:  0.7766 | Function Loss:  1.0027\n",
      "################################  22  ################################\n",
      "Total loss:  1.0953 | PDE Loss:  0.7534 | Function Loss:  0.8316\n",
      "################################  23  ################################\n",
      "Total loss:  0.971 | PDE Loss:  0.7333 | Function Loss:  0.5957\n",
      "################################  24  ################################\n",
      "Total loss:  0.8746 | PDE Loss:  0.7171 | Function Loss:  0.3577\n",
      "################################  25  ################################\n",
      "Total loss:  0.8667 | PDE Loss:  0.7047 | Function Loss:  0.3601\n",
      "################################  26  ################################\n",
      "Total loss:  0.9287 | PDE Loss:  0.6942 | Function Loss:  0.5491\n",
      "################################  27  ################################\n",
      "Total loss:  0.9855 | PDE Loss:  0.6838 | Function Loss:  0.6851\n",
      "################################  28  ################################\n",
      "Total loss:  1.0058 | PDE Loss:  0.6723 | Function Loss:  0.7349\n",
      "################################  29  ################################\n",
      "Total loss:  0.989 | PDE Loss:  0.6596 | Function Loss:  0.7146\n",
      "################################  30  ################################\n",
      "Total loss:  0.9433 | PDE Loss:  0.6459 | Function Loss:  0.6386\n",
      "################################  31  ################################\n",
      "Total loss:  0.8817 | PDE Loss:  0.6321 | Function Loss:  0.5224\n",
      "################################  32  ################################\n",
      "Total loss:  0.8223 | PDE Loss:  0.6192 | Function Loss:  0.3946\n",
      "################################  33  ################################\n",
      "Total loss:  0.7808 | PDE Loss:  0.6083 | Function Loss:  0.2966\n",
      "################################  34  ################################\n",
      "Total loss:  0.7579 | PDE Loss:  0.5999 | Function Loss:  0.242\n",
      "################################  35  ################################\n",
      "Total loss:  0.74 | PDE Loss:  0.5939 | Function Loss:  0.196\n",
      "################################  36  ################################\n",
      "Total loss:  0.7175 | PDE Loss:  0.5892 | Function Loss:  0.1255\n",
      "################################  37  ################################\n",
      "Total loss:  0.6934 | PDE Loss:  0.5847 | Function Loss:  0.0385\n",
      "################################  38  ################################\n",
      "Total loss:  0.6783 | PDE Loss:  0.579 | Function Loss:  -0.0115\n",
      "################################  39  ################################\n",
      "Total loss:  0.6768 | PDE Loss:  0.5711 | Function Loss:  0.0112\n",
      "################################  40  ################################\n",
      "Total loss:  0.679 | PDE Loss:  0.5604 | Function Loss:  0.0573\n",
      "################################  41  ################################\n",
      "Total loss:  0.6706 | PDE Loss:  0.5467 | Function Loss:  0.0651\n",
      "################################  42  ################################\n",
      "Total loss:  0.6451 | PDE Loss:  0.5306 | Function Loss:  0.0102\n",
      "################################  43  ################################\n",
      "Total loss:  0.6068 | PDE Loss:  0.5124 | Function Loss:  -0.1022\n",
      "################################  44  ################################\n",
      "Total loss:  0.5685 | PDE Loss:  0.4926 | Function Loss:  -0.2264\n",
      "################################  45  ################################\n",
      "Total loss:  0.544 | PDE Loss:  0.4721 | Function Loss:  -0.2725\n",
      "################################  46  ################################\n",
      "Total loss:  0.5344 | PDE Loss:  0.4517 | Function Loss:  -0.2265\n",
      "################################  47  ################################\n",
      "Total loss:  0.528 | PDE Loss:  0.4326 | Function Loss:  -0.1769\n",
      "################################  48  ################################\n",
      "Total loss:  0.5156 | PDE Loss:  0.4157 | Function Loss:  -0.1719\n",
      "################################  49  ################################\n",
      "Total loss:  0.4984 | PDE Loss:  0.4012 | Function Loss:  -0.1994\n",
      "################################  50  ################################\n",
      "Total loss:  0.4828 | PDE Loss:  0.3888 | Function Loss:  -0.2282\n",
      "################################  51  ################################\n",
      "Total loss:  0.4691 | PDE Loss:  0.3777 | Function Loss:  -0.2528\n",
      "################################  52  ################################\n",
      "Total loss:  0.4516 | PDE Loss:  0.3672 | Function Loss:  -0.3014\n",
      "################################  53  ################################\n",
      "Total loss:  0.4279 | PDE Loss:  0.3568 | Function Loss:  -0.3931\n",
      "################################  54  ################################\n",
      "Total loss:  0.4047 | PDE Loss:  0.3465 | Function Loss:  -0.4971\n",
      "################################  55  ################################\n",
      "Total loss:  0.3904 | PDE Loss:  0.3363 | Function Loss:  -0.5405\n",
      "################################  56  ################################\n",
      "Total loss:  0.3836 | PDE Loss:  0.3261 | Function Loss:  -0.5231\n",
      "################################  57  ################################\n",
      "Total loss:  0.3746 | PDE Loss:  0.3157 | Function Loss:  -0.5222\n",
      "################################  58  ################################\n",
      "Total loss:  0.3593 | PDE Loss:  0.3048 | Function Loss:  -0.5689\n",
      "################################  59  ################################\n",
      "Total loss:  0.3423 | PDE Loss:  0.2932 | Function Loss:  -0.6288\n",
      "################################  60  ################################\n",
      "Total loss:  0.3277 | PDE Loss:  0.2805 | Function Loss:  -0.6595\n",
      "################################  61  ################################\n",
      "Total loss:  0.3139 | PDE Loss:  0.267 | Function Loss:  -0.6761\n",
      "################################  62  ################################\n",
      "Total loss:  0.2983 | PDE Loss:  0.2527 | Function Loss:  -0.7028\n",
      "################################  63  ################################\n",
      "Total loss:  0.2846 | PDE Loss:  0.2383 | Function Loss:  -0.71\n",
      "################################  64  ################################\n",
      "Total loss:  0.2758 | PDE Loss:  0.2246 | Function Loss:  -0.6781\n",
      "################################  65  ################################\n",
      "Total loss:  0.2675 | PDE Loss:  0.2126 | Function Loss:  -0.6576\n",
      "################################  66  ################################\n",
      "Total loss:  0.2551 | PDE Loss:  0.2025 | Function Loss:  -0.6882\n",
      "################################  67  ################################\n",
      "Total loss:  0.241 | PDE Loss:  0.1941 | Function Loss:  -0.749\n",
      "################################  68  ################################\n",
      "Total loss:  0.2294 | PDE Loss:  0.1865 | Function Loss:  -0.7977\n",
      "################################  69  ################################\n",
      "Total loss:  0.219 | PDE Loss:  0.1789 | Function Loss:  -0.8365\n",
      "################################  70  ################################\n",
      "Total loss:  0.208 | PDE Loss:  0.1709 | Function Loss:  -0.8783\n",
      "################################  71  ################################\n",
      "Total loss:  0.1986 | PDE Loss:  0.1623 | Function Loss:  -0.8967\n",
      "################################  72  ################################\n",
      "Total loss:  0.1908 | PDE Loss:  0.1533 | Function Loss:  -0.8918\n",
      "################################  73  ################################\n",
      "Total loss:  0.1812 | PDE Loss:  0.1442 | Function Loss:  -0.9067\n",
      "################################  74  ################################\n",
      "Total loss:  0.1701 | PDE Loss:  0.135 | Function Loss:  -0.9406\n",
      "################################  75  ################################\n",
      "Total loss:  0.1606 | PDE Loss:  0.1257 | Function Loss:  -0.9519\n",
      "################################  76  ################################\n",
      "Total loss:  0.1525 | PDE Loss:  0.1161 | Function Loss:  -0.9432\n",
      "################################  77  ################################\n",
      "Total loss:  0.144 | PDE Loss:  0.1065 | Function Loss:  -0.9383\n",
      "################################  78  ################################\n",
      "Total loss:  0.1364 | PDE Loss:  0.0973 | Function Loss:  -0.9296\n",
      "################################  79  ################################\n",
      "Total loss:  0.1293 | PDE Loss:  0.0891 | Function Loss:  -0.9246\n",
      "################################  80  ################################\n",
      "Total loss:  0.121 | PDE Loss:  0.0821 | Function Loss:  -0.9459\n",
      "################################  81  ################################\n",
      "Total loss:  0.1126 | PDE Loss:  0.0759 | Function Loss:  -0.9791\n",
      "################################  82  ################################\n",
      "Total loss:  0.1056 | PDE Loss:  0.0699 | Function Loss:  -0.998\n",
      "################################  83  ################################\n",
      "Total loss:  0.0989 | PDE Loss:  0.0636 | Function Loss:  -1.0099\n",
      "################################  84  ################################\n",
      "Total loss:  0.092 | PDE Loss:  0.0568 | Function Loss:  -1.0166\n",
      "################################  85  ################################\n",
      "Total loss:  0.0857 | PDE Loss:  0.0496 | Function Loss:  -1.0117\n",
      "################################  86  ################################\n",
      "Total loss:  0.0791 | PDE Loss:  0.0423 | Function Loss:  -1.0108\n",
      "################################  87  ################################\n",
      "Total loss:  0.0722 | PDE Loss:  0.0351 | Function Loss:  -1.0148\n",
      "################################  88  ################################\n",
      "Total loss:  0.0662 | PDE Loss:  0.028 | Function Loss:  -1.0086\n",
      "################################  89  ################################\n",
      "Total loss:  0.0604 | PDE Loss:  0.0209 | Function Loss:  -0.9997\n",
      "################################  90  ################################\n",
      "Total loss:  0.0545 | PDE Loss:  0.0139 | Function Loss:  -0.9948\n",
      "################################  91  ################################\n",
      "Total loss:  0.0489 | PDE Loss:  0.0075 | Function Loss:  -0.9921\n",
      "################################  92  ################################\n",
      "Total loss:  0.043 | PDE Loss:  0.0018 | Function Loss:  -0.9997\n",
      "################################  93  ################################\n",
      "Total loss:  0.0371 | PDE Loss:  -0.0033 | Function Loss:  -1.0144\n",
      "################################  94  ################################\n",
      "Total loss:  0.0318 | PDE Loss:  -0.0082 | Function Loss:  -1.0238\n",
      "################################  95  ################################\n",
      "Total loss:  0.0264 | PDE Loss:  -0.0135 | Function Loss:  -1.03\n",
      "################################  96  ################################\n",
      "Total loss:  0.021 | PDE Loss:  -0.0191 | Function Loss:  -1.0327\n",
      "################################  97  ################################\n",
      "Total loss:  0.0158 | PDE Loss:  -0.0249 | Function Loss:  -1.0327\n",
      "################################  98  ################################\n",
      "Total loss:  0.0103 | PDE Loss:  -0.0306 | Function Loss:  -1.0366\n",
      "################################  99  ################################\n",
      "Total loss:  0.005 | PDE Loss:  -0.036 | Function Loss:  -1.0398\n",
      "################################  100  ################################\n",
      "Total loss:  -0.0 | PDE Loss:  -0.0415 | Function Loss:  -1.0408\n",
      "################################  101  ################################\n",
      "Total loss:  -0.0052 | PDE Loss:  -0.0469 | Function Loss:  -1.0438\n",
      "################################  102  ################################\n",
      "Total loss:  -0.0104 | PDE Loss:  -0.0521 | Function Loss:  -1.0487\n",
      "################################  103  ################################\n",
      "Total loss:  -0.0156 | PDE Loss:  -0.0568 | Function Loss:  -1.0593\n",
      "################################  104  ################################\n",
      "Total loss:  -0.0209 | PDE Loss:  -0.0612 | Function Loss:  -1.0732\n",
      "################################  105  ################################\n",
      "Total loss:  -0.0259 | PDE Loss:  -0.0657 | Function Loss:  -1.084\n",
      "################################  106  ################################\n",
      "Total loss:  -0.0311 | PDE Loss:  -0.0706 | Function Loss:  -1.0921\n",
      "################################  107  ################################\n",
      "Total loss:  -0.0363 | PDE Loss:  -0.0758 | Function Loss:  -1.0969\n",
      "################################  108  ################################\n",
      "Total loss:  -0.0416 | PDE Loss:  -0.0811 | Function Loss:  -1.1021\n",
      "################################  109  ################################\n",
      "Total loss:  -0.0469 | PDE Loss:  -0.0863 | Function Loss:  -1.1083\n",
      "################################  110  ################################\n",
      "Total loss:  -0.0522 | PDE Loss:  -0.0917 | Function Loss:  -1.1127\n",
      "################################  111  ################################\n",
      "Total loss:  -0.0575 | PDE Loss:  -0.0972 | Function Loss:  -1.1169\n",
      "################################  112  ################################\n",
      "Total loss:  -0.063 | PDE Loss:  -0.1026 | Function Loss:  -1.1219\n",
      "################################  113  ################################\n",
      "Total loss:  -0.0685 | PDE Loss:  -0.1079 | Function Loss:  -1.1306\n",
      "################################  114  ################################\n",
      "Total loss:  -0.0742 | PDE Loss:  -0.1131 | Function Loss:  -1.1404\n",
      "################################  115  ################################\n",
      "Total loss:  -0.0798 | PDE Loss:  -0.1187 | Function Loss:  -1.1474\n",
      "################################  116  ################################\n",
      "Total loss:  -0.0857 | PDE Loss:  -0.1247 | Function Loss:  -1.1515\n",
      "################################  117  ################################\n",
      "Total loss:  -0.0916 | PDE Loss:  -0.1309 | Function Loss:  -1.1542\n",
      "################################  118  ################################\n",
      "Total loss:  -0.0977 | PDE Loss:  -0.1372 | Function Loss:  -1.1582\n",
      "################################  119  ################################\n",
      "Total loss:  -0.1038 | PDE Loss:  -0.1436 | Function Loss:  -1.1615\n",
      "################################  120  ################################\n",
      "Total loss:  -0.1102 | PDE Loss:  -0.1503 | Function Loss:  -1.1639\n",
      "################################  121  ################################\n",
      "Total loss:  -0.1166 | PDE Loss:  -0.1571 | Function Loss:  -1.167\n",
      "################################  122  ################################\n",
      "Total loss:  -0.1233 | PDE Loss:  -0.1639 | Function Loss:  -1.1727\n",
      "################################  123  ################################\n",
      "Total loss:  -0.1301 | PDE Loss:  -0.1707 | Function Loss:  -1.1789\n",
      "################################  124  ################################\n",
      "Total loss:  -0.137 | PDE Loss:  -0.178 | Function Loss:  -1.1828\n",
      "################################  125  ################################\n",
      "Total loss:  -0.1441 | PDE Loss:  -0.1856 | Function Loss:  -1.1848\n",
      "################################  126  ################################\n",
      "Total loss:  -0.1515 | PDE Loss:  -0.1935 | Function Loss:  -1.1872\n",
      "################################  127  ################################\n",
      "Total loss:  -0.159 | PDE Loss:  -0.2015 | Function Loss:  -1.1897\n",
      "################################  128  ################################\n",
      "Total loss:  -0.1667 | PDE Loss:  -0.2098 | Function Loss:  -1.1911\n",
      "################################  129  ################################\n",
      "Total loss:  -0.1746 | PDE Loss:  -0.2185 | Function Loss:  -1.1924\n",
      "################################  130  ################################\n",
      "Total loss:  -0.1828 | PDE Loss:  -0.2271 | Function Loss:  -1.1954\n",
      "################################  131  ################################\n",
      "Total loss:  -0.1911 | PDE Loss:  -0.2361 | Function Loss:  -1.1979\n",
      "################################  132  ################################\n",
      "Total loss:  -0.1996 | PDE Loss:  -0.2456 | Function Loss:  -1.1982\n",
      "################################  133  ################################\n",
      "Total loss:  -0.2084 | PDE Loss:  -0.2554 | Function Loss:  -1.1973\n",
      "################################  134  ################################\n",
      "Total loss:  -0.2174 | PDE Loss:  -0.2656 | Function Loss:  -1.1963\n",
      "################################  135  ################################\n",
      "Total loss:  -0.2266 | PDE Loss:  -0.2762 | Function Loss:  -1.1938\n",
      "################################  136  ################################\n",
      "Total loss:  -0.236 | PDE Loss:  -0.2871 | Function Loss:  -1.1904\n",
      "################################  137  ################################\n",
      "Total loss:  -0.2456 | PDE Loss:  -0.2983 | Function Loss:  -1.1877\n",
      "################################  138  ################################\n",
      "Total loss:  -0.2554 | PDE Loss:  -0.3099 | Function Loss:  -1.1841\n",
      "################################  139  ################################\n",
      "Total loss:  -0.2654 | PDE Loss:  -0.3219 | Function Loss:  -1.1786\n",
      "################################  140  ################################\n",
      "Total loss:  -0.2755 | PDE Loss:  -0.3344 | Function Loss:  -1.1726\n",
      "################################  141  ################################\n",
      "Total loss:  -0.2858 | PDE Loss:  -0.3472 | Function Loss:  -1.1658\n",
      "################################  142  ################################\n",
      "Total loss:  -0.2962 | PDE Loss:  -0.3605 | Function Loss:  -1.1578\n",
      "################################  143  ################################\n",
      "Total loss:  -0.3068 | PDE Loss:  -0.374 | Function Loss:  -1.1502\n",
      "################################  144  ################################\n",
      "Total loss:  -0.3174 | PDE Loss:  -0.3878 | Function Loss:  -1.1422\n",
      "################################  145  ################################\n",
      "Total loss:  -0.328 | PDE Loss:  -0.4019 | Function Loss:  -1.1333\n",
      "################################  146  ################################\n",
      "Total loss:  -0.3386 | PDE Loss:  -0.4163 | Function Loss:  -1.1246\n",
      "################################  147  ################################\n",
      "Total loss:  -0.3492 | PDE Loss:  -0.431 | Function Loss:  -1.1149\n",
      "################################  148  ################################\n",
      "Total loss:  -0.3598 | PDE Loss:  -0.4457 | Function Loss:  -1.1056\n",
      "################################  149  ################################\n",
      "Total loss:  -0.3702 | PDE Loss:  -0.4605 | Function Loss:  -1.0966\n",
      "################################  150  ################################\n",
      "Total loss:  -0.3805 | PDE Loss:  -0.4754 | Function Loss:  -1.0876\n",
      "################################  151  ################################\n",
      "Total loss:  -0.3906 | PDE Loss:  -0.4901 | Function Loss:  -1.0793\n",
      "################################  152  ################################\n",
      "Total loss:  -0.4005 | PDE Loss:  -0.5049 | Function Loss:  -1.0707\n",
      "################################  153  ################################\n",
      "Total loss:  -0.4101 | PDE Loss:  -0.5191 | Function Loss:  -1.0639\n",
      "################################  154  ################################\n",
      "Total loss:  -0.4194 | PDE Loss:  -0.5336 | Function Loss:  -1.0552\n",
      "################################  155  ################################\n",
      "Total loss:  -0.4278 | PDE Loss:  -0.5463 | Function Loss:  -1.0496\n",
      "################################  156  ################################\n",
      "Total loss:  -0.4327 | PDE Loss:  -0.5616 | Function Loss:  -1.0231\n",
      "################################  157  ################################\n",
      "Total loss:  -0.4225 | PDE Loss:  -0.5688 | Function Loss:  -0.9662\n",
      "################################  158  ################################\n",
      "Total loss:  -0.3884 | PDE Loss:  -0.5884 | Function Loss:  -0.8215\n",
      "################################  159  ################################\n",
      "Total loss:  -0.4247 | PDE Loss:  -0.587 | Function Loss:  -0.9306\n",
      "################################  160  ################################\n",
      "Total loss:  -0.4671 | PDE Loss:  -0.5993 | Function Loss:  -1.048\n",
      "################################  161  ################################\n",
      "Total loss:  -0.4388 | PDE Loss:  -0.6111 | Function Loss:  -0.9238\n",
      "################################  162  ################################\n",
      "Total loss:  -0.4481 | PDE Loss:  -0.6087 | Function Loss:  -0.958\n",
      "################################  163  ################################\n",
      "Total loss:  -0.4852 | PDE Loss:  -0.6194 | Function Loss:  -1.0608\n",
      "################################  164  ################################\n",
      "Total loss:  -0.4641 | PDE Loss:  -0.629 | Function Loss:  -0.9645\n",
      "################################  165  ################################\n",
      "Total loss:  -0.4757 | PDE Loss:  -0.626 | Function Loss:  -1.0093\n",
      "################################  166  ################################\n",
      "Total loss:  -0.5009 | PDE Loss:  -0.6341 | Function Loss:  -1.0792\n",
      "################################  167  ################################\n",
      "Total loss:  -0.4837 | PDE Loss:  -0.6429 | Function Loss:  -0.9969\n",
      "################################  168  ################################\n",
      "Total loss:  -0.4995 | PDE Loss:  -0.6399 | Function Loss:  -1.058\n",
      "################################  169  ################################\n",
      "Total loss:  -0.5146 | PDE Loss:  -0.6457 | Function Loss:  -1.0986\n",
      "################################  170  ################################\n",
      "Total loss:  -0.5021 | PDE Loss:  -0.6542 | Function Loss:  -1.0318\n",
      "################################  171  ################################\n",
      "Total loss:  -0.5186 | PDE Loss:  -0.6516 | Function Loss:  -1.0972\n",
      "################################  172  ################################\n",
      "Total loss:  -0.5274 | PDE Loss:  -0.6561 | Function Loss:  -1.1184\n",
      "################################  173  ################################\n",
      "Total loss:  -0.5194 | PDE Loss:  -0.6643 | Function Loss:  -1.0665\n",
      "################################  174  ################################\n",
      "Total loss:  -0.5339 | PDE Loss:  -0.6624 | Function Loss:  -1.1256\n",
      "################################  175  ################################\n",
      "Total loss:  -0.5403 | PDE Loss:  -0.6665 | Function Loss:  -1.1386\n",
      "################################  176  ################################\n",
      "Total loss:  -0.5352 | PDE Loss:  -0.6743 | Function Loss:  -1.0972\n",
      "################################  177  ################################\n",
      "Total loss:  -0.5468 | PDE Loss:  -0.673 | Function Loss:  -1.1453\n",
      "################################  178  ################################\n",
      "Total loss:  -0.5533 | PDE Loss:  -0.6773 | Function Loss:  -1.1585\n",
      "################################  179  ################################\n",
      "Total loss:  -0.55 | PDE Loss:  -0.6844 | Function Loss:  -1.1248\n",
      "################################  180  ################################\n",
      "Total loss:  -0.5582 | PDE Loss:  -0.6834 | Function Loss:  -1.1594\n",
      "################################  181  ################################\n",
      "Total loss:  -0.5661 | PDE Loss:  -0.6885 | Function Loss:  -1.1757\n",
      "################################  182  ################################\n",
      "Total loss:  -0.5646 | PDE Loss:  -0.6947 | Function Loss:  -1.1517\n",
      "################################  183  ################################\n",
      "Total loss:  -0.5688 | PDE Loss:  -0.6942 | Function Loss:  -1.1695\n",
      "################################  184  ################################\n",
      "Total loss:  -0.5775 | PDE Loss:  -0.7006 | Function Loss:  -1.1853\n",
      "################################  185  ################################\n",
      "Total loss:  -0.5795 | PDE Loss:  -0.7053 | Function Loss:  -1.1788\n",
      "################################  186  ################################\n",
      "Total loss:  -0.5803 | PDE Loss:  -0.7059 | Function Loss:  -1.1804\n",
      "################################  187  ################################\n",
      "Total loss:  -0.587 | PDE Loss:  -0.7132 | Function Loss:  -1.1853\n",
      "################################  188  ################################\n",
      "Total loss:  -0.5929 | PDE Loss:  -0.7161 | Function Loss:  -1.2005\n",
      "################################  189  ################################\n",
      "Total loss:  -0.5943 | PDE Loss:  -0.7185 | Function Loss:  -1.1985\n",
      "################################  190  ################################\n",
      "Total loss:  -0.5967 | PDE Loss:  -0.7255 | Function Loss:  -1.1872\n",
      "################################  191  ################################\n",
      "Total loss:  -0.6026 | PDE Loss:  -0.7267 | Function Loss:  -1.2075\n",
      "################################  192  ################################\n",
      "Total loss:  -0.608 | PDE Loss:  -0.7316 | Function Loss:  -1.214\n",
      "################################  193  ################################\n",
      "Total loss:  -0.6103 | PDE Loss:  -0.7364 | Function Loss:  -1.2091\n",
      "################################  194  ################################\n",
      "Total loss:  -0.6125 | PDE Loss:  -0.7378 | Function Loss:  -1.2134\n",
      "################################  195  ################################\n",
      "Total loss:  -0.6168 | PDE Loss:  -0.7442 | Function Loss:  -1.2114\n",
      "################################  196  ################################\n",
      "Total loss:  -0.6222 | PDE Loss:  -0.746 | Function Loss:  -1.2276\n",
      "################################  197  ################################\n",
      "Total loss:  -0.6265 | PDE Loss:  -0.7501 | Function Loss:  -1.2324\n",
      "################################  198  ################################\n",
      "Total loss:  -0.6293 | PDE Loss:  -0.7545 | Function Loss:  -1.2308\n",
      "################################  199  ################################\n",
      "Total loss:  -0.6318 | PDE Loss:  -0.756 | Function Loss:  -1.2361\n",
      "################################  200  ################################\n",
      "Total loss:  -0.635 | PDE Loss:  -0.7617 | Function Loss:  -1.2321\n",
      "################################  201  ################################\n",
      "Total loss:  -0.6392 | PDE Loss:  -0.7626 | Function Loss:  -1.2461\n",
      "################################  202  ################################\n",
      "Total loss:  -0.6438 | PDE Loss:  -0.7676 | Function Loss:  -1.2495\n",
      "################################  203  ################################\n",
      "Total loss:  -0.6483 | PDE Loss:  -0.7693 | Function Loss:  -1.2623\n",
      "################################  204  ################################\n",
      "Total loss:  -0.6524 | PDE Loss:  -0.773 | Function Loss:  -1.268\n",
      "################################  205  ################################\n",
      "Total loss:  -0.6562 | PDE Loss:  -0.7759 | Function Loss:  -1.2742\n",
      "################################  206  ################################\n",
      "Total loss:  -0.6596 | PDE Loss:  -0.7783 | Function Loss:  -1.2812\n",
      "################################  207  ################################\n",
      "Total loss:  -0.6628 | PDE Loss:  -0.7822 | Function Loss:  -1.282\n",
      "################################  208  ################################\n",
      "Total loss:  -0.6655 | PDE Loss:  -0.7833 | Function Loss:  -1.2895\n",
      "################################  209  ################################\n",
      "Total loss:  -0.667 | PDE Loss:  -0.7885 | Function Loss:  -1.2793\n",
      "################################  210  ################################\n",
      "Total loss:  -0.6661 | PDE Loss:  -0.7877 | Function Loss:  -1.2782\n",
      "################################  211  ################################\n",
      "Total loss:  -0.6614 | PDE Loss:  -0.7952 | Function Loss:  -1.2379\n",
      "################################  212  ################################\n",
      "Total loss:  -0.6554 | PDE Loss:  -0.7914 | Function Loss:  -1.2259\n",
      "################################  213  ################################\n",
      "Total loss:  -0.6575 | PDE Loss:  -0.8011 | Function Loss:  -1.208\n",
      "################################  214  ################################\n",
      "Total loss:  -0.6733 | PDE Loss:  -0.7973 | Function Loss:  -1.2785\n",
      "################################  215  ################################\n",
      "Total loss:  -0.6896 | PDE Loss:  -0.8039 | Function Loss:  -1.3253\n",
      "################################  216  ################################\n",
      "Total loss:  -0.6971 | PDE Loss:  -0.8054 | Function Loss:  -1.3533\n",
      "################################  217  ################################\n",
      "Total loss:  -0.6959 | PDE Loss:  -0.8065 | Function Loss:  -1.3442\n",
      "################################  218  ################################\n",
      "Total loss:  -0.69 | PDE Loss:  -0.8131 | Function Loss:  -1.2977\n",
      "################################  219  ################################\n",
      "Total loss:  -0.6871 | PDE Loss:  -0.8103 | Function Loss:  -1.2945\n",
      "################################  220  ################################\n",
      "Total loss:  -0.6946 | PDE Loss:  -0.8187 | Function Loss:  -1.2992\n",
      "################################  221  ################################\n",
      "Total loss:  -0.7083 | PDE Loss:  -0.8171 | Function Loss:  -1.3629\n",
      "################################  222  ################################\n",
      "Total loss:  -0.7182 | PDE Loss:  -0.822 | Function Loss:  -1.3908\n",
      "################################  223  ################################\n",
      "Total loss:  -0.7213 | PDE Loss:  -0.825 | Function Loss:  -1.3938\n",
      "################################  224  ################################\n",
      "Total loss:  -0.7192 | PDE Loss:  -0.8256 | Function Loss:  -1.3822\n",
      "################################  225  ################################\n",
      "Total loss:  -0.7159 | PDE Loss:  -0.8325 | Function Loss:  -1.3442\n",
      "################################  226  ################################\n",
      "Total loss:  -0.7169 | PDE Loss:  -0.8305 | Function Loss:  -1.3547\n",
      "################################  227  ################################\n",
      "Total loss:  -0.7245 | PDE Loss:  -0.8381 | Function Loss:  -1.3625\n",
      "################################  228  ################################\n",
      "Total loss:  -0.7351 | PDE Loss:  -0.8373 | Function Loss:  -1.4136\n",
      "################################  229  ################################\n",
      "Total loss:  -0.7434 | PDE Loss:  -0.8422 | Function Loss:  -1.435\n",
      "################################  230  ################################\n",
      "Total loss:  -0.7479 | PDE Loss:  -0.8447 | Function Loss:  -1.4472\n",
      "################################  231  ################################\n",
      "Total loss:  -0.7492 | PDE Loss:  -0.8464 | Function Loss:  -1.4468\n",
      "################################  232  ################################\n",
      "Total loss:  -0.7483 | PDE Loss:  -0.8519 | Function Loss:  -1.4214\n",
      "################################  233  ################################\n",
      "Total loss:  -0.7464 | PDE Loss:  -0.8511 | Function Loss:  -1.4153\n",
      "################################  234  ################################\n",
      "Total loss:  -0.7456 | PDE Loss:  -0.8586 | Function Loss:  -1.3859\n",
      "################################  235  ################################\n",
      "Total loss:  -0.7496 | PDE Loss:  -0.8565 | Function Loss:  -1.4106\n",
      "################################  236  ################################\n",
      "Total loss:  -0.7579 | PDE Loss:  -0.8638 | Function Loss:  -1.4227\n",
      "################################  237  ################################\n",
      "Total loss:  -0.7677 | PDE Loss:  -0.8632 | Function Loss:  -1.4725\n",
      "################################  238  ################################\n",
      "Total loss:  -0.7757 | PDE Loss:  -0.8684 | Function Loss:  -1.492\n",
      "################################  239  ################################\n",
      "Total loss:  -0.7813 | PDE Loss:  -0.8702 | Function Loss:  -1.5137\n",
      "################################  240  ################################\n",
      "Total loss:  -0.785 | PDE Loss:  -0.8732 | Function Loss:  -1.5207\n",
      "################################  241  ################################\n",
      "Total loss:  -0.7873 | PDE Loss:  -0.8772 | Function Loss:  -1.5158\n",
      "################################  242  ################################\n",
      "Total loss:  -0.7879 | PDE Loss:  -0.8782 | Function Loss:  -1.5144\n",
      "################################  243  ################################\n",
      "Total loss:  -0.7856 | PDE Loss:  -0.8842 | Function Loss:  -1.4777\n",
      "################################  244  ################################\n",
      "Total loss:  -0.7795 | PDE Loss:  -0.8826 | Function Loss:  -1.4547\n",
      "################################  245  ################################\n",
      "Total loss:  -0.7727 | PDE Loss:  -0.891 | Function Loss:  -1.3954\n",
      "################################  246  ################################\n",
      "Total loss:  -0.7763 | PDE Loss:  -0.8875 | Function Loss:  -1.4223\n",
      "################################  247  ################################\n",
      "Total loss:  -0.7914 | PDE Loss:  -0.896 | Function Loss:  -1.4611\n",
      "################################  248  ################################\n",
      "Total loss:  -0.8077 | PDE Loss:  -0.8951 | Function Loss:  -1.5472\n",
      "################################  249  ################################\n",
      "Total loss:  -0.8174 | PDE Loss:  -0.8999 | Function Loss:  -1.5791\n",
      "################################  250  ################################\n",
      "Total loss:  -0.8207 | PDE Loss:  -0.903 | Function Loss:  -1.5833\n",
      "################################  251  ################################\n",
      "Total loss:  -0.819 | PDE Loss:  -0.9043 | Function Loss:  -1.568\n",
      "################################  252  ################################\n",
      "Total loss:  -0.8131 | PDE Loss:  -0.9106 | Function Loss:  -1.5095\n",
      "################################  253  ################################\n",
      "Total loss:  -0.8063 | PDE Loss:  -0.9086 | Function Loss:  -1.4843\n",
      "################################  254  ################################\n",
      "Total loss:  -0.8067 | PDE Loss:  -0.917 | Function Loss:  -1.4559\n",
      "################################  255  ################################\n",
      "Total loss:  -0.819 | PDE Loss:  -0.9146 | Function Loss:  -1.5231\n",
      "################################  256  ################################\n",
      "Total loss:  -0.8338 | PDE Loss:  -0.9214 | Function Loss:  -1.5719\n",
      "################################  257  ################################\n",
      "Total loss:  -0.8437 | PDE Loss:  -0.9223 | Function Loss:  -1.6243\n",
      "################################  258  ################################\n",
      "Total loss:  -0.8478 | PDE Loss:  -0.9257 | Function Loss:  -1.6325\n",
      "################################  259  ################################\n",
      "Total loss:  -0.8475 | PDE Loss:  -0.9299 | Function Loss:  -1.6098\n",
      "################################  260  ################################\n",
      "Total loss:  -0.8435 | PDE Loss:  -0.9301 | Function Loss:  -1.5863\n",
      "################################  261  ################################\n",
      "Total loss:  -0.8373 | PDE Loss:  -0.9368 | Function Loss:  -1.5258\n",
      "################################  262  ################################\n",
      "Total loss:  -0.8346 | PDE Loss:  -0.9346 | Function Loss:  -1.5217\n",
      "################################  263  ################################\n",
      "Total loss:  -0.8408 | PDE Loss:  -0.9424 | Function Loss:  -1.5217\n",
      "################################  264  ################################\n",
      "Total loss:  -0.8536 | PDE Loss:  -0.9409 | Function Loss:  -1.5932\n",
      "################################  265  ################################\n",
      "Total loss:  -0.8648 | PDE Loss:  -0.9467 | Function Loss:  -1.63\n",
      "################################  266  ################################\n",
      "Total loss:  -0.8716 | PDE Loss:  -0.9482 | Function Loss:  -1.6632\n",
      "################################  267  ################################\n",
      "Total loss:  -0.8745 | PDE Loss:  -0.9511 | Function Loss:  -1.666\n",
      "################################  268  ################################\n",
      "Total loss:  -0.8743 | PDE Loss:  -0.955 | Function Loss:  -1.6449\n",
      "################################  269  ################################\n",
      "Total loss:  -0.8713 | PDE Loss:  -0.9553 | Function Loss:  -1.6264\n",
      "################################  270  ################################\n",
      "Total loss:  -0.8659 | PDE Loss:  -0.9613 | Function Loss:  -1.5706\n",
      "################################  271  ################################\n",
      "Total loss:  -0.8614 | PDE Loss:  -0.9593 | Function Loss:  -1.5568\n",
      "################################  272  ################################\n",
      "Total loss:  -0.8635 | PDE Loss:  -0.9667 | Function Loss:  -1.5381\n",
      "################################  273  ################################\n",
      "Total loss:  -0.8736 | PDE Loss:  -0.9648 | Function Loss:  -1.5962\n",
      "################################  274  ################################\n",
      "Total loss:  -0.8851 | PDE Loss:  -0.9709 | Function Loss:  -1.6318\n",
      "################################  275  ################################\n",
      "Total loss:  -0.8935 | PDE Loss:  -0.9714 | Function Loss:  -1.6778\n",
      "################################  276  ################################\n",
      "Total loss:  -0.898 | PDE Loss:  -0.9749 | Function Loss:  -1.6881\n",
      "################################  277  ################################\n",
      "Total loss:  -0.8997 | PDE Loss:  -0.9777 | Function Loss:  -1.6841\n",
      "################################  278  ################################\n",
      "Total loss:  -0.8991 | PDE Loss:  -0.9788 | Function Loss:  -1.6749\n",
      "################################  279  ################################\n",
      "Total loss:  -0.8961 | PDE Loss:  -0.9834 | Function Loss:  -1.6355\n",
      "################################  280  ################################\n",
      "Total loss:  -0.8909 | PDE Loss:  -0.9823 | Function Loss:  -1.6124\n",
      "################################  281  ################################\n",
      "Total loss:  -0.8861 | PDE Loss:  -0.9888 | Function Loss:  -1.5625\n",
      "################################  282  ################################\n",
      "Total loss:  -0.8872 | PDE Loss:  -0.9864 | Function Loss:  -1.5772\n",
      "################################  283  ################################\n",
      "Total loss:  -0.8955 | PDE Loss:  -0.993 | Function Loss:  -1.592\n",
      "################################  284  ################################\n",
      "Total loss:  -0.9062 | PDE Loss:  -0.9919 | Function Loss:  -1.6534\n",
      "################################  285  ################################\n",
      "Total loss:  -0.9145 | PDE Loss:  -0.9963 | Function Loss:  -1.6793\n",
      "################################  286  ################################\n",
      "Total loss:  -0.9192 | PDE Loss:  -0.9975 | Function Loss:  -1.7015\n",
      "################################  287  ################################\n",
      "Total loss:  -0.9211 | PDE Loss:  -0.9997 | Function Loss:  -1.7022\n",
      "################################  288  ################################\n",
      "Total loss:  -0.9209 | PDE Loss:  -1.0027 | Function Loss:  -1.6864\n",
      "################################  289  ################################\n",
      "Total loss:  -0.9188 | PDE Loss:  -1.0029 | Function Loss:  -1.6729\n",
      "################################  290  ################################\n",
      "Total loss:  -0.9147 | PDE Loss:  -1.0075 | Function Loss:  -1.6303\n",
      "################################  291  ################################\n",
      "Total loss:  -0.9101 | PDE Loss:  -1.0059 | Function Loss:  -1.6135\n",
      "################################  292  ################################\n",
      "Total loss:  -0.9083 | PDE Loss:  -1.0117 | Function Loss:  -1.5823\n",
      "################################  293  ################################\n",
      "Total loss:  -0.9127 | PDE Loss:  -1.0095 | Function Loss:  -1.612\n",
      "################################  294  ################################\n",
      "Total loss:  -0.9211 | PDE Loss:  -1.0148 | Function Loss:  -1.6331\n",
      "################################  295  ################################\n",
      "Total loss:  -0.9293 | PDE Loss:  -1.0141 | Function Loss:  -1.6806\n",
      "################################  296  ################################\n",
      "Total loss:  -0.9349 | PDE Loss:  -1.0175 | Function Loss:  -1.6965\n",
      "################################  297  ################################\n",
      "Total loss:  -0.9379 | PDE Loss:  -1.0187 | Function Loss:  -1.7081\n",
      "################################  298  ################################\n",
      "Total loss:  -0.9389 | PDE Loss:  -1.0203 | Function Loss:  -1.7063\n",
      "################################  299  ################################\n",
      "Total loss:  -0.9384 | PDE Loss:  -1.023 | Function Loss:  -1.6906\n",
      "################################  300  ################################\n",
      "Total loss:  -0.9365 | PDE Loss:  -1.0229 | Function Loss:  -1.68\n",
      "################################  301  ################################\n",
      "Total loss:  -0.9332 | PDE Loss:  -1.0268 | Function Loss:  -1.6459\n",
      "################################  302  ################################\n",
      "Total loss:  -0.9298 | PDE Loss:  -1.0252 | Function Loss:  -1.6348\n",
      "################################  303  ################################\n",
      "Total loss:  -0.9283 | PDE Loss:  -1.03 | Function Loss:  -1.6088\n",
      "################################  304  ################################\n",
      "Total loss:  -0.9311 | PDE Loss:  -1.028 | Function Loss:  -1.6301\n",
      "################################  305  ################################\n",
      "Total loss:  -0.9371 | PDE Loss:  -1.0326 | Function Loss:  -1.6417\n",
      "################################  306  ################################\n",
      "Total loss:  -0.9437 | PDE Loss:  -1.0317 | Function Loss:  -1.6801\n",
      "################################  307  ################################\n",
      "Total loss:  -0.9488 | PDE Loss:  -1.0349 | Function Loss:  -1.6937\n",
      "################################  308  ################################\n",
      "Total loss:  -0.9519 | PDE Loss:  -1.0355 | Function Loss:  -1.709\n",
      "################################  309  ################################\n",
      "Total loss:  -0.9536 | PDE Loss:  -1.0371 | Function Loss:  -1.7105\n",
      "################################  310  ################################\n",
      "Total loss:  -0.9541 | PDE Loss:  -1.0388 | Function Loss:  -1.7056\n",
      "################################  311  ################################\n",
      "Total loss:  -0.9537 | PDE Loss:  -1.0392 | Function Loss:  -1.7018\n",
      "################################  312  ################################\n",
      "Total loss:  -0.9524 | PDE Loss:  -1.0418 | Function Loss:  -1.6829\n",
      "################################  313  ################################\n",
      "Total loss:  -0.9502 | PDE Loss:  -1.041 | Function Loss:  -1.6746\n",
      "################################  314  ################################\n",
      "Total loss:  -0.9476 | PDE Loss:  -1.0445 | Function Loss:  -1.6463\n",
      "################################  315  ################################\n",
      "Total loss:  -0.9457 | PDE Loss:  -1.0429 | Function Loss:  -1.6438\n",
      "################################  316  ################################\n",
      "Total loss:  -0.9462 | PDE Loss:  -1.047 | Function Loss:  -1.6299\n",
      "################################  317  ################################\n",
      "Total loss:  -0.9495 | PDE Loss:  -1.0454 | Function Loss:  -1.6529\n",
      "################################  318  ################################\n",
      "Total loss:  -0.9545 | PDE Loss:  -1.049 | Function Loss:  -1.6629\n",
      "################################  319  ################################\n",
      "Total loss:  -0.9593 | PDE Loss:  -1.0483 | Function Loss:  -1.6916\n",
      "################################  320  ################################\n",
      "Total loss:  -0.9631 | PDE Loss:  -1.0508 | Function Loss:  -1.7008\n",
      "################################  321  ################################\n",
      "Total loss:  -0.9656 | PDE Loss:  -1.0511 | Function Loss:  -1.7134\n",
      "################################  322  ################################\n",
      "Total loss:  -0.9671 | PDE Loss:  -1.0524 | Function Loss:  -1.7156\n",
      "################################  323  ################################\n",
      "Total loss:  -0.9679 | PDE Loss:  -1.0535 | Function Loss:  -1.7154\n",
      "################################  324  ################################\n",
      "Total loss:  -0.9682 | PDE Loss:  -1.054 | Function Loss:  -1.7147\n",
      "################################  325  ################################\n",
      "Total loss:  -0.968 | PDE Loss:  -1.0558 | Function Loss:  -1.7055\n",
      "################################  326  ################################\n",
      "Total loss:  -0.9672 | PDE Loss:  -1.0556 | Function Loss:  -1.702\n",
      "################################  327  ################################\n",
      "Total loss:  -0.9657 | PDE Loss:  -1.0581 | Function Loss:  -1.6829\n",
      "################################  328  ################################\n",
      "Total loss:  -0.9635 | PDE Loss:  -1.0571 | Function Loss:  -1.6758\n",
      "################################  329  ################################\n",
      "Total loss:  -0.9612 | PDE Loss:  -1.0604 | Function Loss:  -1.6511\n",
      "################################  330  ################################\n",
      "Total loss:  -0.96 | PDE Loss:  -1.0587 | Function Loss:  -1.6517\n",
      "################################  331  ################################\n",
      "Total loss:  -0.961 | PDE Loss:  -1.0622 | Function Loss:  -1.643\n",
      "################################  332  ################################\n",
      "Total loss:  -0.9644 | PDE Loss:  -1.0606 | Function Loss:  -1.6663\n",
      "################################  333  ################################\n",
      "Total loss:  -0.969 | PDE Loss:  -1.0637 | Function Loss:  -1.677\n",
      "################################  334  ################################\n",
      "Total loss:  -0.9733 | PDE Loss:  -1.0629 | Function Loss:  -1.703\n",
      "################################  335  ################################\n",
      "Total loss:  -0.9766 | PDE Loss:  -1.065 | Function Loss:  -1.7115\n",
      "################################  336  ################################\n",
      "Total loss:  -0.9789 | PDE Loss:  -1.0651 | Function Loss:  -1.7233\n",
      "################################  337  ################################\n",
      "Total loss:  -0.9803 | PDE Loss:  -1.0664 | Function Loss:  -1.7256\n",
      "################################  338  ################################\n",
      "Total loss:  -0.9812 | PDE Loss:  -1.0672 | Function Loss:  -1.7266\n",
      "################################  339  ################################\n",
      "Total loss:  -0.9816 | PDE Loss:  -1.0677 | Function Loss:  -1.7267\n",
      "################################  340  ################################\n",
      "Total loss:  -0.9816 | PDE Loss:  -1.0691 | Function Loss:  -1.7207\n",
      "################################  341  ################################\n",
      "Total loss:  -0.9812 | PDE Loss:  -1.069 | Function Loss:  -1.7188\n",
      "################################  342  ################################\n",
      "Total loss:  -0.9802 | PDE Loss:  -1.071 | Function Loss:  -1.7047\n",
      "################################  343  ################################\n",
      "Total loss:  -0.9785 | PDE Loss:  -1.0702 | Function Loss:  -1.6986\n",
      "################################  344  ################################\n",
      "Total loss:  -0.9761 | PDE Loss:  -1.0728 | Function Loss:  -1.6756\n",
      "################################  345  ################################\n",
      "Total loss:  -0.9738 | PDE Loss:  -1.0714 | Function Loss:  -1.6698\n",
      "################################  346  ################################\n",
      "Total loss:  -0.9728 | PDE Loss:  -1.0746 | Function Loss:  -1.6528\n",
      "################################  347  ################################\n",
      "Total loss:  -0.9743 | PDE Loss:  -1.0729 | Function Loss:  -1.6663\n",
      "################################  348  ################################\n",
      "Total loss:  -0.9779 | PDE Loss:  -1.076 | Function Loss:  -1.6725\n",
      "################################  349  ################################\n",
      "Total loss:  -0.9826 | PDE Loss:  -1.0749 | Function Loss:  -1.7005\n",
      "################################  350  ################################\n",
      "Total loss:  -0.9867 | PDE Loss:  -1.0771 | Function Loss:  -1.7125\n",
      "################################  351  ################################\n",
      "Total loss:  -0.9898 | PDE Loss:  -1.0769 | Function Loss:  -1.7304\n",
      "################################  352  ################################\n",
      "Total loss:  -0.9919 | PDE Loss:  -1.0783 | Function Loss:  -1.7354\n",
      "################################  353  ################################\n",
      "Total loss:  -0.9932 | PDE Loss:  -1.0788 | Function Loss:  -1.7407\n",
      "################################  354  ################################\n",
      "Total loss:  -0.994 | PDE Loss:  -1.0795 | Function Loss:  -1.7416\n",
      "################################  355  ################################\n",
      "Total loss:  -0.9944 | PDE Loss:  -1.0805 | Function Loss:  -1.7393\n",
      "################################  356  ################################\n",
      "Total loss:  -0.9944 | PDE Loss:  -1.0807 | Function Loss:  -1.7385\n",
      "################################  357  ################################\n",
      "Total loss:  -0.994 | PDE Loss:  -1.0822 | Function Loss:  -1.7295\n",
      "################################  358  ################################\n",
      "Total loss:  -0.993 | PDE Loss:  -1.0819 | Function Loss:  -1.7255\n",
      "################################  359  ################################\n",
      "Total loss:  -0.9912 | PDE Loss:  -1.084 | Function Loss:  -1.7074\n",
      "################################  360  ################################\n",
      "Total loss:  -0.9888 | PDE Loss:  -1.083 | Function Loss:  -1.6988\n",
      "################################  361  ################################\n",
      "Total loss:  -0.9863 | PDE Loss:  -1.0856 | Function Loss:  -1.6755\n",
      "################################  362  ################################\n",
      "Total loss:  -0.985 | PDE Loss:  -1.0842 | Function Loss:  -1.6748\n",
      "################################  363  ################################\n",
      "Total loss:  -0.986 | PDE Loss:  -1.0871 | Function Loss:  -1.6685\n",
      "################################  364  ################################\n",
      "Total loss:  -0.9896 | PDE Loss:  -1.0858 | Function Loss:  -1.6913\n",
      "################################  365  ################################\n",
      "Total loss:  -0.9942 | PDE Loss:  -1.0884 | Function Loss:  -1.7042\n",
      "################################  366  ################################\n",
      "Total loss:  -0.9985 | PDE Loss:  -1.0877 | Function Loss:  -1.7296\n",
      "################################  367  ################################\n",
      "Total loss:  -1.0017 | PDE Loss:  -1.0895 | Function Loss:  -1.7394\n",
      "################################  368  ################################\n",
      "Total loss:  -1.0039 | PDE Loss:  -1.0896 | Function Loss:  -1.7512\n",
      "################################  369  ################################\n",
      "Total loss:  -1.0054 | PDE Loss:  -1.0907 | Function Loss:  -1.7542\n",
      "################################  370  ################################\n",
      "Total loss:  -1.0062 | PDE Loss:  -1.0913 | Function Loss:  -1.756\n",
      "################################  371  ################################\n",
      "Total loss:  -1.0067 | PDE Loss:  -1.0919 | Function Loss:  -1.7562\n",
      "################################  372  ################################\n",
      "Total loss:  -1.0068 | PDE Loss:  -1.093 | Function Loss:  -1.7519\n",
      "################################  373  ################################\n",
      "Total loss:  -1.0066 | PDE Loss:  -1.0931 | Function Loss:  -1.75\n",
      "################################  374  ################################\n",
      "Total loss:  -1.0057 | PDE Loss:  -1.0946 | Function Loss:  -1.7384\n",
      "################################  375  ################################\n",
      "Total loss:  -1.0042 | PDE Loss:  -1.0942 | Function Loss:  -1.7317\n",
      "################################  376  ################################\n",
      "Total loss:  -1.0017 | PDE Loss:  -1.0963 | Function Loss:  -1.71\n",
      "################################  377  ################################\n",
      "Total loss:  -0.9988 | PDE Loss:  -1.0953 | Function Loss:  -1.6996\n",
      "################################  378  ################################\n",
      "Total loss:  -0.9966 | PDE Loss:  -1.098 | Function Loss:  -1.6783\n",
      "################################  379  ################################\n",
      "Total loss:  -0.9968 | PDE Loss:  -1.0966 | Function Loss:  -1.6842\n",
      "################################  380  ################################\n",
      "Total loss:  -0.9997 | PDE Loss:  -1.0994 | Function Loss:  -1.6878\n",
      "################################  381  ################################\n",
      "Total loss:  -1.0044 | PDE Loss:  -1.0983 | Function Loss:  -1.7158\n",
      "################################  382  ################################\n",
      "Total loss:  -1.0092 | PDE Loss:  -1.1005 | Function Loss:  -1.7313\n",
      "################################  383  ################################\n",
      "Total loss:  -1.013 | PDE Loss:  -1.1002 | Function Loss:  -1.7529\n",
      "################################  384  ################################\n",
      "Total loss:  -1.0156 | PDE Loss:  -1.1017 | Function Loss:  -1.7605\n",
      "################################  385  ################################\n",
      "Total loss:  -1.0172 | PDE Loss:  -1.102 | Function Loss:  -1.7681\n",
      "################################  386  ################################\n",
      "Total loss:  -1.0182 | PDE Loss:  -1.1029 | Function Loss:  -1.7698\n",
      "################################  387  ################################\n",
      "Total loss:  -1.0188 | PDE Loss:  -1.1037 | Function Loss:  -1.7693\n",
      "################################  388  ################################\n",
      "Total loss:  -1.019 | PDE Loss:  -1.1041 | Function Loss:  -1.7687\n",
      "################################  389  ################################\n",
      "Total loss:  -1.0189 | PDE Loss:  -1.1054 | Function Loss:  -1.762\n",
      "################################  390  ################################\n",
      "Total loss:  -1.0181 | PDE Loss:  -1.1054 | Function Loss:  -1.7582\n",
      "################################  391  ################################\n",
      "Total loss:  -1.0166 | PDE Loss:  -1.1071 | Function Loss:  -1.7425\n",
      "################################  392  ################################\n",
      "Total loss:  -1.0142 | PDE Loss:  -1.1065 | Function Loss:  -1.7322\n",
      "################################  393  ################################\n",
      "Total loss:  -1.0111 | PDE Loss:  -1.1088 | Function Loss:  -1.7069\n",
      "################################  394  ################################\n",
      "Total loss:  -1.0083 | PDE Loss:  -1.1077 | Function Loss:  -1.6977\n",
      "################################  395  ################################\n",
      "Total loss:  -1.0077 | PDE Loss:  -1.1104 | Function Loss:  -1.6841\n",
      "################################  396  ################################\n",
      "Total loss:  -1.0102 | PDE Loss:  -1.1091 | Function Loss:  -1.7011\n",
      "################################  397  ################################\n",
      "Total loss:  -1.0149 | PDE Loss:  -1.1117 | Function Loss:  -1.7146\n",
      "################################  398  ################################\n",
      "Total loss:  -1.0201 | PDE Loss:  -1.111 | Function Loss:  -1.744\n",
      "################################  399  ################################\n",
      "Total loss:  -1.0243 | PDE Loss:  -1.1129 | Function Loss:  -1.7581\n",
      "################################  400  ################################\n",
      "Total loss:  -1.0271 | PDE Loss:  -1.1129 | Function Loss:  -1.7738\n",
      "################################  401  ################################\n",
      "Total loss:  -1.029 | PDE Loss:  -1.1141 | Function Loss:  -1.7785\n",
      "################################  402  ################################\n",
      "Total loss:  -1.0301 | PDE Loss:  -1.1147 | Function Loss:  -1.7823\n",
      "################################  403  ################################\n",
      "Total loss:  -1.0308 | PDE Loss:  -1.1154 | Function Loss:  -1.7828\n",
      "################################  404  ################################\n",
      "Total loss:  -1.0311 | PDE Loss:  -1.1164 | Function Loss:  -1.78\n",
      "################################  405  ################################\n",
      "Total loss:  -1.031 | PDE Loss:  -1.1167 | Function Loss:  -1.7782\n",
      "################################  406  ################################\n",
      "Total loss:  -1.0304 | PDE Loss:  -1.118 | Function Loss:  -1.7685\n",
      "################################  407  ################################\n",
      "Total loss:  -1.029 | PDE Loss:  -1.1179 | Function Loss:  -1.7615\n",
      "################################  408  ################################\n",
      "Total loss:  -1.0266 | PDE Loss:  -1.1198 | Function Loss:  -1.7407\n",
      "################################  409  ################################\n",
      "Total loss:  -1.0233 | PDE Loss:  -1.1191 | Function Loss:  -1.7266\n",
      "################################  410  ################################\n",
      "Total loss:  -1.0199 | PDE Loss:  -1.1215 | Function Loss:  -1.7007\n",
      "################################  411  ################################\n",
      "Total loss:  -1.0186 | PDE Loss:  -1.1204 | Function Loss:  -1.6986\n",
      "################################  412  ################################\n",
      "Total loss:  -1.0206 | PDE Loss:  -1.123 | Function Loss:  -1.6981\n",
      "################################  413  ################################\n",
      "Total loss:  -1.0254 | PDE Loss:  -1.122 | Function Loss:  -1.7257\n",
      "################################  414  ################################\n",
      "Total loss:  -1.031 | PDE Loss:  -1.1243 | Function Loss:  -1.7446\n",
      "################################  415  ################################\n",
      "Total loss:  -1.0355 | PDE Loss:  -1.124 | Function Loss:  -1.7703\n",
      "################################  416  ################################\n",
      "Total loss:  -1.0387 | PDE Loss:  -1.1255 | Function Loss:  -1.7807\n",
      "################################  417  ################################\n",
      "Total loss:  -1.0408 | PDE Loss:  -1.1259 | Function Loss:  -1.7905\n",
      "################################  418  ################################\n",
      "Total loss:  -1.042 | PDE Loss:  -1.1268 | Function Loss:  -1.7929\n",
      "################################  419  ################################\n",
      "Total loss:  -1.0427 | PDE Loss:  -1.1276 | Function Loss:  -1.7935\n",
      "################################  420  ################################\n",
      "Total loss:  -1.0431 | PDE Loss:  -1.1282 | Function Loss:  -1.793\n",
      "################################  421  ################################\n",
      "Total loss:  -1.0431 | PDE Loss:  -1.1293 | Function Loss:  -1.7876\n",
      "################################  422  ################################\n",
      "Total loss:  -1.0425 | PDE Loss:  -1.1295 | Function Loss:  -1.7836\n",
      "################################  423  ################################\n",
      "Total loss:  -1.0411 | PDE Loss:  -1.131 | Function Loss:  -1.7692\n",
      "################################  424  ################################\n",
      "Total loss:  -1.0387 | PDE Loss:  -1.1307 | Function Loss:  -1.7575\n",
      "################################  425  ################################\n",
      "Total loss:  -1.0351 | PDE Loss:  -1.1328 | Function Loss:  -1.7308\n",
      "################################  426  ################################\n",
      "Total loss:  -1.0314 | PDE Loss:  -1.1319 | Function Loss:  -1.7161\n",
      "################################  427  ################################\n",
      "Total loss:  -1.0295 | PDE Loss:  -1.1345 | Function Loss:  -1.6976\n",
      "################################  428  ################################\n",
      "Total loss:  -1.0314 | PDE Loss:  -1.1334 | Function Loss:  -1.7105\n",
      "################################  429  ################################\n",
      "Total loss:  -1.0364 | PDE Loss:  -1.1359 | Function Loss:  -1.725\n",
      "################################  430  ################################\n",
      "Total loss:  -1.0422 | PDE Loss:  -1.1352 | Function Loss:  -1.7572\n",
      "################################  431  ################################\n",
      "Total loss:  -1.0471 | PDE Loss:  -1.1372 | Function Loss:  -1.7747\n",
      "################################  432  ################################\n",
      "Total loss:  -1.0505 | PDE Loss:  -1.1372 | Function Loss:  -1.7927\n",
      "################################  433  ################################\n",
      "Total loss:  -1.0526 | PDE Loss:  -1.1385 | Function Loss:  -1.7987\n",
      "################################  434  ################################\n",
      "Total loss:  -1.0539 | PDE Loss:  -1.1391 | Function Loss:  -1.8033\n",
      "################################  435  ################################\n",
      "Total loss:  -1.0547 | PDE Loss:  -1.1399 | Function Loss:  -1.804\n",
      "################################  436  ################################\n",
      "Total loss:  -1.0551 | PDE Loss:  -1.1408 | Function Loss:  -1.8019\n",
      "################################  437  ################################\n",
      "Total loss:  -1.055 | PDE Loss:  -1.1412 | Function Loss:  -1.8\n",
      "################################  438  ################################\n",
      "Total loss:  -1.0545 | PDE Loss:  -1.1425 | Function Loss:  -1.7909\n",
      "################################  439  ################################\n",
      "Total loss:  -1.0531 | PDE Loss:  -1.1425 | Function Loss:  -1.7833\n",
      "################################  440  ################################\n",
      "Total loss:  -1.0506 | PDE Loss:  -1.1443 | Function Loss:  -1.7623\n",
      "################################  441  ################################\n",
      "Total loss:  -1.0468 | PDE Loss:  -1.1438 | Function Loss:  -1.7453\n",
      "################################  442  ################################\n",
      "Total loss:  -1.0427 | PDE Loss:  -1.1461 | Function Loss:  -1.7163\n",
      "################################  443  ################################\n",
      "Total loss:  -1.0405 | PDE Loss:  -1.1451 | Function Loss:  -1.7099\n",
      "################################  444  ################################\n",
      "Total loss:  -1.0422 | PDE Loss:  -1.1477 | Function Loss:  -1.7085\n",
      "################################  445  ################################\n",
      "Total loss:  -1.0475 | PDE Loss:  -1.1468 | Function Loss:  -1.7371\n",
      "################################  446  ################################\n",
      "Total loss:  -1.0537 | PDE Loss:  -1.149 | Function Loss:  -1.7591\n",
      "################################  447  ################################\n",
      "Total loss:  -1.0588 | PDE Loss:  -1.1488 | Function Loss:  -1.7867\n",
      "################################  448  ################################\n",
      "Total loss:  -1.0623 | PDE Loss:  -1.1503 | Function Loss:  -1.7987\n",
      "################################  449  ################################\n",
      "Total loss:  -1.0645 | PDE Loss:  -1.1507 | Function Loss:  -1.8089\n",
      "################################  450  ################################\n",
      "Total loss:  -1.0658 | PDE Loss:  -1.1517 | Function Loss:  -1.8116\n",
      "################################  451  ################################\n",
      "Total loss:  -1.0666 | PDE Loss:  -1.1525 | Function Loss:  -1.8126\n",
      "################################  452  ################################\n",
      "Total loss:  -1.067 | PDE Loss:  -1.1531 | Function Loss:  -1.812\n",
      "################################  453  ################################\n",
      "Total loss:  -1.067 | PDE Loss:  -1.1542 | Function Loss:  -1.8071\n",
      "################################  454  ################################\n",
      "Total loss:  -1.0664 | PDE Loss:  -1.1545 | Function Loss:  -1.8028\n",
      "################################  455  ################################\n",
      "Total loss:  -1.065 | PDE Loss:  -1.156 | Function Loss:  -1.7887\n",
      "################################  456  ################################\n",
      "Total loss:  -1.0624 | PDE Loss:  -1.1559 | Function Loss:  -1.7755\n",
      "################################  457  ################################\n",
      "Total loss:  -1.0584 | PDE Loss:  -1.1579 | Function Loss:  -1.7473\n",
      "################################  458  ################################\n",
      "Total loss:  -1.0539 | PDE Loss:  -1.1571 | Function Loss:  -1.7287\n",
      "################################  459  ################################\n",
      "Total loss:  -1.0513 | PDE Loss:  -1.1596 | Function Loss:  -1.7076\n",
      "################################  460  ################################\n",
      "Total loss:  -1.053 | PDE Loss:  -1.1585 | Function Loss:  -1.7193\n",
      "################################  461  ################################\n",
      "Total loss:  -1.0585 | PDE Loss:  -1.161 | Function Loss:  -1.7361\n",
      "################################  462  ################################\n",
      "Total loss:  -1.0651 | PDE Loss:  -1.1604 | Function Loss:  -1.7705\n",
      "################################  463  ################################\n",
      "Total loss:  -1.0704 | PDE Loss:  -1.1623 | Function Loss:  -1.7901\n",
      "################################  464  ################################\n",
      "Total loss:  -1.074 | PDE Loss:  -1.1625 | Function Loss:  -1.8087\n",
      "################################  465  ################################\n",
      "Total loss:  -1.0763 | PDE Loss:  -1.1637 | Function Loss:  -1.8151\n",
      "################################  466  ################################\n",
      "Total loss:  -1.0776 | PDE Loss:  -1.1643 | Function Loss:  -1.8198\n",
      "################################  467  ################################\n",
      "Total loss:  -1.0784 | PDE Loss:  -1.1651 | Function Loss:  -1.8206\n",
      "################################  468  ################################\n",
      "Total loss:  -1.0788 | PDE Loss:  -1.166 | Function Loss:  -1.8188\n",
      "################################  469  ################################\n",
      "Total loss:  -1.0788 | PDE Loss:  -1.1665 | Function Loss:  -1.8167\n",
      "################################  470  ################################\n",
      "Total loss:  -1.0783 | PDE Loss:  -1.1678 | Function Loss:  -1.8082\n",
      "################################  471  ################################\n",
      "Total loss:  -1.0769 | PDE Loss:  -1.168 | Function Loss:  -1.8\n",
      "################################  472  ################################\n",
      "Total loss:  -1.0742 | PDE Loss:  -1.1697 | Function Loss:  -1.7788\n",
      "################################  473  ################################\n",
      "Total loss:  -1.07 | PDE Loss:  -1.1693 | Function Loss:  -1.7594\n",
      "################################  474  ################################\n",
      "Total loss:  -1.0651 | PDE Loss:  -1.1715 | Function Loss:  -1.728\n",
      "################################  475  ################################\n",
      "Total loss:  -1.0622 | PDE Loss:  -1.1705 | Function Loss:  -1.7181\n",
      "################################  476  ################################\n",
      "Total loss:  -1.0637 | PDE Loss:  -1.173 | Function Loss:  -1.7164\n",
      "################################  477  ################################\n",
      "Total loss:  -1.0695 | PDE Loss:  -1.1722 | Function Loss:  -1.7463\n",
      "################################  478  ################################\n",
      "Total loss:  -1.0764 | PDE Loss:  -1.1744 | Function Loss:  -1.7709\n",
      "################################  479  ################################\n",
      "Total loss:  -1.0819 | PDE Loss:  -1.1742 | Function Loss:  -1.7998\n",
      "################################  480  ################################\n",
      "Total loss:  -1.0856 | PDE Loss:  -1.1758 | Function Loss:  -1.8125\n",
      "################################  481  ################################\n",
      "Total loss:  -1.0879 | PDE Loss:  -1.1762 | Function Loss:  -1.8229\n",
      "################################  482  ################################\n",
      "Total loss:  -1.0892 | PDE Loss:  -1.1772 | Function Loss:  -1.8258\n",
      "################################  483  ################################\n",
      "Total loss:  -1.09 | PDE Loss:  -1.1779 | Function Loss:  -1.8269\n",
      "################################  484  ################################\n",
      "Total loss:  -1.0905 | PDE Loss:  -1.1786 | Function Loss:  -1.8264\n",
      "################################  485  ################################\n",
      "Total loss:  -1.0905 | PDE Loss:  -1.1797 | Function Loss:  -1.822\n",
      "################################  486  ################################\n",
      "Total loss:  -1.0901 | PDE Loss:  -1.1801 | Function Loss:  -1.8178\n",
      "################################  487  ################################\n",
      "Total loss:  -1.0887 | PDE Loss:  -1.1815 | Function Loss:  -1.8045\n",
      "################################  488  ################################\n",
      "Total loss:  -1.0861 | PDE Loss:  -1.1815 | Function Loss:  -1.791\n",
      "################################  489  ################################\n",
      "Total loss:  -1.0817 | PDE Loss:  -1.1834 | Function Loss:  -1.7623\n",
      "################################  490  ################################\n",
      "Total loss:  -1.0765 | PDE Loss:  -1.1827 | Function Loss:  -1.7403\n",
      "################################  491  ################################\n",
      "Total loss:  -1.0729 | PDE Loss:  -1.185 | Function Loss:  -1.7157\n",
      "################################  492  ################################\n",
      "Total loss:  -1.0741 | PDE Loss:  -1.1841 | Function Loss:  -1.7244\n",
      "################################  493  ################################\n",
      "Total loss:  -1.0798 | PDE Loss:  -1.1865 | Function Loss:  -1.7417\n",
      "################################  494  ################################\n",
      "Total loss:  -1.087 | PDE Loss:  -1.186 | Function Loss:  -1.7778\n",
      "################################  495  ################################\n",
      "Total loss:  -1.0928 | PDE Loss:  -1.1879 | Function Loss:  -1.7994\n",
      "################################  496  ################################\n",
      "Total loss:  -1.0967 | PDE Loss:  -1.188 | Function Loss:  -1.8191\n",
      "################################  497  ################################\n",
      "Total loss:  -1.0991 | PDE Loss:  -1.1893 | Function Loss:  -1.8262\n",
      "################################  498  ################################\n",
      "Total loss:  -1.1005 | PDE Loss:  -1.1898 | Function Loss:  -1.8314\n",
      "################################  499  ################################\n",
      "Total loss:  -1.1014 | PDE Loss:  -1.1907 | Function Loss:  -1.8324\n",
      "################################  500  ################################\n",
      "Total loss:  -1.1019 | PDE Loss:  -1.1915 | Function Loss:  -1.8313\n",
      "################################  501  ################################\n",
      "Total loss:  -1.1021 | PDE Loss:  -1.1921 | Function Loss:  -1.8296\n",
      "################################  502  ################################\n",
      "Total loss:  -1.1017 | PDE Loss:  -1.1933 | Function Loss:  -1.8226\n",
      "################################  503  ################################\n",
      "Total loss:  -1.1006 | PDE Loss:  -1.1936 | Function Loss:  -1.8156\n",
      "################################  504  ################################\n",
      "Total loss:  -1.0982 | PDE Loss:  -1.1952 | Function Loss:  -1.7969\n",
      "################################  505  ################################\n",
      "Total loss:  -1.0941 | PDE Loss:  -1.1949 | Function Loss:  -1.7779\n",
      "################################  506  ################################\n",
      "Total loss:  -1.0886 | PDE Loss:  -1.1969 | Function Loss:  -1.7445\n",
      "################################  507  ################################\n",
      "Total loss:  -1.084 | PDE Loss:  -1.196 | Function Loss:  -1.7271\n",
      "################################  508  ################################\n",
      "Total loss:  -1.0837 | PDE Loss:  -1.1985 | Function Loss:  -1.7177\n",
      "################################  509  ################################\n",
      "Total loss:  -1.0889 | PDE Loss:  -1.1976 | Function Loss:  -1.7437\n",
      "################################  510  ################################\n",
      "Total loss:  -1.0963 | PDE Loss:  -1.1999 | Function Loss:  -1.7697\n",
      "################################  511  ################################\n",
      "Total loss:  -1.1028 | PDE Loss:  -1.1996 | Function Loss:  -1.8021\n",
      "################################  512  ################################\n",
      "Total loss:  -1.1072 | PDE Loss:  -1.2013 | Function Loss:  -1.8178\n",
      "################################  513  ################################\n",
      "Total loss:  -1.1099 | PDE Loss:  -1.2016 | Function Loss:  -1.8304\n",
      "################################  514  ################################\n",
      "Total loss:  -1.1115 | PDE Loss:  -1.2027 | Function Loss:  -1.8342\n",
      "################################  515  ################################\n",
      "Total loss:  -1.1125 | PDE Loss:  -1.2033 | Function Loss:  -1.8365\n",
      "################################  516  ################################\n",
      "Total loss:  -1.113 | PDE Loss:  -1.2041 | Function Loss:  -1.8365\n",
      "################################  517  ################################\n",
      "Total loss:  -1.1133 | PDE Loss:  -1.205 | Function Loss:  -1.8337\n",
      "################################  518  ################################\n",
      "Total loss:  -1.1132 | PDE Loss:  -1.2055 | Function Loss:  -1.831\n",
      "################################  519  ################################\n",
      "Total loss:  -1.1124 | PDE Loss:  -1.2068 | Function Loss:  -1.8215\n",
      "################################  520  ################################\n",
      "Total loss:  -1.1105 | PDE Loss:  -1.2069 | Function Loss:  -1.8115\n",
      "################################  521  ################################\n",
      "Total loss:  -1.107 | PDE Loss:  -1.2086 | Function Loss:  -1.7875\n",
      "################################  522  ################################\n",
      "Total loss:  -1.1016 | PDE Loss:  -1.2081 | Function Loss:  -1.7642\n",
      "################################  523  ################################\n",
      "Total loss:  -1.0958 | PDE Loss:  -1.2103 | Function Loss:  -1.7309\n",
      "################################  524  ################################\n",
      "Total loss:  -1.0934 | PDE Loss:  -1.2093 | Function Loss:  -1.7236\n",
      "################################  525  ################################\n",
      "Total loss:  -1.0967 | PDE Loss:  -1.2118 | Function Loss:  -1.7298\n",
      "################################  526  ################################\n",
      "Total loss:  -1.1041 | PDE Loss:  -1.211 | Function Loss:  -1.765\n",
      "################################  527  ################################\n",
      "Total loss:  -1.1114 | PDE Loss:  -1.2131 | Function Loss:  -1.7915\n",
      "################################  528  ################################\n",
      "Total loss:  -1.1167 | PDE Loss:  -1.213 | Function Loss:  -1.8178\n",
      "################################  529  ################################\n",
      "Total loss:  -1.12 | PDE Loss:  -1.2145 | Function Loss:  -1.8287\n",
      "################################  530  ################################\n",
      "Total loss:  -1.1219 | PDE Loss:  -1.2149 | Function Loss:  -1.8369\n",
      "################################  531  ################################\n",
      "Total loss:  -1.1231 | PDE Loss:  -1.2158 | Function Loss:  -1.839\n",
      "################################  532  ################################\n",
      "Total loss:  -1.1238 | PDE Loss:  -1.2166 | Function Loss:  -1.8398\n",
      "################################  533  ################################\n",
      "Total loss:  -1.1242 | PDE Loss:  -1.2172 | Function Loss:  -1.8392\n",
      "################################  534  ################################\n",
      "Total loss:  -1.1244 | PDE Loss:  -1.2183 | Function Loss:  -1.8355\n",
      "################################  535  ################################\n",
      "Total loss:  -1.124 | PDE Loss:  -1.2187 | Function Loss:  -1.832\n",
      "################################  536  ################################\n",
      "Total loss:  -1.1228 | PDE Loss:  -1.22 | Function Loss:  -1.8207\n",
      "################################  537  ################################\n",
      "Total loss:  -1.1203 | PDE Loss:  -1.22 | Function Loss:  -1.8083\n",
      "################################  538  ################################\n",
      "Total loss:  -1.1158 | PDE Loss:  -1.2217 | Function Loss:  -1.7804\n",
      "################################  539  ################################\n",
      "Total loss:  -1.1096 | PDE Loss:  -1.2211 | Function Loss:  -1.7549\n",
      "################################  540  ################################\n",
      "Total loss:  -1.1042 | PDE Loss:  -1.2233 | Function Loss:  -1.7241\n",
      "################################  541  ################################\n",
      "Total loss:  -1.1039 | PDE Loss:  -1.2223 | Function Loss:  -1.7262\n",
      "################################  542  ################################\n",
      "Total loss:  -1.1095 | PDE Loss:  -1.2248 | Function Loss:  -1.742\n",
      "################################  543  ################################\n",
      "Total loss:  -1.1176 | PDE Loss:  -1.2241 | Function Loss:  -1.7801\n",
      "################################  544  ################################\n",
      "Total loss:  -1.1244 | PDE Loss:  -1.2261 | Function Loss:  -1.8047\n",
      "################################  545  ################################\n",
      "Total loss:  -1.1289 | PDE Loss:  -1.2261 | Function Loss:  -1.8266\n",
      "################################  546  ################################\n",
      "Total loss:  -1.1316 | PDE Loss:  -1.2274 | Function Loss:  -1.8348\n",
      "################################  547  ################################\n",
      "Total loss:  -1.1331 | PDE Loss:  -1.2279 | Function Loss:  -1.8409\n",
      "################################  548  ################################\n",
      "Total loss:  -1.1341 | PDE Loss:  -1.2288 | Function Loss:  -1.8422\n",
      "################################  549  ################################\n",
      "Total loss:  -1.1347 | PDE Loss:  -1.2295 | Function Loss:  -1.8423\n",
      "################################  550  ################################\n",
      "Total loss:  -1.1351 | PDE Loss:  -1.2302 | Function Loss:  -1.8415\n",
      "################################  551  ################################\n",
      "Total loss:  -1.1352 | PDE Loss:  -1.2312 | Function Loss:  -1.8377\n",
      "################################  552  ################################\n",
      "Total loss:  -1.1347 | PDE Loss:  -1.2315 | Function Loss:  -1.8339\n",
      "################################  553  ################################\n",
      "Total loss:  -1.1333 | PDE Loss:  -1.2329 | Function Loss:  -1.822\n",
      "################################  554  ################################\n",
      "Total loss:  -1.1304 | PDE Loss:  -1.2328 | Function Loss:  -1.8085\n",
      "################################  555  ################################\n",
      "Total loss:  -1.1254 | PDE Loss:  -1.2345 | Function Loss:  -1.7787\n",
      "################################  556  ################################\n",
      "Total loss:  -1.1187 | PDE Loss:  -1.2338 | Function Loss:  -1.7519\n",
      "################################  557  ################################\n",
      "Total loss:  -1.1134 | PDE Loss:  -1.2361 | Function Loss:  -1.7222\n",
      "################################  558  ################################\n",
      "Total loss:  -1.114 | PDE Loss:  -1.235 | Function Loss:  -1.7282\n",
      "################################  559  ################################\n",
      "Total loss:  -1.1206 | PDE Loss:  -1.2375 | Function Loss:  -1.748\n",
      "################################  560  ################################\n",
      "Total loss:  -1.1291 | PDE Loss:  -1.2369 | Function Loss:  -1.787\n",
      "################################  561  ################################\n",
      "Total loss:  -1.1357 | PDE Loss:  -1.2388 | Function Loss:  -1.8108\n",
      "################################  562  ################################\n",
      "Total loss:  -1.1399 | PDE Loss:  -1.2388 | Function Loss:  -1.831\n",
      "################################  563  ################################\n",
      "Total loss:  -1.1423 | PDE Loss:  -1.24 | Function Loss:  -1.8382\n",
      "################################  564  ################################\n",
      "Total loss:  -1.1438 | PDE Loss:  -1.2405 | Function Loss:  -1.8435\n",
      "################################  565  ################################\n",
      "Total loss:  -1.1447 | PDE Loss:  -1.2414 | Function Loss:  -1.8447\n",
      "################################  566  ################################\n",
      "Total loss:  -1.1453 | PDE Loss:  -1.2421 | Function Loss:  -1.8447\n",
      "################################  567  ################################\n",
      "Total loss:  -1.1457 | PDE Loss:  -1.2427 | Function Loss:  -1.8441\n",
      "################################  568  ################################\n",
      "Total loss:  -1.1458 | PDE Loss:  -1.2437 | Function Loss:  -1.8406\n",
      "################################  569  ################################\n",
      "Total loss:  -1.1454 | PDE Loss:  -1.2441 | Function Loss:  -1.8374\n",
      "################################  570  ################################\n",
      "Total loss:  -1.1441 | PDE Loss:  -1.2453 | Function Loss:  -1.8263\n",
      "################################  571  ################################\n",
      "Total loss:  -1.1413 | PDE Loss:  -1.2452 | Function Loss:  -1.8134\n",
      "################################  572  ################################\n",
      "Total loss:  -1.1362 | PDE Loss:  -1.2469 | Function Loss:  -1.7841\n",
      "################################  573  ################################\n",
      "Total loss:  -1.1292 | PDE Loss:  -1.2462 | Function Loss:  -1.756\n",
      "################################  574  ################################\n",
      "Total loss:  -1.123 | PDE Loss:  -1.2485 | Function Loss:  -1.7235\n",
      "################################  575  ################################\n",
      "Total loss:  -1.123 | PDE Loss:  -1.2474 | Function Loss:  -1.7266\n",
      "################################  576  ################################\n",
      "Total loss:  -1.1295 | PDE Loss:  -1.2499 | Function Loss:  -1.7457\n",
      "################################  577  ################################\n",
      "Total loss:  -1.1384 | PDE Loss:  -1.2492 | Function Loss:  -1.786\n",
      "################################  578  ################################\n",
      "Total loss:  -1.1455 | PDE Loss:  -1.2511 | Function Loss:  -1.8111\n",
      "################################  579  ################################\n",
      "Total loss:  -1.1499 | PDE Loss:  -1.2511 | Function Loss:  -1.8322\n",
      "################################  580  ################################\n",
      "Total loss:  -1.1525 | PDE Loss:  -1.2524 | Function Loss:  -1.8398\n",
      "################################  581  ################################\n",
      "Total loss:  -1.154 | PDE Loss:  -1.2528 | Function Loss:  -1.8456\n",
      "################################  582  ################################\n",
      "Total loss:  -1.1549 | PDE Loss:  -1.2536 | Function Loss:  -1.8468\n",
      "################################  583  ################################\n",
      "Total loss:  -1.1556 | PDE Loss:  -1.2543 | Function Loss:  -1.8473\n",
      "################################  584  ################################\n",
      "Total loss:  -1.156 | PDE Loss:  -1.255 | Function Loss:  -1.847\n",
      "################################  585  ################################\n",
      "Total loss:  -1.1562 | PDE Loss:  -1.2559 | Function Loss:  -1.8444\n",
      "################################  586  ################################\n",
      "Total loss:  -1.1561 | PDE Loss:  -1.2563 | Function Loss:  -1.8421\n",
      "################################  587  ################################\n",
      "Total loss:  -1.1552 | PDE Loss:  -1.2574 | Function Loss:  -1.8334\n",
      "################################  588  ################################\n",
      "Total loss:  -1.153 | PDE Loss:  -1.2574 | Function Loss:  -1.8231\n",
      "################################  589  ################################\n",
      "Total loss:  -1.1486 | PDE Loss:  -1.259 | Function Loss:  -1.7974\n",
      "################################  590  ################################\n",
      "Total loss:  -1.1417 | PDE Loss:  -1.2584 | Function Loss:  -1.7697\n",
      "################################  591  ################################\n",
      "Total loss:  -1.1341 | PDE Loss:  -1.2606 | Function Loss:  -1.7312\n",
      "################################  592  ################################\n",
      "Total loss:  -1.1311 | PDE Loss:  -1.2594 | Function Loss:  -1.7231\n",
      "################################  593  ################################\n",
      "Total loss:  -1.1358 | PDE Loss:  -1.262 | Function Loss:  -1.7341\n",
      "################################  594  ################################\n",
      "Total loss:  -1.1451 | PDE Loss:  -1.2612 | Function Loss:  -1.775\n",
      "################################  595  ################################\n",
      "Total loss:  -1.1534 | PDE Loss:  -1.2632 | Function Loss:  -1.804\n",
      "################################  596  ################################\n",
      "Total loss:  -1.1588 | PDE Loss:  -1.2631 | Function Loss:  -1.8296\n",
      "################################  597  ################################\n",
      "Total loss:  -1.162 | PDE Loss:  -1.2644 | Function Loss:  -1.8395\n",
      "################################  598  ################################\n",
      "Total loss:  -1.1638 | PDE Loss:  -1.2648 | Function Loss:  -1.8468\n",
      "################################  599  ################################\n",
      "Total loss:  -1.1649 | PDE Loss:  -1.2656 | Function Loss:  -1.8487\n",
      "################################  600  ################################\n",
      "Total loss:  -1.1656 | PDE Loss:  -1.2662 | Function Loss:  -1.85\n",
      "################################  601  ################################\n",
      "Total loss:  -1.1661 | PDE Loss:  -1.2669 | Function Loss:  -1.85\n",
      "################################  602  ################################\n",
      "Total loss:  -1.1665 | PDE Loss:  -1.2677 | Function Loss:  -1.8486\n",
      "################################  603  ################################\n",
      "Total loss:  -1.1666 | PDE Loss:  -1.2682 | Function Loss:  -1.8474\n",
      "################################  604  ################################\n",
      "Total loss:  -1.1663 | PDE Loss:  -1.2693 | Function Loss:  -1.8416\n",
      "################################  605  ################################\n",
      "Total loss:  -1.165 | PDE Loss:  -1.2694 | Function Loss:  -1.8354\n",
      "################################  606  ################################\n",
      "Total loss:  -1.1621 | PDE Loss:  -1.2708 | Function Loss:  -1.8167\n",
      "################################  607  ################################\n",
      "Total loss:  -1.1565 | PDE Loss:  -1.2703 | Function Loss:  -1.7939\n",
      "################################  608  ################################\n",
      "Total loss:  -1.1483 | PDE Loss:  -1.2725 | Function Loss:  -1.7529\n",
      "################################  609  ################################\n",
      "Total loss:  -1.141 | PDE Loss:  -1.2712 | Function Loss:  -1.7277\n",
      "################################  610  ################################\n",
      "Total loss:  -1.1405 | PDE Loss:  -1.2739 | Function Loss:  -1.718\n",
      "################################  611  ################################\n",
      "Total loss:  -1.1483 | PDE Loss:  -1.2727 | Function Loss:  -1.7517\n",
      "################################  612  ################################\n",
      "Total loss:  -1.1582 | PDE Loss:  -1.2751 | Function Loss:  -1.7852\n",
      "################################  613  ################################\n",
      "Total loss:  -1.1658 | PDE Loss:  -1.2747 | Function Loss:  -1.8199\n",
      "################################  614  ################################\n",
      "Total loss:  -1.1704 | PDE Loss:  -1.2763 | Function Loss:  -1.8352\n",
      "################################  615  ################################\n",
      "Total loss:  -1.1729 | PDE Loss:  -1.2764 | Function Loss:  -1.8465\n",
      "################################  616  ################################\n",
      "Total loss:  -1.1744 | PDE Loss:  -1.2774 | Function Loss:  -1.8497\n",
      "################################  617  ################################\n",
      "Total loss:  -1.1753 | PDE Loss:  -1.2779 | Function Loss:  -1.8523\n",
      "################################  618  ################################\n",
      "Total loss:  -1.176 | PDE Loss:  -1.2786 | Function Loss:  -1.8528\n",
      "################################  619  ################################\n",
      "Total loss:  -1.1765 | PDE Loss:  -1.2793 | Function Loss:  -1.8525\n",
      "################################  620  ################################\n",
      "Total loss:  -1.1768 | PDE Loss:  -1.2799 | Function Loss:  -1.8521\n",
      "################################  621  ################################\n",
      "Total loss:  -1.1769 | PDE Loss:  -1.2808 | Function Loss:  -1.849\n",
      "################################  622  ################################\n",
      "Total loss:  -1.1766 | PDE Loss:  -1.2811 | Function Loss:  -1.8463\n",
      "################################  623  ################################\n",
      "Total loss:  -1.1752 | PDE Loss:  -1.2824 | Function Loss:  -1.8356\n",
      "################################  624  ################################\n",
      "Total loss:  -1.1721 | PDE Loss:  -1.2822 | Function Loss:  -1.822\n",
      "################################  625  ################################\n",
      "Total loss:  -1.166 | PDE Loss:  -1.284 | Function Loss:  -1.7896\n",
      "################################  626  ################################\n",
      "Total loss:  -1.1571 | PDE Loss:  -1.283 | Function Loss:  -1.7561\n",
      "################################  627  ################################\n",
      "Total loss:  -1.1491 | PDE Loss:  -1.2856 | Function Loss:  -1.7183\n",
      "################################  628  ################################\n",
      "Total loss:  -1.1494 | PDE Loss:  -1.2841 | Function Loss:  -1.7236\n",
      "################################  629  ################################\n",
      "Total loss:  -1.1582 | PDE Loss:  -1.2868 | Function Loss:  -1.7494\n",
      "################################  630  ################################\n",
      "Total loss:  -1.1688 | PDE Loss:  -1.286 | Function Loss:  -1.7951\n",
      "################################  631  ################################\n",
      "Total loss:  -1.1764 | PDE Loss:  -1.2879 | Function Loss:  -1.8215\n",
      "################################  632  ################################\n",
      "Total loss:  -1.1809 | PDE Loss:  -1.2878 | Function Loss:  -1.8418\n",
      "################################  633  ################################\n",
      "Total loss:  -1.1833 | PDE Loss:  -1.289 | Function Loss:  -1.8486\n",
      "################################  634  ################################\n",
      "Total loss:  -1.1847 | PDE Loss:  -1.2894 | Function Loss:  -1.8538\n",
      "################################  635  ################################\n",
      "Total loss:  -1.1855 | PDE Loss:  -1.2902 | Function Loss:  -1.855\n",
      "################################  636  ################################\n",
      "Total loss:  -1.1862 | PDE Loss:  -1.2907 | Function Loss:  -1.8558\n",
      "################################  637  ################################\n",
      "Total loss:  -1.1867 | PDE Loss:  -1.2914 | Function Loss:  -1.8559\n",
      "################################  638  ################################\n",
      "Total loss:  -1.1871 | PDE Loss:  -1.2922 | Function Loss:  -1.8548\n",
      "################################  639  ################################\n",
      "Total loss:  -1.1873 | PDE Loss:  -1.2926 | Function Loss:  -1.8541\n",
      "################################  640  ################################\n",
      "Total loss:  -1.1871 | PDE Loss:  -1.2937 | Function Loss:  -1.8495\n",
      "################################  641  ################################\n",
      "Total loss:  -1.1861 | PDE Loss:  -1.2938 | Function Loss:  -1.8445\n",
      "################################  642  ################################\n",
      "Total loss:  -1.1835 | PDE Loss:  -1.2952 | Function Loss:  -1.8277\n",
      "################################  643  ################################\n",
      "Total loss:  -1.178 | PDE Loss:  -1.2948 | Function Loss:  -1.8055\n",
      "################################  644  ################################\n",
      "Total loss:  -1.1688 | PDE Loss:  -1.2969 | Function Loss:  -1.7616\n",
      "################################  645  ################################\n",
      "Total loss:  -1.1591 | PDE Loss:  -1.2955 | Function Loss:  -1.7284\n",
      "################################  646  ################################\n",
      "Total loss:  -1.1564 | PDE Loss:  -1.2984 | Function Loss:  -1.7109\n",
      "################################  647  ################################\n",
      "Total loss:  -1.1646 | PDE Loss:  -1.2969 | Function Loss:  -1.7452\n",
      "################################  648  ################################\n",
      "Total loss:  -1.1762 | PDE Loss:  -1.2995 | Function Loss:  -1.7833\n",
      "################################  649  ################################\n",
      "Total loss:  -1.1851 | PDE Loss:  -1.2989 | Function Loss:  -1.8226\n",
      "################################  650  ################################\n",
      "Total loss:  -1.1903 | PDE Loss:  -1.3006 | Function Loss:  -1.8398\n",
      "################################  651  ################################\n",
      "Total loss:  -1.1931 | PDE Loss:  -1.3006 | Function Loss:  -1.8521\n",
      "################################  652  ################################\n",
      "Total loss:  -1.1946 | PDE Loss:  -1.3016 | Function Loss:  -1.8554\n",
      "################################  653  ################################\n",
      "Total loss:  -1.1956 | PDE Loss:  -1.302 | Function Loss:  -1.8583\n",
      "################################  654  ################################\n",
      "Total loss:  -1.1962 | PDE Loss:  -1.3028 | Function Loss:  -1.8588\n",
      "################################  655  ################################\n",
      "Total loss:  -1.1968 | PDE Loss:  -1.3034 | Function Loss:  -1.859\n",
      "################################  656  ################################\n",
      "Total loss:  -1.1973 | PDE Loss:  -1.304 | Function Loss:  -1.859\n",
      "################################  657  ################################\n",
      "Total loss:  -1.1976 | PDE Loss:  -1.3049 | Function Loss:  -1.8575\n",
      "################################  658  ################################\n",
      "Total loss:  -1.1977 | PDE Loss:  -1.3052 | Function Loss:  -1.8566\n",
      "################################  659  ################################\n",
      "Total loss:  -1.1973 | PDE Loss:  -1.3063 | Function Loss:  -1.8507\n",
      "################################  660  ################################\n",
      "Total loss:  -1.1957 | PDE Loss:  -1.3064 | Function Loss:  -1.8436\n",
      "################################  661  ################################\n",
      "Total loss:  -1.1918 | PDE Loss:  -1.308 | Function Loss:  -1.8213\n",
      "################################  662  ################################\n",
      "Total loss:  -1.1842 | PDE Loss:  -1.3072 | Function Loss:  -1.792\n",
      "################################  663  ################################\n",
      "Total loss:  -1.1729 | PDE Loss:  -1.3096 | Function Loss:  -1.7414\n",
      "################################  664  ################################\n",
      "Total loss:  -1.1645 | PDE Loss:  -1.3079 | Function Loss:  -1.7153\n",
      "################################  665  ################################\n",
      "Total loss:  -1.1673 | PDE Loss:  -1.311 | Function Loss:  -1.7174\n",
      "################################  666  ################################\n",
      "Total loss:  -1.1794 | PDE Loss:  -1.3096 | Function Loss:  -1.7662\n",
      "################################  667  ################################\n",
      "Total loss:  -1.191 | PDE Loss:  -1.312 | Function Loss:  -1.8049\n",
      "################################  668  ################################\n",
      "Total loss:  -1.1983 | PDE Loss:  -1.3116 | Function Loss:  -1.8373\n",
      "################################  669  ################################\n",
      "Total loss:  -1.2022 | PDE Loss:  -1.313 | Function Loss:  -1.8494\n",
      "################################  670  ################################\n",
      "Total loss:  -1.2042 | PDE Loss:  -1.3132 | Function Loss:  -1.858\n",
      "################################  671  ################################\n",
      "Total loss:  -1.2054 | PDE Loss:  -1.3141 | Function Loss:  -1.8601\n",
      "################################  672  ################################\n",
      "Total loss:  -1.2062 | PDE Loss:  -1.3145 | Function Loss:  -1.862\n",
      "################################  673  ################################\n",
      "Total loss:  -1.2068 | PDE Loss:  -1.3153 | Function Loss:  -1.8623\n",
      "################################  674  ################################\n",
      "Total loss:  -1.2073 | PDE Loss:  -1.3159 | Function Loss:  -1.8624\n",
      "################################  675  ################################\n",
      "Total loss:  -1.2078 | PDE Loss:  -1.3165 | Function Loss:  -1.8625\n",
      "################################  676  ################################\n",
      "Total loss:  -1.2082 | PDE Loss:  -1.3174 | Function Loss:  -1.8613\n",
      "################################  677  ################################\n",
      "Total loss:  -1.2083 | PDE Loss:  -1.3178 | Function Loss:  -1.8606\n",
      "################################  678  ################################\n",
      "Total loss:  -1.208 | PDE Loss:  -1.3188 | Function Loss:  -1.8554\n",
      "################################  679  ################################\n",
      "Total loss:  -1.2066 | PDE Loss:  -1.3189 | Function Loss:  -1.8492\n",
      "################################  680  ################################\n",
      "Total loss:  -1.203 | PDE Loss:  -1.3205 | Function Loss:  -1.8283\n",
      "################################  681  ################################\n",
      "Total loss:  -1.1953 | PDE Loss:  -1.3197 | Function Loss:  -1.799\n",
      "################################  682  ################################\n",
      "Total loss:  -1.183 | PDE Loss:  -1.3222 | Function Loss:  -1.745\n",
      "################################  683  ################################\n",
      "Total loss:  -1.1724 | PDE Loss:  -1.3203 | Function Loss:  -1.7121\n",
      "################################  684  ################################\n",
      "Total loss:  -1.1742 | PDE Loss:  -1.3235 | Function Loss:  -1.7103\n",
      "################################  685  ################################\n",
      "Total loss:  -1.1875 | PDE Loss:  -1.3219 | Function Loss:  -1.7622\n",
      "################################  686  ################################\n",
      "Total loss:  -1.2004 | PDE Loss:  -1.3245 | Function Loss:  -1.8049\n",
      "################################  687  ################################\n",
      "Total loss:  -1.2084 | PDE Loss:  -1.324 | Function Loss:  -1.8398\n",
      "################################  688  ################################\n",
      "Total loss:  -1.2125 | PDE Loss:  -1.3255 | Function Loss:  -1.8526\n",
      "################################  689  ################################\n",
      "Total loss:  -1.2146 | PDE Loss:  -1.3256 | Function Loss:  -1.8614\n",
      "################################  690  ################################\n",
      "Total loss:  -1.2158 | PDE Loss:  -1.3265 | Function Loss:  -1.8634\n",
      "################################  691  ################################\n",
      "Total loss:  -1.2166 | PDE Loss:  -1.327 | Function Loss:  -1.8654\n",
      "################################  692  ################################\n",
      "Total loss:  -1.2172 | PDE Loss:  -1.3277 | Function Loss:  -1.8657\n",
      "################################  693  ################################\n",
      "Total loss:  -1.2177 | PDE Loss:  -1.3283 | Function Loss:  -1.866\n",
      "################################  694  ################################\n",
      "Total loss:  -1.2183 | PDE Loss:  -1.329 | Function Loss:  -1.8661\n",
      "################################  695  ################################\n",
      "Total loss:  -1.2187 | PDE Loss:  -1.3298 | Function Loss:  -1.8654\n",
      "################################  696  ################################\n",
      "Total loss:  -1.2191 | PDE Loss:  -1.3302 | Function Loss:  -1.8653\n",
      "################################  697  ################################\n",
      "Total loss:  -1.2192 | PDE Loss:  -1.3312 | Function Loss:  -1.8624\n",
      "################################  698  ################################\n",
      "Total loss:  -1.2186 | PDE Loss:  -1.3314 | Function Loss:  -1.8594\n",
      "################################  699  ################################\n",
      "Total loss:  -1.2167 | PDE Loss:  -1.3328 | Function Loss:  -1.8464\n",
      "################################  700  ################################\n",
      "Total loss:  -1.2117 | PDE Loss:  -1.3323 | Function Loss:  -1.827\n",
      "################################  701  ################################\n",
      "Total loss:  -1.2014 | PDE Loss:  -1.3345 | Function Loss:  -1.78\n",
      "################################  702  ################################\n",
      "Total loss:  -1.1868 | PDE Loss:  -1.3328 | Function Loss:  -1.7312\n",
      "################################  703  ################################\n",
      "Total loss:  -1.1781 | PDE Loss:  -1.336 | Function Loss:  -1.6939\n",
      "################################  704  ################################\n",
      "Total loss:  -1.1866 | PDE Loss:  -1.334 | Function Loss:  -1.7275\n",
      "################################  705  ################################\n",
      "Total loss:  -1.2026 | PDE Loss:  -1.3371 | Function Loss:  -1.7772\n",
      "################################  706  ################################\n",
      "Total loss:  -1.2147 | PDE Loss:  -1.3362 | Function Loss:  -1.8272\n",
      "################################  707  ################################\n",
      "Total loss:  -1.2211 | PDE Loss:  -1.338 | Function Loss:  -1.8483\n",
      "################################  708  ################################\n",
      "Total loss:  -1.2243 | PDE Loss:  -1.338 | Function Loss:  -1.8619\n",
      "################################  709  ################################\n",
      "Total loss:  -1.2258 | PDE Loss:  -1.339 | Function Loss:  -1.8653\n",
      "################################  710  ################################\n",
      "Total loss:  -1.2268 | PDE Loss:  -1.3393 | Function Loss:  -1.8684\n",
      "################################  711  ################################\n",
      "Total loss:  -1.2275 | PDE Loss:  -1.3401 | Function Loss:  -1.8689\n",
      "################################  712  ################################\n",
      "Total loss:  -1.2281 | PDE Loss:  -1.3406 | Function Loss:  -1.8696\n",
      "################################  713  ################################\n",
      "Total loss:  -1.2286 | PDE Loss:  -1.3414 | Function Loss:  -1.8696\n",
      "################################  714  ################################\n",
      "Total loss:  -1.2292 | PDE Loss:  -1.342 | Function Loss:  -1.8696\n",
      "################################  715  ################################\n",
      "Total loss:  -1.2297 | PDE Loss:  -1.3427 | Function Loss:  -1.8698\n",
      "################################  716  ################################\n",
      "Total loss:  -1.2302 | PDE Loss:  -1.3434 | Function Loss:  -1.8695\n",
      "################################  717  ################################\n",
      "Total loss:  -1.2307 | PDE Loss:  -1.344 | Function Loss:  -1.8696\n",
      "################################  718  ################################\n",
      "Total loss:  -1.231 | PDE Loss:  -1.3449 | Function Loss:  -1.868\n",
      "################################  719  ################################\n",
      "Total loss:  -1.2309 | PDE Loss:  -1.3452 | Function Loss:  -1.8666\n",
      "################################  720  ################################\n",
      "Total loss:  -1.2299 | PDE Loss:  -1.3464 | Function Loss:  -1.8583\n",
      "################################  721  ################################\n",
      "Total loss:  -1.2267 | PDE Loss:  -1.3462 | Function Loss:  -1.8455\n",
      "################################  722  ################################\n",
      "Total loss:  -1.2186 | PDE Loss:  -1.3482 | Function Loss:  -1.8072\n",
      "################################  723  ################################\n",
      "Total loss:  -1.2032 | PDE Loss:  -1.3466 | Function Loss:  -1.754\n",
      "################################  724  ################################\n",
      "Total loss:  -1.186 | PDE Loss:  -1.3497 | Function Loss:  -1.6889\n",
      "################################  725  ################################\n",
      "Total loss:  -1.1866 | PDE Loss:  -1.3473 | Function Loss:  -1.6962\n",
      "################################  726  ################################\n",
      "Total loss:  -1.2045 | PDE Loss:  -1.3508 | Function Loss:  -1.748\n",
      "################################  727  ################################\n",
      "Total loss:  -1.2215 | PDE Loss:  -1.3496 | Function Loss:  -1.8141\n",
      "################################  728  ################################\n",
      "Total loss:  -1.2308 | PDE Loss:  -1.3518 | Function Loss:  -1.845\n",
      "################################  729  ################################\n",
      "Total loss:  -1.2351 | PDE Loss:  -1.3516 | Function Loss:  -1.8635\n",
      "################################  730  ################################\n",
      "Total loss:  -1.2371 | PDE Loss:  -1.3527 | Function Loss:  -1.8684\n",
      "################################  731  ################################\n",
      "Total loss:  -1.2382 | PDE Loss:  -1.353 | Function Loss:  -1.8721\n",
      "################################  732  ################################\n",
      "Total loss:  -1.2389 | PDE Loss:  -1.3537 | Function Loss:  -1.8728\n",
      "################################  733  ################################\n",
      "Total loss:  -1.2395 | PDE Loss:  -1.3543 | Function Loss:  -1.8734\n",
      "################################  734  ################################\n",
      "Total loss:  -1.24 | PDE Loss:  -1.355 | Function Loss:  -1.8734\n",
      "################################  735  ################################\n",
      "Total loss:  -1.2405 | PDE Loss:  -1.3557 | Function Loss:  -1.8733\n",
      "################################  736  ################################\n",
      "Total loss:  -1.241 | PDE Loss:  -1.3563 | Function Loss:  -1.8735\n",
      "################################  737  ################################\n",
      "Total loss:  -1.2414 | PDE Loss:  -1.3571 | Function Loss:  -1.8724\n",
      "################################  738  ################################\n",
      "Total loss:  -1.2416 | PDE Loss:  -1.3575 | Function Loss:  -1.8718\n",
      "################################  739  ################################\n",
      "Total loss:  -1.2411 | PDE Loss:  -1.3586 | Function Loss:  -1.8661\n",
      "################################  740  ################################\n",
      "Total loss:  -1.2391 | PDE Loss:  -1.3586 | Function Loss:  -1.8578\n",
      "################################  741  ################################\n",
      "Total loss:  -1.2334 | PDE Loss:  -1.3603 | Function Loss:  -1.8294\n",
      "################################  742  ################################\n",
      "Total loss:  -1.2207 | PDE Loss:  -1.3591 | Function Loss:  -1.7847\n",
      "################################  743  ################################\n",
      "Total loss:  -1.2015 | PDE Loss:  -1.362 | Function Loss:  -1.7114\n",
      "################################  744  ################################\n",
      "Total loss:  -1.1921 | PDE Loss:  -1.3594 | Function Loss:  -1.6875\n",
      "################################  745  ################################\n",
      "Total loss:  -1.2055 | PDE Loss:  -1.3632 | Function Loss:  -1.7217\n",
      "################################  746  ################################\n",
      "Total loss:  -1.2255 | PDE Loss:  -1.3616 | Function Loss:  -1.7956\n",
      "################################  747  ################################\n",
      "Total loss:  -1.2381 | PDE Loss:  -1.3641 | Function Loss:  -1.8371\n",
      "################################  748  ################################\n",
      "Total loss:  -1.2441 | PDE Loss:  -1.3638 | Function Loss:  -1.8624\n",
      "################################  749  ################################\n",
      "Total loss:  -1.2468 | PDE Loss:  -1.3651 | Function Loss:  -1.8695\n",
      "################################  750  ################################\n",
      "Total loss:  -1.2481 | PDE Loss:  -1.3652 | Function Loss:  -1.8746\n",
      "################################  751  ################################\n",
      "Total loss:  -1.2489 | PDE Loss:  -1.366 | Function Loss:  -1.8754\n",
      "################################  752  ################################\n",
      "Total loss:  -1.2496 | PDE Loss:  -1.3664 | Function Loss:  -1.8767\n",
      "################################  753  ################################\n",
      "Total loss:  -1.2501 | PDE Loss:  -1.3673 | Function Loss:  -1.8764\n",
      "################################  754  ################################\n",
      "Total loss:  -1.2506 | PDE Loss:  -1.3678 | Function Loss:  -1.8768\n",
      "################################  755  ################################\n",
      "Total loss:  -1.251 | PDE Loss:  -1.3687 | Function Loss:  -1.8756\n",
      "################################  756  ################################\n",
      "Total loss:  -1.2512 | PDE Loss:  -1.3691 | Function Loss:  -1.8752\n",
      "################################  757  ################################\n",
      "Total loss:  -1.2508 | PDE Loss:  -1.3702 | Function Loss:  -1.8702\n",
      "################################  758  ################################\n",
      "Total loss:  -1.2491 | PDE Loss:  -1.3701 | Function Loss:  -1.8631\n",
      "################################  759  ################################\n",
      "Total loss:  -1.2441 | PDE Loss:  -1.3719 | Function Loss:  -1.8377\n",
      "################################  760  ################################\n",
      "Total loss:  -1.2326 | PDE Loss:  -1.3707 | Function Loss:  -1.7975\n",
      "################################  761  ################################\n",
      "Total loss:  -1.2141 | PDE Loss:  -1.3736 | Function Loss:  -1.7265\n",
      "################################  762  ################################\n",
      "Total loss:  -1.2024 | PDE Loss:  -1.371 | Function Loss:  -1.6948\n",
      "################################  763  ################################\n",
      "Total loss:  -1.2126 | PDE Loss:  -1.3749 | Function Loss:  -1.7188\n",
      "################################  764  ################################\n",
      "Total loss:  -1.2326 | PDE Loss:  -1.3731 | Function Loss:  -1.791\n",
      "################################  765  ################################\n",
      "Total loss:  -1.2462 | PDE Loss:  -1.3757 | Function Loss:  -1.8348\n",
      "################################  766  ################################\n",
      "Total loss:  -1.2529 | PDE Loss:  -1.3752 | Function Loss:  -1.8628\n",
      "################################  767  ################################\n",
      "Total loss:  -1.2559 | PDE Loss:  -1.3766 | Function Loss:  -1.8708\n",
      "################################  768  ################################\n",
      "Total loss:  -1.2573 | PDE Loss:  -1.3767 | Function Loss:  -1.8766\n",
      "################################  769  ################################\n",
      "Total loss:  -1.2582 | PDE Loss:  -1.3776 | Function Loss:  -1.8771\n",
      "################################  770  ################################\n",
      "Total loss:  -1.2587 | PDE Loss:  -1.3779 | Function Loss:  -1.8785\n",
      "################################  771  ################################\n",
      "Total loss:  -1.259 | PDE Loss:  -1.3789 | Function Loss:  -1.8765\n",
      "################################  772  ################################\n",
      "Total loss:  -1.2588 | PDE Loss:  -1.3791 | Function Loss:  -1.875\n",
      "################################  773  ################################\n",
      "Total loss:  -1.2575 | PDE Loss:  -1.3804 | Function Loss:  -1.8655\n",
      "################################  774  ################################\n",
      "Total loss:  -1.2537 | PDE Loss:  -1.38 | Function Loss:  -1.8516\n",
      "################################  775  ################################\n",
      "Total loss:  -1.2451 | PDE Loss:  -1.3822 | Function Loss:  -1.8126\n",
      "################################  776  ################################\n",
      "Total loss:  -1.2304 | PDE Loss:  -1.3804 | Function Loss:  -1.7649\n",
      "################################  777  ################################\n",
      "Total loss:  -1.2168 | PDE Loss:  -1.3837 | Function Loss:  -1.713\n",
      "################################  778  ################################\n",
      "Total loss:  -1.2198 | PDE Loss:  -1.3813 | Function Loss:  -1.7278\n",
      "################################  779  ################################\n",
      "Total loss:  -1.2358 | PDE Loss:  -1.3849 | Function Loss:  -1.7726\n",
      "################################  780  ################################\n",
      "Total loss:  -1.2503 | PDE Loss:  -1.3836 | Function Loss:  -1.8281\n",
      "################################  781  ################################\n",
      "Total loss:  -1.2585 | PDE Loss:  -1.3858 | Function Loss:  -1.8534\n",
      "################################  782  ################################\n",
      "Total loss:  -1.2624 | PDE Loss:  -1.3854 | Function Loss:  -1.8703\n",
      "################################  783  ################################\n",
      "Total loss:  -1.2643 | PDE Loss:  -1.3867 | Function Loss:  -1.8742\n",
      "################################  784  ################################\n",
      "Total loss:  -1.2653 | PDE Loss:  -1.3866 | Function Loss:  -1.8782\n",
      "################################  785  ################################\n",
      "Total loss:  -1.2656 | PDE Loss:  -1.3878 | Function Loss:  -1.8763\n",
      "################################  786  ################################\n",
      "Total loss:  -1.2654 | PDE Loss:  -1.3878 | Function Loss:  -1.8752\n",
      "################################  787  ################################\n",
      "Total loss:  -1.264 | PDE Loss:  -1.3892 | Function Loss:  -1.8651\n",
      "################################  788  ################################\n",
      "Total loss:  -1.2603 | PDE Loss:  -1.3887 | Function Loss:  -1.8521\n",
      "################################  789  ################################\n",
      "Total loss:  -1.2526 | PDE Loss:  -1.3908 | Function Loss:  -1.8171\n",
      "################################  790  ################################\n",
      "Total loss:  -1.2407 | PDE Loss:  -1.3892 | Function Loss:  -1.7791\n",
      "################################  791  ################################\n",
      "Total loss:  -1.2303 | PDE Loss:  -1.3924 | Function Loss:  -1.7369\n",
      "################################  792  ################################\n",
      "Total loss:  -1.2321 | PDE Loss:  -1.3902 | Function Loss:  -1.7478\n",
      "################################  793  ################################\n",
      "Total loss:  -1.2443 | PDE Loss:  -1.3936 | Function Loss:  -1.7805\n",
      "################################  794  ################################\n",
      "Total loss:  -1.2566 | PDE Loss:  -1.3923 | Function Loss:  -1.8281\n",
      "################################  795  ################################\n",
      "Total loss:  -1.2644 | PDE Loss:  -1.3945 | Function Loss:  -1.8513\n",
      "################################  796  ################################\n",
      "Total loss:  -1.2685 | PDE Loss:  -1.394 | Function Loss:  -1.8688\n",
      "################################  797  ################################\n",
      "Total loss:  -1.2705 | PDE Loss:  -1.3955 | Function Loss:  -1.8726\n",
      "################################  798  ################################\n",
      "Total loss:  -1.2714 | PDE Loss:  -1.3953 | Function Loss:  -1.8769\n",
      "################################  799  ################################\n",
      "Total loss:  -1.2716 | PDE Loss:  -1.3966 | Function Loss:  -1.8734\n",
      "################################  800  ################################\n",
      "Total loss:  -1.2707 | PDE Loss:  -1.3963 | Function Loss:  -1.8707\n",
      "################################  801  ################################\n",
      "Total loss:  -1.2682 | PDE Loss:  -1.398 | Function Loss:  -1.8558\n",
      "################################  802  ################################\n",
      "Total loss:  -1.2629 | PDE Loss:  -1.3971 | Function Loss:  -1.8383\n",
      "################################  803  ################################\n",
      "Total loss:  -1.2544 | PDE Loss:  -1.3996 | Function Loss:  -1.8009\n",
      "################################  804  ################################\n",
      "Total loss:  -1.2454 | PDE Loss:  -1.3977 | Function Loss:  -1.7743\n",
      "################################  805  ################################\n",
      "Total loss:  -1.2422 | PDE Loss:  -1.401 | Function Loss:  -1.7563\n",
      "################################  806  ################################\n",
      "Total loss:  -1.2488 | PDE Loss:  -1.399 | Function Loss:  -1.7827\n",
      "################################  807  ################################\n",
      "Total loss:  -1.2591 | PDE Loss:  -1.4021 | Function Loss:  -1.811\n",
      "################################  808  ################################\n",
      "Total loss:  -1.2675 | PDE Loss:  -1.401 | Function Loss:  -1.8449\n",
      "################################  809  ################################\n",
      "Total loss:  -1.2727 | PDE Loss:  -1.403 | Function Loss:  -1.8588\n",
      "################################  810  ################################\n",
      "Total loss:  -1.2755 | PDE Loss:  -1.4025 | Function Loss:  -1.8712\n",
      "################################  811  ################################\n",
      "Total loss:  -1.2768 | PDE Loss:  -1.404 | Function Loss:  -1.872\n",
      "################################  812  ################################\n",
      "Total loss:  -1.2771 | PDE Loss:  -1.4037 | Function Loss:  -1.8743\n",
      "################################  813  ################################\n",
      "Total loss:  -1.2764 | PDE Loss:  -1.4052 | Function Loss:  -1.8669\n",
      "################################  814  ################################\n",
      "Total loss:  -1.2742 | PDE Loss:  -1.4046 | Function Loss:  -1.8602\n",
      "################################  815  ################################\n",
      "Total loss:  -1.2699 | PDE Loss:  -1.4067 | Function Loss:  -1.8384\n",
      "################################  816  ################################\n",
      "Total loss:  -1.2635 | PDE Loss:  -1.4053 | Function Loss:  -1.8183\n",
      "################################  817  ################################\n",
      "Total loss:  -1.2566 | PDE Loss:  -1.4081 | Function Loss:  -1.7875\n",
      "################################  818  ################################\n",
      "Total loss:  -1.2539 | PDE Loss:  -1.4062 | Function Loss:  -1.7828\n",
      "################################  819  ################################\n",
      "Total loss:  -1.2576 | PDE Loss:  -1.4094 | Function Loss:  -1.788\n",
      "################################  820  ################################\n",
      "Total loss:  -1.2653 | PDE Loss:  -1.4078 | Function Loss:  -1.8187\n",
      "################################  821  ################################\n",
      "Total loss:  -1.2725 | PDE Loss:  -1.4104 | Function Loss:  -1.838\n",
      "################################  822  ################################\n",
      "Total loss:  -1.2775 | PDE Loss:  -1.4095 | Function Loss:  -1.8591\n",
      "################################  823  ################################\n",
      "Total loss:  -1.2805 | PDE Loss:  -1.4114 | Function Loss:  -1.8651\n",
      "################################  824  ################################\n",
      "Total loss:  -1.2819 | PDE Loss:  -1.4108 | Function Loss:  -1.8723\n",
      "################################  825  ################################\n",
      "Total loss:  -1.2823 | PDE Loss:  -1.4124 | Function Loss:  -1.8692\n",
      "################################  826  ################################\n",
      "Total loss:  -1.2816 | PDE Loss:  -1.4118 | Function Loss:  -1.8681\n",
      "################################  827  ################################\n",
      "Total loss:  -1.2796 | PDE Loss:  -1.4137 | Function Loss:  -1.8552\n",
      "################################  828  ################################\n",
      "Total loss:  -1.2759 | PDE Loss:  -1.4127 | Function Loss:  -1.8443\n",
      "################################  829  ################################\n",
      "Total loss:  -1.2709 | PDE Loss:  -1.4151 | Function Loss:  -1.8197\n",
      "################################  830  ################################\n",
      "Total loss:  -1.2661 | PDE Loss:  -1.4135 | Function Loss:  -1.8072\n",
      "################################  831  ################################\n",
      "Total loss:  -1.2644 | PDE Loss:  -1.4164 | Function Loss:  -1.794\n",
      "################################  832  ################################\n",
      "Total loss:  -1.2673 | PDE Loss:  -1.4147 | Function Loss:  -1.8082\n",
      "################################  833  ################################\n",
      "Total loss:  -1.2729 | PDE Loss:  -1.4175 | Function Loss:  -1.8209\n",
      "################################  834  ################################\n",
      "Total loss:  -1.2787 | PDE Loss:  -1.4163 | Function Loss:  -1.8447\n",
      "################################  835  ################################\n",
      "Total loss:  -1.2829 | PDE Loss:  -1.4185 | Function Loss:  -1.8546\n",
      "################################  836  ################################\n",
      "Total loss:  -1.2856 | PDE Loss:  -1.4177 | Function Loss:  -1.8669\n",
      "################################  837  ################################\n",
      "Total loss:  -1.287 | PDE Loss:  -1.4195 | Function Loss:  -1.8672\n",
      "################################  838  ################################\n",
      "Total loss:  -1.2873 | PDE Loss:  -1.4188 | Function Loss:  -1.8703\n",
      "################################  839  ################################\n",
      "Total loss:  -1.2866 | PDE Loss:  -1.4206 | Function Loss:  -1.8626\n",
      "################################  840  ################################\n",
      "Total loss:  -1.2848 | PDE Loss:  -1.4198 | Function Loss:  -1.858\n",
      "################################  841  ################################\n",
      "Total loss:  -1.2817 | PDE Loss:  -1.4219 | Function Loss:  -1.8409\n",
      "################################  842  ################################\n",
      "Total loss:  -1.2779 | PDE Loss:  -1.4206 | Function Loss:  -1.8308\n",
      "################################  843  ################################\n",
      "Total loss:  -1.2747 | PDE Loss:  -1.4232 | Function Loss:  -1.8129\n",
      "################################  844  ################################\n",
      "Total loss:  -1.274 | PDE Loss:  -1.4216 | Function Loss:  -1.8145\n",
      "################################  845  ################################\n",
      "Total loss:  -1.2763 | PDE Loss:  -1.4244 | Function Loss:  -1.8155\n",
      "################################  846  ################################\n",
      "Total loss:  -1.2806 | PDE Loss:  -1.423 | Function Loss:  -1.8343\n",
      "################################  847  ################################\n",
      "Total loss:  -1.285 | PDE Loss:  -1.4254 | Function Loss:  -1.8438\n",
      "################################  848  ################################\n",
      "Total loss:  -1.2885 | PDE Loss:  -1.4244 | Function Loss:  -1.8594\n",
      "################################  849  ################################\n",
      "Total loss:  -1.2908 | PDE Loss:  -1.4264 | Function Loss:  -1.8626\n",
      "################################  850  ################################\n",
      "Total loss:  -1.2921 | PDE Loss:  -1.4256 | Function Loss:  -1.8693\n",
      "################################  851  ################################\n",
      "Total loss:  -1.2923 | PDE Loss:  -1.4274 | Function Loss:  -1.8653\n",
      "################################  852  ################################\n",
      "Total loss:  -1.2916 | PDE Loss:  -1.4266 | Function Loss:  -1.865\n",
      "################################  853  ################################\n",
      "Total loss:  -1.29 | PDE Loss:  -1.4286 | Function Loss:  -1.8536\n",
      "################################  854  ################################\n",
      "Total loss:  -1.2876 | PDE Loss:  -1.4274 | Function Loss:  -1.8477\n",
      "################################  855  ################################\n",
      "Total loss:  -1.2848 | PDE Loss:  -1.4298 | Function Loss:  -1.8316\n",
      "################################  856  ################################\n",
      "Total loss:  -1.2828 | PDE Loss:  -1.4283 | Function Loss:  -1.8284\n",
      "################################  857  ################################\n",
      "Total loss:  -1.2826 | PDE Loss:  -1.431 | Function Loss:  -1.8211\n",
      "################################  858  ################################\n",
      "Total loss:  -1.2846 | PDE Loss:  -1.4295 | Function Loss:  -1.8318\n",
      "################################  859  ################################\n",
      "Total loss:  -1.2879 | PDE Loss:  -1.4321 | Function Loss:  -1.8368\n",
      "################################  860  ################################\n",
      "Total loss:  -1.2913 | PDE Loss:  -1.4308 | Function Loss:  -1.8523\n",
      "################################  861  ################################\n",
      "Total loss:  -1.2941 | PDE Loss:  -1.433 | Function Loss:  -1.8568\n",
      "################################  862  ################################\n",
      "Total loss:  -1.296 | PDE Loss:  -1.4321 | Function Loss:  -1.8664\n",
      "################################  863  ################################\n",
      "Total loss:  -1.2971 | PDE Loss:  -1.434 | Function Loss:  -1.8651\n",
      "################################  864  ################################\n",
      "Total loss:  -1.2973 | PDE Loss:  -1.4331 | Function Loss:  -1.8683\n",
      "################################  865  ################################\n",
      "Total loss:  -1.2967 | PDE Loss:  -1.4351 | Function Loss:  -1.8608\n",
      "################################  866  ################################\n",
      "Total loss:  -1.2954 | PDE Loss:  -1.434 | Function Loss:  -1.8587\n",
      "################################  867  ################################\n",
      "Total loss:  -1.2935 | PDE Loss:  -1.4362 | Function Loss:  -1.8461\n",
      "################################  868  ################################\n",
      "Total loss:  -1.2916 | PDE Loss:  -1.4349 | Function Loss:  -1.8428\n",
      "################################  869  ################################\n",
      "Total loss:  -1.2904 | PDE Loss:  -1.4374 | Function Loss:  -1.8322\n",
      "################################  870  ################################\n",
      "Total loss:  -1.2906 | PDE Loss:  -1.4359 | Function Loss:  -1.8366\n",
      "################################  871  ################################\n",
      "Total loss:  -1.2922 | PDE Loss:  -1.4385 | Function Loss:  -1.8358\n",
      "################################  872  ################################\n",
      "Total loss:  -1.2947 | PDE Loss:  -1.4371 | Function Loss:  -1.8482\n",
      "################################  873  ################################\n",
      "Total loss:  -1.2974 | PDE Loss:  -1.4394 | Function Loss:  -1.8517\n",
      "################################  874  ################################\n",
      "Total loss:  -1.2996 | PDE Loss:  -1.4383 | Function Loss:  -1.8628\n",
      "################################  875  ################################\n",
      "Total loss:  -1.3012 | PDE Loss:  -1.4404 | Function Loss:  -1.8632\n",
      "################################  876  ################################\n",
      "Total loss:  -1.3021 | PDE Loss:  -1.4394 | Function Loss:  -1.8691\n",
      "################################  877  ################################\n",
      "Total loss:  -1.3023 | PDE Loss:  -1.4414 | Function Loss:  -1.8645\n",
      "################################  878  ################################\n",
      "Total loss:  -1.3018 | PDE Loss:  -1.4404 | Function Loss:  -1.8655\n",
      "################################  879  ################################\n",
      "Total loss:  -1.3008 | PDE Loss:  -1.4425 | Function Loss:  -1.8562\n",
      "################################  880  ################################\n",
      "Total loss:  -1.2995 | PDE Loss:  -1.4413 | Function Loss:  -1.8546\n",
      "################################  881  ################################\n",
      "Total loss:  -1.2982 | PDE Loss:  -1.4436 | Function Loss:  -1.8441\n",
      "################################  882  ################################\n",
      "Total loss:  -1.2975 | PDE Loss:  -1.4422 | Function Loss:  -1.8453\n",
      "################################  883  ################################\n",
      "Total loss:  -1.2978 | PDE Loss:  -1.4446 | Function Loss:  -1.8402\n",
      "################################  884  ################################\n",
      "Total loss:  -1.2992 | PDE Loss:  -1.4432 | Function Loss:  -1.8484\n",
      "################################  885  ################################\n",
      "Total loss:  -1.3011 | PDE Loss:  -1.4456 | Function Loss:  -1.8493\n",
      "################################  886  ################################\n",
      "Total loss:  -1.3032 | PDE Loss:  -1.4444 | Function Loss:  -1.86\n",
      "################################  887  ################################\n",
      "Total loss:  -1.305 | PDE Loss:  -1.4465 | Function Loss:  -1.8609\n",
      "################################  888  ################################\n",
      "Total loss:  -1.3064 | PDE Loss:  -1.4455 | Function Loss:  -1.8685\n",
      "################################  889  ################################\n",
      "Total loss:  -1.3071 | PDE Loss:  -1.4475 | Function Loss:  -1.866\n",
      "################################  890  ################################\n",
      "Total loss:  -1.3073 | PDE Loss:  -1.4464 | Function Loss:  -1.8694\n",
      "################################  891  ################################\n",
      "Total loss:  -1.307 | PDE Loss:  -1.4485 | Function Loss:  -1.8629\n",
      "################################  892  ################################\n",
      "Total loss:  -1.3063 | PDE Loss:  -1.4473 | Function Loss:  -1.8632\n",
      "################################  893  ################################\n",
      "Total loss:  -1.3053 | PDE Loss:  -1.4495 | Function Loss:  -1.8542\n",
      "################################  894  ################################\n",
      "Total loss:  -1.3045 | PDE Loss:  -1.4482 | Function Loss:  -1.8548\n",
      "################################  895  ################################\n",
      "Total loss:  -1.3042 | PDE Loss:  -1.4506 | Function Loss:  -1.8477\n",
      "################################  896  ################################\n",
      "Total loss:  -1.3046 | PDE Loss:  -1.4492 | Function Loss:  -1.8526\n",
      "################################  897  ################################\n",
      "Total loss:  -1.3057 | PDE Loss:  -1.4515 | Function Loss:  -1.8504\n",
      "################################  898  ################################\n",
      "Total loss:  -1.3072 | PDE Loss:  -1.4502 | Function Loss:  -1.8592\n",
      "################################  899  ################################\n",
      "Total loss:  -1.3089 | PDE Loss:  -1.4525 | Function Loss:  -1.8594\n",
      "################################  900  ################################\n",
      "Total loss:  -1.3104 | PDE Loss:  -1.4513 | Function Loss:  -1.8677\n",
      "################################  901  ################################\n",
      "Total loss:  -1.3115 | PDE Loss:  -1.4533 | Function Loss:  -1.8663\n",
      "################################  902  ################################\n",
      "Total loss:  -1.3121 | PDE Loss:  -1.4523 | Function Loss:  -1.8715\n",
      "################################  903  ################################\n",
      "Total loss:  -1.3123 | PDE Loss:  -1.4543 | Function Loss:  -1.867\n",
      "################################  904  ################################\n",
      "Total loss:  -1.3122 | PDE Loss:  -1.4532 | Function Loss:  -1.8693\n",
      "################################  905  ################################\n",
      "Total loss:  -1.3117 | PDE Loss:  -1.4553 | Function Loss:  -1.8621\n",
      "################################  906  ################################\n",
      "Total loss:  -1.3111 | PDE Loss:  -1.454 | Function Loss:  -1.8632\n",
      "################################  907  ################################\n",
      "Total loss:  -1.3106 | PDE Loss:  -1.4563 | Function Loss:  -1.8558\n",
      "################################  908  ################################\n",
      "Total loss:  -1.3105 | PDE Loss:  -1.4549 | Function Loss:  -1.8589\n",
      "################################  909  ################################\n",
      "Total loss:  -1.3109 | PDE Loss:  -1.4572 | Function Loss:  -1.8545\n",
      "################################  910  ################################\n",
      "Total loss:  -1.3118 | PDE Loss:  -1.4559 | Function Loss:  -1.8611\n",
      "################################  911  ################################\n",
      "Total loss:  -1.3131 | PDE Loss:  -1.4581 | Function Loss:  -1.8597\n",
      "################################  912  ################################\n",
      "Total loss:  -1.3144 | PDE Loss:  -1.4569 | Function Loss:  -1.8676\n",
      "################################  913  ################################\n",
      "Total loss:  -1.3156 | PDE Loss:  -1.459 | Function Loss:  -1.8664\n",
      "################################  914  ################################\n",
      "Total loss:  -1.3165 | PDE Loss:  -1.4579 | Function Loss:  -1.8727\n",
      "################################  915  ################################\n",
      "Total loss:  -1.3171 | PDE Loss:  -1.4599 | Function Loss:  -1.8696\n",
      "################################  916  ################################\n",
      "Total loss:  -1.3173 | PDE Loss:  -1.4588 | Function Loss:  -1.8734\n",
      "################################  917  ################################\n",
      "Total loss:  -1.3173 | PDE Loss:  -1.4608 | Function Loss:  -1.8679\n",
      "################################  918  ################################\n",
      "Total loss:  -1.317 | PDE Loss:  -1.4596 | Function Loss:  -1.87\n",
      "################################  919  ################################\n",
      "Total loss:  -1.3167 | PDE Loss:  -1.4618 | Function Loss:  -1.8634\n",
      "################################  920  ################################\n",
      "Total loss:  -1.3165 | PDE Loss:  -1.4605 | Function Loss:  -1.8658\n",
      "################################  921  ################################\n",
      "Total loss:  -1.3165 | PDE Loss:  -1.4627 | Function Loss:  -1.8603\n",
      "################################  922  ################################\n",
      "Total loss:  -1.3169 | PDE Loss:  -1.4614 | Function Loss:  -1.8651\n",
      "################################  923  ################################\n",
      "Total loss:  -1.3176 | PDE Loss:  -1.4636 | Function Loss:  -1.8621\n",
      "################################  924  ################################\n",
      "Total loss:  -1.3186 | PDE Loss:  -1.4623 | Function Loss:  -1.8689\n",
      "################################  925  ################################\n",
      "Total loss:  -1.3197 | PDE Loss:  -1.4645 | Function Loss:  -1.8672\n",
      "################################  926  ################################\n",
      "Total loss:  -1.3207 | PDE Loss:  -1.4632 | Function Loss:  -1.8738\n",
      "################################  927  ################################\n",
      "Total loss:  -1.3215 | PDE Loss:  -1.4653 | Function Loss:  -1.8714\n",
      "################################  928  ################################\n",
      "Total loss:  -1.322 | PDE Loss:  -1.4641 | Function Loss:  -1.8763\n",
      "################################  929  ################################\n",
      "Total loss:  -1.3223 | PDE Loss:  -1.4662 | Function Loss:  -1.8721\n",
      "################################  930  ################################\n",
      "Total loss:  -1.3224 | PDE Loss:  -1.465 | Function Loss:  -1.8753\n",
      "################################  931  ################################\n",
      "Total loss:  -1.3223 | PDE Loss:  -1.4671 | Function Loss:  -1.8697\n",
      "################################  932  ################################\n",
      "Total loss:  -1.3221 | PDE Loss:  -1.4658 | Function Loss:  -1.8723\n",
      "################################  933  ################################\n",
      "Total loss:  -1.322 | PDE Loss:  -1.468 | Function Loss:  -1.8666\n",
      "################################  934  ################################\n",
      "Total loss:  -1.3222 | PDE Loss:  -1.4667 | Function Loss:  -1.8703\n",
      "################################  935  ################################\n",
      "Total loss:  -1.3225 | PDE Loss:  -1.4688 | Function Loss:  -1.8662\n",
      "################################  936  ################################\n",
      "Total loss:  -1.3232 | PDE Loss:  -1.4676 | Function Loss:  -1.8717\n",
      "################################  937  ################################\n",
      "Total loss:  -1.324 | PDE Loss:  -1.4697 | Function Loss:  -1.8691\n",
      "################################  938  ################################\n",
      "Total loss:  -1.3249 | PDE Loss:  -1.4684 | Function Loss:  -1.8754\n",
      "################################  939  ################################\n",
      "Total loss:  -1.3257 | PDE Loss:  -1.4705 | Function Loss:  -1.873\n",
      "################################  940  ################################\n",
      "Total loss:  -1.3264 | PDE Loss:  -1.4693 | Function Loss:  -1.8786\n",
      "################################  941  ################################\n",
      "Total loss:  -1.3269 | PDE Loss:  -1.4713 | Function Loss:  -1.8752\n",
      "################################  942  ################################\n",
      "Total loss:  -1.3272 | PDE Loss:  -1.4702 | Function Loss:  -1.8794\n",
      "################################  943  ################################\n",
      "Total loss:  -1.3274 | PDE Loss:  -1.4722 | Function Loss:  -1.8747\n",
      "################################  944  ################################\n",
      "Total loss:  -1.3274 | PDE Loss:  -1.471 | Function Loss:  -1.8779\n",
      "################################  945  ################################\n",
      "Total loss:  -1.3274 | PDE Loss:  -1.473 | Function Loss:  -1.8726\n",
      "################################  946  ################################\n",
      "Total loss:  -1.3274 | PDE Loss:  -1.4718 | Function Loss:  -1.8759\n",
      "################################  947  ################################\n",
      "Total loss:  -1.3276 | PDE Loss:  -1.4739 | Function Loss:  -1.8712\n",
      "################################  948  ################################\n",
      "Total loss:  -1.3279 | PDE Loss:  -1.4726 | Function Loss:  -1.8757\n",
      "################################  949  ################################\n",
      "Total loss:  -1.3285 | PDE Loss:  -1.4747 | Function Loss:  -1.8722\n",
      "################################  950  ################################\n",
      "Total loss:  -1.3291 | PDE Loss:  -1.4735 | Function Loss:  -1.8778\n",
      "################################  951  ################################\n",
      "Total loss:  -1.3299 | PDE Loss:  -1.4755 | Function Loss:  -1.8751\n",
      "################################  952  ################################\n",
      "Total loss:  -1.3306 | PDE Loss:  -1.4743 | Function Loss:  -1.8807\n",
      "################################  953  ################################\n",
      "Total loss:  -1.3312 | PDE Loss:  -1.4763 | Function Loss:  -1.8778\n",
      "################################  954  ################################\n",
      "Total loss:  -1.3317 | PDE Loss:  -1.4751 | Function Loss:  -1.8826\n",
      "################################  955  ################################\n",
      "Total loss:  -1.332 | PDE Loss:  -1.4771 | Function Loss:  -1.8787\n",
      "################################  956  ################################\n",
      "Total loss:  -1.3322 | PDE Loss:  -1.4759 | Function Loss:  -1.8825\n",
      "################################  957  ################################\n",
      "Total loss:  -1.3324 | PDE Loss:  -1.4779 | Function Loss:  -1.8778\n",
      "################################  958  ################################\n",
      "Total loss:  -1.3324 | PDE Loss:  -1.4767 | Function Loss:  -1.8812\n",
      "################################  959  ################################\n",
      "Total loss:  -1.3326 | PDE Loss:  -1.4788 | Function Loss:  -1.8764\n",
      "################################  960  ################################\n",
      "Total loss:  -1.3328 | PDE Loss:  -1.4775 | Function Loss:  -1.8803\n",
      "################################  961  ################################\n",
      "Total loss:  -1.3331 | PDE Loss:  -1.4796 | Function Loss:  -1.8763\n",
      "################################  962  ################################\n",
      "Total loss:  -1.3336 | PDE Loss:  -1.4783 | Function Loss:  -1.8811\n",
      "################################  963  ################################\n",
      "Total loss:  -1.3341 | PDE Loss:  -1.4804 | Function Loss:  -1.8779\n",
      "################################  964  ################################\n",
      "Total loss:  -1.3347 | PDE Loss:  -1.4791 | Function Loss:  -1.8832\n",
      "################################  965  ################################\n",
      "Total loss:  -1.3353 | PDE Loss:  -1.4811 | Function Loss:  -1.8803\n",
      "################################  966  ################################\n",
      "Total loss:  -1.3359 | PDE Loss:  -1.4799 | Function Loss:  -1.8853\n",
      "################################  967  ################################\n",
      "Total loss:  -1.3364 | PDE Loss:  -1.4819 | Function Loss:  -1.8819\n",
      "################################  968  ################################\n",
      "Total loss:  -1.3367 | PDE Loss:  -1.4807 | Function Loss:  -1.8862\n",
      "################################  969  ################################\n",
      "Total loss:  -1.337 | PDE Loss:  -1.4827 | Function Loss:  -1.8822\n",
      "################################  970  ################################\n",
      "Total loss:  -1.3372 | PDE Loss:  -1.4815 | Function Loss:  -1.8859\n",
      "################################  971  ################################\n",
      "Total loss:  -1.3373 | PDE Loss:  -1.4835 | Function Loss:  -1.8814\n",
      "################################  972  ################################\n",
      "Total loss:  -1.3375 | PDE Loss:  -1.4822 | Function Loss:  -1.8851\n",
      "################################  973  ################################\n",
      "Total loss:  -1.3377 | PDE Loss:  -1.4842 | Function Loss:  -1.8808\n",
      "################################  974  ################################\n",
      "Total loss:  -1.338 | PDE Loss:  -1.483 | Function Loss:  -1.8851\n",
      "################################  975  ################################\n",
      "Total loss:  -1.3384 | PDE Loss:  -1.485 | Function Loss:  -1.8814\n",
      "################################  976  ################################\n",
      "Total loss:  -1.3389 | PDE Loss:  -1.4838 | Function Loss:  -1.8862\n",
      "################################  977  ################################\n",
      "Total loss:  -1.3395 | PDE Loss:  -1.4858 | Function Loss:  -1.8831\n",
      "################################  978  ################################\n",
      "Total loss:  -1.34 | PDE Loss:  -1.4845 | Function Loss:  -1.888\n",
      "################################  979  ################################\n",
      "Total loss:  -1.3405 | PDE Loss:  -1.4865 | Function Loss:  -1.8848\n",
      "################################  980  ################################\n",
      "Total loss:  -1.3409 | PDE Loss:  -1.4853 | Function Loss:  -1.8895\n",
      "################################  981  ################################\n",
      "Total loss:  -1.3413 | PDE Loss:  -1.4873 | Function Loss:  -1.8858\n",
      "################################  982  ################################\n",
      "Total loss:  -1.3416 | PDE Loss:  -1.4861 | Function Loss:  -1.8899\n",
      "################################  983  ################################\n",
      "Total loss:  -1.3419 | PDE Loss:  -1.488 | Function Loss:  -1.8858\n",
      "################################  984  ################################\n",
      "Total loss:  -1.3421 | PDE Loss:  -1.4868 | Function Loss:  -1.8896\n",
      "################################  985  ################################\n",
      "Total loss:  -1.3423 | PDE Loss:  -1.4888 | Function Loss:  -1.8854\n",
      "################################  986  ################################\n",
      "Total loss:  -1.3425 | PDE Loss:  -1.4875 | Function Loss:  -1.8893\n",
      "################################  987  ################################\n",
      "Total loss:  -1.3428 | PDE Loss:  -1.4895 | Function Loss:  -1.8854\n",
      "################################  988  ################################\n",
      "Total loss:  -1.3432 | PDE Loss:  -1.4883 | Function Loss:  -1.8898\n",
      "################################  989  ################################\n",
      "Total loss:  -1.3436 | PDE Loss:  -1.4903 | Function Loss:  -1.8863\n",
      "################################  990  ################################\n",
      "Total loss:  -1.344 | PDE Loss:  -1.489 | Function Loss:  -1.891\n",
      "################################  991  ################################\n",
      "Total loss:  -1.3445 | PDE Loss:  -1.491 | Function Loss:  -1.8877\n",
      "################################  992  ################################\n",
      "Total loss:  -1.345 | PDE Loss:  -1.4898 | Function Loss:  -1.8924\n",
      "################################  993  ################################\n",
      "Total loss:  -1.3454 | PDE Loss:  -1.4917 | Function Loss:  -1.889\n",
      "################################  994  ################################\n",
      "Total loss:  -1.3458 | PDE Loss:  -1.4905 | Function Loss:  -1.8934\n",
      "################################  995  ################################\n",
      "Total loss:  -1.3461 | PDE Loss:  -1.4924 | Function Loss:  -1.8896\n",
      "################################  996  ################################\n",
      "Total loss:  -1.3464 | PDE Loss:  -1.4912 | Function Loss:  -1.8936\n",
      "################################  997  ################################\n",
      "Total loss:  -1.3466 | PDE Loss:  -1.4932 | Function Loss:  -1.8897\n",
      "################################  998  ################################\n",
      "Total loss:  -1.3469 | PDE Loss:  -1.492 | Function Loss:  -1.8935\n",
      "################################  999  ################################\n",
      "Total loss:  -1.3471 | PDE Loss:  -1.4939 | Function Loss:  -1.8896\n",
      "################################  1000  ################################\n",
      "Total loss:  -1.3474 | PDE Loss:  -1.4927 | Function Loss:  -1.8936\n",
      "################################  1001  ################################\n",
      "Total loss:  -1.3477 | PDE Loss:  -1.4946 | Function Loss:  -1.8899\n",
      "################################  1002  ################################\n",
      "Total loss:  -1.3481 | PDE Loss:  -1.4934 | Function Loss:  -1.8943\n",
      "################################  1003  ################################\n",
      "Total loss:  -1.3485 | PDE Loss:  -1.4953 | Function Loss:  -1.8908\n",
      "################################  1004  ################################\n",
      "Total loss:  -1.3489 | PDE Loss:  -1.4941 | Function Loss:  -1.8954\n",
      "################################  1005  ################################\n",
      "Total loss:  -1.3493 | PDE Loss:  -1.496 | Function Loss:  -1.892\n",
      "################################  1006  ################################\n",
      "Total loss:  -1.3497 | PDE Loss:  -1.4948 | Function Loss:  -1.8965\n",
      "################################  1007  ################################\n",
      "Total loss:  -1.3501 | PDE Loss:  -1.4967 | Function Loss:  -1.893\n",
      "################################  1008  ################################\n",
      "Total loss:  -1.3504 | PDE Loss:  -1.4955 | Function Loss:  -1.8971\n",
      "################################  1009  ################################\n",
      "Total loss:  -1.3507 | PDE Loss:  -1.4974 | Function Loss:  -1.8934\n",
      "################################  1010  ################################\n",
      "Total loss:  -1.351 | PDE Loss:  -1.4962 | Function Loss:  -1.8974\n",
      "################################  1011  ################################\n",
      "Total loss:  -1.3513 | PDE Loss:  -1.4981 | Function Loss:  -1.8935\n",
      "################################  1012  ################################\n",
      "Total loss:  -1.3515 | PDE Loss:  -1.4969 | Function Loss:  -1.8974\n",
      "################################  1013  ################################\n",
      "Total loss:  -1.3518 | PDE Loss:  -1.4988 | Function Loss:  -1.8936\n",
      "################################  1014  ################################\n",
      "Total loss:  -1.3521 | PDE Loss:  -1.4976 | Function Loss:  -1.8977\n",
      "################################  1015  ################################\n",
      "Total loss:  -1.3525 | PDE Loss:  -1.4995 | Function Loss:  -1.8942\n",
      "################################  1016  ################################\n",
      "Total loss:  -1.3528 | PDE Loss:  -1.4983 | Function Loss:  -1.8985\n",
      "################################  1017  ################################\n",
      "Total loss:  -1.3532 | PDE Loss:  -1.5002 | Function Loss:  -1.8951\n",
      "################################  1018  ################################\n",
      "Total loss:  -1.3536 | PDE Loss:  -1.499 | Function Loss:  -1.8995\n",
      "################################  1019  ################################\n",
      "Total loss:  -1.354 | PDE Loss:  -1.5009 | Function Loss:  -1.8961\n",
      "################################  1020  ################################\n",
      "Total loss:  -1.3543 | PDE Loss:  -1.4997 | Function Loss:  -1.9003\n",
      "################################  1021  ################################\n",
      "Total loss:  -1.3547 | PDE Loss:  -1.5016 | Function Loss:  -1.8968\n",
      "################################  1022  ################################\n",
      "Total loss:  -1.355 | PDE Loss:  -1.5004 | Function Loss:  -1.9009\n",
      "################################  1023  ################################\n",
      "Total loss:  -1.3553 | PDE Loss:  -1.5023 | Function Loss:  -1.8972\n",
      "################################  1024  ################################\n",
      "Total loss:  -1.3555 | PDE Loss:  -1.5011 | Function Loss:  -1.9011\n",
      "################################  1025  ################################\n",
      "Total loss:  -1.3558 | PDE Loss:  -1.5029 | Function Loss:  -1.8974\n",
      "################################  1026  ################################\n",
      "Total loss:  -1.3561 | PDE Loss:  -1.5017 | Function Loss:  -1.9013\n",
      "################################  1027  ################################\n",
      "Total loss:  -1.3564 | PDE Loss:  -1.5036 | Function Loss:  -1.8976\n",
      "################################  1028  ################################\n",
      "Total loss:  -1.3567 | PDE Loss:  -1.5024 | Function Loss:  -1.9017\n",
      "################################  1029  ################################\n",
      "Total loss:  -1.357 | PDE Loss:  -1.5043 | Function Loss:  -1.8982\n",
      "################################  1030  ################################\n",
      "Total loss:  -1.3574 | PDE Loss:  -1.5031 | Function Loss:  -1.9024\n",
      "################################  1031  ################################\n",
      "Total loss:  -1.3577 | PDE Loss:  -1.505 | Function Loss:  -1.899\n",
      "################################  1032  ################################\n",
      "Total loss:  -1.3581 | PDE Loss:  -1.5038 | Function Loss:  -1.9033\n",
      "################################  1033  ################################\n",
      "Total loss:  -1.3584 | PDE Loss:  -1.5056 | Function Loss:  -1.8999\n",
      "################################  1034  ################################\n",
      "Total loss:  -1.3588 | PDE Loss:  -1.5044 | Function Loss:  -1.904\n",
      "################################  1035  ################################\n",
      "Total loss:  -1.3591 | PDE Loss:  -1.5063 | Function Loss:  -1.9005\n",
      "################################  1036  ################################\n",
      "Total loss:  -1.3594 | PDE Loss:  -1.5051 | Function Loss:  -1.9045\n",
      "################################  1037  ################################\n",
      "Total loss:  -1.3596 | PDE Loss:  -1.5069 | Function Loss:  -1.9008\n",
      "################################  1038  ################################\n",
      "Total loss:  -1.3599 | PDE Loss:  -1.5057 | Function Loss:  -1.9047\n",
      "################################  1039  ################################\n",
      "Total loss:  -1.3602 | PDE Loss:  -1.5076 | Function Loss:  -1.9011\n",
      "################################  1040  ################################\n",
      "Total loss:  -1.3605 | PDE Loss:  -1.5064 | Function Loss:  -1.905\n",
      "################################  1041  ################################\n",
      "Total loss:  -1.3608 | PDE Loss:  -1.5083 | Function Loss:  -1.9014\n",
      "################################  1042  ################################\n",
      "Total loss:  -1.3611 | PDE Loss:  -1.5071 | Function Loss:  -1.9055\n",
      "################################  1043  ################################\n",
      "Total loss:  -1.3614 | PDE Loss:  -1.5089 | Function Loss:  -1.902\n",
      "################################  1044  ################################\n",
      "Total loss:  -1.3617 | PDE Loss:  -1.5077 | Function Loss:  -1.9062\n",
      "################################  1045  ################################\n",
      "Total loss:  -1.3621 | PDE Loss:  -1.5096 | Function Loss:  -1.9028\n",
      "################################  1046  ################################\n",
      "Total loss:  -1.3624 | PDE Loss:  -1.5084 | Function Loss:  -1.9069\n",
      "################################  1047  ################################\n",
      "Total loss:  -1.3627 | PDE Loss:  -1.5102 | Function Loss:  -1.9035\n",
      "################################  1048  ################################\n",
      "Total loss:  -1.3631 | PDE Loss:  -1.509 | Function Loss:  -1.9075\n",
      "################################  1049  ################################\n",
      "Total loss:  -1.3633 | PDE Loss:  -1.5108 | Function Loss:  -1.904\n",
      "################################  1050  ################################\n",
      "Total loss:  -1.3636 | PDE Loss:  -1.5097 | Function Loss:  -1.908\n",
      "################################  1051  ################################\n",
      "Total loss:  -1.3639 | PDE Loss:  -1.5115 | Function Loss:  -1.9044\n",
      "################################  1052  ################################\n",
      "Total loss:  -1.3642 | PDE Loss:  -1.5103 | Function Loss:  -1.9083\n",
      "################################  1053  ################################\n",
      "Total loss:  -1.3645 | PDE Loss:  -1.5121 | Function Loss:  -1.9047\n",
      "################################  1054  ################################\n",
      "Total loss:  -1.3647 | PDE Loss:  -1.5109 | Function Loss:  -1.9086\n",
      "################################  1055  ################################\n",
      "Total loss:  -1.365 | PDE Loss:  -1.5128 | Function Loss:  -1.9051\n",
      "################################  1056  ################################\n",
      "Total loss:  -1.3653 | PDE Loss:  -1.5116 | Function Loss:  -1.9091\n",
      "################################  1057  ################################\n",
      "Total loss:  -1.3656 | PDE Loss:  -1.5134 | Function Loss:  -1.9057\n",
      "################################  1058  ################################\n",
      "Total loss:  -1.366 | PDE Loss:  -1.5122 | Function Loss:  -1.9097\n",
      "################################  1059  ################################\n",
      "Total loss:  -1.3663 | PDE Loss:  -1.514 | Function Loss:  -1.9063\n",
      "################################  1060  ################################\n",
      "Total loss:  -1.3666 | PDE Loss:  -1.5128 | Function Loss:  -1.9103\n",
      "################################  1061  ################################\n",
      "Total loss:  -1.3669 | PDE Loss:  -1.5147 | Function Loss:  -1.9069\n",
      "################################  1062  ################################\n",
      "Total loss:  -1.3672 | PDE Loss:  -1.5135 | Function Loss:  -1.9109\n",
      "################################  1063  ################################\n",
      "Total loss:  -1.3675 | PDE Loss:  -1.5153 | Function Loss:  -1.9074\n",
      "################################  1064  ################################\n",
      "Total loss:  -1.3678 | PDE Loss:  -1.5141 | Function Loss:  -1.9113\n",
      "################################  1065  ################################\n",
      "Total loss:  -1.368 | PDE Loss:  -1.5159 | Function Loss:  -1.9077\n",
      "################################  1066  ################################\n",
      "Total loss:  -1.3683 | PDE Loss:  -1.5147 | Function Loss:  -1.9116\n",
      "################################  1067  ################################\n",
      "Total loss:  -1.3686 | PDE Loss:  -1.5165 | Function Loss:  -1.9081\n",
      "################################  1068  ################################\n",
      "Total loss:  -1.3689 | PDE Loss:  -1.5154 | Function Loss:  -1.912\n",
      "################################  1069  ################################\n",
      "Total loss:  -1.3692 | PDE Loss:  -1.5172 | Function Loss:  -1.9085\n",
      "################################  1070  ################################\n",
      "Total loss:  -1.3694 | PDE Loss:  -1.516 | Function Loss:  -1.9125\n",
      "################################  1071  ################################\n",
      "Total loss:  -1.3697 | PDE Loss:  -1.5178 | Function Loss:  -1.9091\n",
      "################################  1072  ################################\n",
      "Total loss:  -1.37 | PDE Loss:  -1.5166 | Function Loss:  -1.9131\n",
      "################################  1073  ################################\n",
      "Total loss:  -1.3703 | PDE Loss:  -1.5184 | Function Loss:  -1.9096\n",
      "################################  1074  ################################\n",
      "Total loss:  -1.3706 | PDE Loss:  -1.5172 | Function Loss:  -1.9136\n",
      "################################  1075  ################################\n",
      "Total loss:  -1.3709 | PDE Loss:  -1.519 | Function Loss:  -1.9101\n",
      "################################  1076  ################################\n",
      "Total loss:  -1.3712 | PDE Loss:  -1.5178 | Function Loss:  -1.9141\n",
      "################################  1077  ################################\n",
      "Total loss:  -1.3715 | PDE Loss:  -1.5196 | Function Loss:  -1.9106\n",
      "################################  1078  ################################\n",
      "Total loss:  -1.3718 | PDE Loss:  -1.5184 | Function Loss:  -1.9145\n",
      "################################  1079  ################################\n",
      "Total loss:  -1.372 | PDE Loss:  -1.5202 | Function Loss:  -1.911\n",
      "################################  1080  ################################\n",
      "Total loss:  -1.3723 | PDE Loss:  -1.5191 | Function Loss:  -1.9148\n",
      "################################  1081  ################################\n",
      "Total loss:  -1.3726 | PDE Loss:  -1.5208 | Function Loss:  -1.9113\n",
      "################################  1082  ################################\n",
      "Total loss:  -1.3729 | PDE Loss:  -1.5197 | Function Loss:  -1.9152\n",
      "################################  1083  ################################\n",
      "Total loss:  -1.3731 | PDE Loss:  -1.5215 | Function Loss:  -1.9118\n",
      "################################  1084  ################################\n",
      "Total loss:  -1.3734 | PDE Loss:  -1.5203 | Function Loss:  -1.9157\n",
      "################################  1085  ################################\n",
      "Total loss:  -1.3737 | PDE Loss:  -1.5221 | Function Loss:  -1.9123\n",
      "################################  1086  ################################\n",
      "Total loss:  -1.374 | PDE Loss:  -1.5209 | Function Loss:  -1.9162\n",
      "################################  1087  ################################\n",
      "Total loss:  -1.3743 | PDE Loss:  -1.5227 | Function Loss:  -1.9128\n",
      "################################  1088  ################################\n",
      "Total loss:  -1.3746 | PDE Loss:  -1.5215 | Function Loss:  -1.9167\n",
      "################################  1089  ################################\n",
      "Total loss:  -1.3748 | PDE Loss:  -1.5233 | Function Loss:  -1.9132\n",
      "################################  1090  ################################\n",
      "Total loss:  -1.3751 | PDE Loss:  -1.5221 | Function Loss:  -1.9171\n",
      "################################  1091  ################################\n",
      "Total loss:  -1.3754 | PDE Loss:  -1.5239 | Function Loss:  -1.9137\n",
      "################################  1092  ################################\n",
      "Total loss:  -1.3757 | PDE Loss:  -1.5227 | Function Loss:  -1.9175\n",
      "################################  1093  ################################\n",
      "Total loss:  -1.3759 | PDE Loss:  -1.5245 | Function Loss:  -1.914\n",
      "################################  1094  ################################\n",
      "Total loss:  -1.3762 | PDE Loss:  -1.5233 | Function Loss:  -1.9179\n",
      "################################  1095  ################################\n",
      "Total loss:  -1.3765 | PDE Loss:  -1.5251 | Function Loss:  -1.9144\n",
      "################################  1096  ################################\n",
      "Total loss:  -1.3767 | PDE Loss:  -1.5239 | Function Loss:  -1.9183\n",
      "################################  1097  ################################\n",
      "Total loss:  -1.377 | PDE Loss:  -1.5257 | Function Loss:  -1.9148\n",
      "################################  1098  ################################\n",
      "Total loss:  -1.3773 | PDE Loss:  -1.5245 | Function Loss:  -1.9187\n",
      "################################  1099  ################################\n",
      "Total loss:  -1.3776 | PDE Loss:  -1.5262 | Function Loss:  -1.9153\n",
      "################################  1100  ################################\n",
      "Total loss:  -1.3778 | PDE Loss:  -1.525 | Function Loss:  -1.9192\n",
      "################################  1101  ################################\n",
      "Total loss:  -1.3781 | PDE Loss:  -1.5268 | Function Loss:  -1.9158\n",
      "################################  1102  ################################\n",
      "Total loss:  -1.3784 | PDE Loss:  -1.5256 | Function Loss:  -1.9196\n",
      "################################  1103  ################################\n",
      "Total loss:  -1.3787 | PDE Loss:  -1.5274 | Function Loss:  -1.9162\n",
      "################################  1104  ################################\n",
      "Total loss:  -1.3789 | PDE Loss:  -1.5262 | Function Loss:  -1.9201\n",
      "################################  1105  ################################\n",
      "Total loss:  -1.3792 | PDE Loss:  -1.528 | Function Loss:  -1.9166\n",
      "################################  1106  ################################\n",
      "Total loss:  -1.3794 | PDE Loss:  -1.5268 | Function Loss:  -1.9204\n",
      "################################  1107  ################################\n",
      "Total loss:  -1.3797 | PDE Loss:  -1.5286 | Function Loss:  -1.917\n",
      "################################  1108  ################################\n",
      "Total loss:  -1.38 | PDE Loss:  -1.5274 | Function Loss:  -1.9208\n",
      "################################  1109  ################################\n",
      "Total loss:  -1.3802 | PDE Loss:  -1.5292 | Function Loss:  -1.9173\n",
      "################################  1110  ################################\n",
      "Total loss:  -1.3805 | PDE Loss:  -1.528 | Function Loss:  -1.9211\n",
      "################################  1111  ################################\n",
      "Total loss:  -1.3807 | PDE Loss:  -1.5298 | Function Loss:  -1.9177\n",
      "################################  1112  ################################\n",
      "Total loss:  -1.381 | PDE Loss:  -1.5286 | Function Loss:  -1.9215\n",
      "################################  1113  ################################\n",
      "Total loss:  -1.3813 | PDE Loss:  -1.5303 | Function Loss:  -1.9181\n",
      "################################  1114  ################################\n",
      "Total loss:  -1.3815 | PDE Loss:  -1.5291 | Function Loss:  -1.922\n",
      "################################  1115  ################################\n",
      "Total loss:  -1.3818 | PDE Loss:  -1.5309 | Function Loss:  -1.9185\n",
      "################################  1116  ################################\n",
      "Total loss:  -1.3821 | PDE Loss:  -1.5297 | Function Loss:  -1.9224\n",
      "################################  1117  ################################\n",
      "Total loss:  -1.3823 | PDE Loss:  -1.5315 | Function Loss:  -1.919\n",
      "################################  1118  ################################\n",
      "Total loss:  -1.3826 | PDE Loss:  -1.5303 | Function Loss:  -1.9228\n",
      "################################  1119  ################################\n",
      "Total loss:  -1.3829 | PDE Loss:  -1.5321 | Function Loss:  -1.9193\n",
      "################################  1120  ################################\n",
      "Total loss:  -1.3831 | PDE Loss:  -1.5309 | Function Loss:  -1.9232\n",
      "################################  1121  ################################\n",
      "Total loss:  -1.3834 | PDE Loss:  -1.5326 | Function Loss:  -1.9197\n",
      "################################  1122  ################################\n",
      "Total loss:  -1.3836 | PDE Loss:  -1.5314 | Function Loss:  -1.9235\n",
      "################################  1123  ################################\n",
      "Total loss:  -1.3839 | PDE Loss:  -1.5332 | Function Loss:  -1.9201\n",
      "################################  1124  ################################\n",
      "Total loss:  -1.3841 | PDE Loss:  -1.532 | Function Loss:  -1.9239\n",
      "################################  1125  ################################\n",
      "Total loss:  -1.3844 | PDE Loss:  -1.5338 | Function Loss:  -1.9204\n",
      "################################  1126  ################################\n",
      "Total loss:  -1.3847 | PDE Loss:  -1.5326 | Function Loss:  -1.9243\n",
      "################################  1127  ################################\n",
      "Total loss:  -1.3849 | PDE Loss:  -1.5344 | Function Loss:  -1.9208\n",
      "################################  1128  ################################\n",
      "Total loss:  -1.3852 | PDE Loss:  -1.5331 | Function Loss:  -1.9247\n",
      "################################  1129  ################################\n",
      "Total loss:  -1.3854 | PDE Loss:  -1.5349 | Function Loss:  -1.9212\n",
      "################################  1130  ################################\n",
      "Total loss:  -1.3857 | PDE Loss:  -1.5337 | Function Loss:  -1.9251\n",
      "################################  1131  ################################\n",
      "Total loss:  -1.3859 | PDE Loss:  -1.5355 | Function Loss:  -1.9216\n",
      "################################  1132  ################################\n",
      "Total loss:  -1.3862 | PDE Loss:  -1.5343 | Function Loss:  -1.9255\n",
      "################################  1133  ################################\n",
      "Total loss:  -1.3865 | PDE Loss:  -1.536 | Function Loss:  -1.922\n",
      "################################  1134  ################################\n",
      "Total loss:  -1.3867 | PDE Loss:  -1.5348 | Function Loss:  -1.9258\n",
      "################################  1135  ################################\n",
      "Total loss:  -1.3869 | PDE Loss:  -1.5366 | Function Loss:  -1.9223\n",
      "################################  1136  ################################\n",
      "Total loss:  -1.3872 | PDE Loss:  -1.5354 | Function Loss:  -1.9261\n",
      "################################  1137  ################################\n",
      "Total loss:  -1.3874 | PDE Loss:  -1.5372 | Function Loss:  -1.9226\n",
      "################################  1138  ################################\n",
      "Total loss:  -1.3877 | PDE Loss:  -1.5359 | Function Loss:  -1.9265\n",
      "################################  1139  ################################\n",
      "Total loss:  -1.3879 | PDE Loss:  -1.5377 | Function Loss:  -1.923\n",
      "################################  1140  ################################\n",
      "Total loss:  -1.3882 | PDE Loss:  -1.5365 | Function Loss:  -1.9269\n",
      "################################  1141  ################################\n",
      "Total loss:  -1.3884 | PDE Loss:  -1.5383 | Function Loss:  -1.9234\n",
      "################################  1142  ################################\n",
      "Total loss:  -1.3887 | PDE Loss:  -1.5371 | Function Loss:  -1.9272\n",
      "################################  1143  ################################\n",
      "Total loss:  -1.3889 | PDE Loss:  -1.5388 | Function Loss:  -1.9237\n",
      "################################  1144  ################################\n",
      "Total loss:  -1.3892 | PDE Loss:  -1.5376 | Function Loss:  -1.9276\n",
      "################################  1145  ################################\n",
      "Total loss:  -1.3894 | PDE Loss:  -1.5394 | Function Loss:  -1.9241\n",
      "################################  1146  ################################\n",
      "Total loss:  -1.3897 | PDE Loss:  -1.5382 | Function Loss:  -1.928\n",
      "################################  1147  ################################\n",
      "Total loss:  -1.3899 | PDE Loss:  -1.54 | Function Loss:  -1.9245\n",
      "################################  1148  ################################\n",
      "Total loss:  -1.3902 | PDE Loss:  -1.5387 | Function Loss:  -1.9283\n",
      "################################  1149  ################################\n",
      "Total loss:  -1.3904 | PDE Loss:  -1.5405 | Function Loss:  -1.9248\n",
      "################################  1150  ################################\n",
      "Total loss:  -1.3907 | PDE Loss:  -1.5393 | Function Loss:  -1.9286\n",
      "################################  1151  ################################\n",
      "Total loss:  -1.3909 | PDE Loss:  -1.5411 | Function Loss:  -1.9251\n",
      "################################  1152  ################################\n",
      "Total loss:  -1.3912 | PDE Loss:  -1.5398 | Function Loss:  -1.929\n",
      "################################  1153  ################################\n",
      "Total loss:  -1.3914 | PDE Loss:  -1.5416 | Function Loss:  -1.9254\n",
      "################################  1154  ################################\n",
      "Total loss:  -1.3916 | PDE Loss:  -1.5404 | Function Loss:  -1.9293\n",
      "################################  1155  ################################\n",
      "Total loss:  -1.3919 | PDE Loss:  -1.5422 | Function Loss:  -1.9258\n",
      "################################  1156  ################################\n",
      "Total loss:  -1.3921 | PDE Loss:  -1.5409 | Function Loss:  -1.9297\n",
      "################################  1157  ################################\n",
      "Total loss:  -1.3924 | PDE Loss:  -1.5427 | Function Loss:  -1.9261\n",
      "################################  1158  ################################\n",
      "Total loss:  -1.3926 | PDE Loss:  -1.5415 | Function Loss:  -1.93\n",
      "################################  1159  ################################\n",
      "Total loss:  -1.3929 | PDE Loss:  -1.5432 | Function Loss:  -1.9265\n",
      "################################  1160  ################################\n",
      "Total loss:  -1.3931 | PDE Loss:  -1.542 | Function Loss:  -1.9304\n",
      "################################  1161  ################################\n",
      "Total loss:  -1.3934 | PDE Loss:  -1.5438 | Function Loss:  -1.9268\n",
      "################################  1162  ################################\n",
      "Total loss:  -1.3936 | PDE Loss:  -1.5425 | Function Loss:  -1.9307\n",
      "################################  1163  ################################\n",
      "Total loss:  -1.3938 | PDE Loss:  -1.5443 | Function Loss:  -1.9271\n",
      "################################  1164  ################################\n",
      "Total loss:  -1.3941 | PDE Loss:  -1.5431 | Function Loss:  -1.931\n",
      "################################  1165  ################################\n",
      "Total loss:  -1.3943 | PDE Loss:  -1.5449 | Function Loss:  -1.9274\n",
      "################################  1166  ################################\n",
      "Total loss:  -1.3945 | PDE Loss:  -1.5436 | Function Loss:  -1.9313\n",
      "################################  1167  ################################\n",
      "Total loss:  -1.3948 | PDE Loss:  -1.5454 | Function Loss:  -1.9277\n",
      "################################  1168  ################################\n",
      "Total loss:  -1.395 | PDE Loss:  -1.5442 | Function Loss:  -1.9316\n",
      "################################  1169  ################################\n",
      "Total loss:  -1.3952 | PDE Loss:  -1.546 | Function Loss:  -1.9281\n",
      "################################  1170  ################################\n",
      "Total loss:  -1.3955 | PDE Loss:  -1.5447 | Function Loss:  -1.932\n",
      "################################  1171  ################################\n",
      "Total loss:  -1.3957 | PDE Loss:  -1.5465 | Function Loss:  -1.9284\n",
      "################################  1172  ################################\n",
      "Total loss:  -1.396 | PDE Loss:  -1.5452 | Function Loss:  -1.9323\n",
      "################################  1173  ################################\n",
      "Total loss:  -1.3962 | PDE Loss:  -1.547 | Function Loss:  -1.9288\n",
      "################################  1174  ################################\n",
      "Total loss:  -1.3964 | PDE Loss:  -1.5458 | Function Loss:  -1.9326\n",
      "################################  1175  ################################\n",
      "Total loss:  -1.3967 | PDE Loss:  -1.5476 | Function Loss:  -1.9291\n",
      "################################  1176  ################################\n",
      "Total loss:  -1.3969 | PDE Loss:  -1.5463 | Function Loss:  -1.9329\n",
      "################################  1177  ################################\n",
      "Total loss:  -1.3971 | PDE Loss:  -1.5481 | Function Loss:  -1.9293\n",
      "################################  1178  ################################\n",
      "Total loss:  -1.3974 | PDE Loss:  -1.5468 | Function Loss:  -1.9332\n",
      "################################  1179  ################################\n",
      "Total loss:  -1.3976 | PDE Loss:  -1.5486 | Function Loss:  -1.9296\n",
      "################################  1180  ################################\n",
      "Total loss:  -1.3978 | PDE Loss:  -1.5473 | Function Loss:  -1.9335\n",
      "################################  1181  ################################\n",
      "Total loss:  -1.3981 | PDE Loss:  -1.5492 | Function Loss:  -1.9299\n",
      "################################  1182  ################################\n",
      "Total loss:  -1.3983 | PDE Loss:  -1.5479 | Function Loss:  -1.9338\n",
      "################################  1183  ################################\n",
      "Total loss:  -1.3985 | PDE Loss:  -1.5497 | Function Loss:  -1.9303\n",
      "################################  1184  ################################\n",
      "Total loss:  -1.3988 | PDE Loss:  -1.5484 | Function Loss:  -1.9342\n",
      "################################  1185  ################################\n",
      "Total loss:  -1.399 | PDE Loss:  -1.5502 | Function Loss:  -1.9306\n",
      "################################  1186  ################################\n",
      "Total loss:  -1.3992 | PDE Loss:  -1.5489 | Function Loss:  -1.9345\n",
      "################################  1187  ################################\n",
      "Total loss:  -1.3995 | PDE Loss:  -1.5507 | Function Loss:  -1.9309\n",
      "################################  1188  ################################\n",
      "Total loss:  -1.3997 | PDE Loss:  -1.5494 | Function Loss:  -1.9348\n",
      "################################  1189  ################################\n",
      "Total loss:  -1.3999 | PDE Loss:  -1.5513 | Function Loss:  -1.9312\n",
      "################################  1190  ################################\n",
      "Total loss:  -1.4001 | PDE Loss:  -1.55 | Function Loss:  -1.9351\n",
      "################################  1191  ################################\n",
      "Total loss:  -1.4004 | PDE Loss:  -1.5518 | Function Loss:  -1.9315\n",
      "################################  1192  ################################\n",
      "Total loss:  -1.4006 | PDE Loss:  -1.5505 | Function Loss:  -1.9354\n",
      "################################  1193  ################################\n",
      "Total loss:  -1.4008 | PDE Loss:  -1.5523 | Function Loss:  -1.9317\n",
      "################################  1194  ################################\n",
      "Total loss:  -1.401 | PDE Loss:  -1.551 | Function Loss:  -1.9356\n",
      "################################  1195  ################################\n",
      "Total loss:  -1.4013 | PDE Loss:  -1.5528 | Function Loss:  -1.932\n",
      "################################  1196  ################################\n",
      "Total loss:  -1.4015 | PDE Loss:  -1.5515 | Function Loss:  -1.9359\n",
      "################################  1197  ################################\n",
      "Total loss:  -1.4017 | PDE Loss:  -1.5534 | Function Loss:  -1.9323\n",
      "################################  1198  ################################\n",
      "Total loss:  -1.402 | PDE Loss:  -1.5521 | Function Loss:  -1.9362\n",
      "################################  1199  ################################\n",
      "Total loss:  -1.4022 | PDE Loss:  -1.5539 | Function Loss:  -1.9326\n",
      "################################  1200  ################################\n",
      "Total loss:  -1.4024 | PDE Loss:  -1.5526 | Function Loss:  -1.9366\n",
      "################################  1201  ################################\n",
      "Total loss:  -1.4026 | PDE Loss:  -1.5544 | Function Loss:  -1.9329\n",
      "################################  1202  ################################\n",
      "Total loss:  -1.4029 | PDE Loss:  -1.5531 | Function Loss:  -1.9369\n",
      "################################  1203  ################################\n",
      "Total loss:  -1.4031 | PDE Loss:  -1.5549 | Function Loss:  -1.9332\n",
      "################################  1204  ################################\n",
      "Total loss:  -1.4033 | PDE Loss:  -1.5536 | Function Loss:  -1.9371\n",
      "################################  1205  ################################\n",
      "Total loss:  -1.4035 | PDE Loss:  -1.5554 | Function Loss:  -1.9335\n",
      "################################  1206  ################################\n",
      "Total loss:  -1.4037 | PDE Loss:  -1.5541 | Function Loss:  -1.9374\n",
      "################################  1207  ################################\n",
      "Total loss:  -1.404 | PDE Loss:  -1.5559 | Function Loss:  -1.9338\n",
      "################################  1208  ################################\n",
      "Total loss:  -1.4042 | PDE Loss:  -1.5546 | Function Loss:  -1.9377\n",
      "################################  1209  ################################\n",
      "Total loss:  -1.4044 | PDE Loss:  -1.5565 | Function Loss:  -1.934\n",
      "################################  1210  ################################\n",
      "Total loss:  -1.4046 | PDE Loss:  -1.5551 | Function Loss:  -1.9379\n",
      "################################  1211  ################################\n",
      "Total loss:  -1.4049 | PDE Loss:  -1.557 | Function Loss:  -1.9343\n",
      "################################  1212  ################################\n",
      "Total loss:  -1.4051 | PDE Loss:  -1.5556 | Function Loss:  -1.9382\n",
      "################################  1213  ################################\n",
      "Total loss:  -1.4053 | PDE Loss:  -1.5575 | Function Loss:  -1.9346\n",
      "################################  1214  ################################\n",
      "Total loss:  -1.4055 | PDE Loss:  -1.5562 | Function Loss:  -1.9385\n",
      "################################  1215  ################################\n",
      "Total loss:  -1.4057 | PDE Loss:  -1.558 | Function Loss:  -1.9349\n",
      "################################  1216  ################################\n",
      "Total loss:  -1.406 | PDE Loss:  -1.5567 | Function Loss:  -1.9388\n",
      "################################  1217  ################################\n",
      "Total loss:  -1.4062 | PDE Loss:  -1.5585 | Function Loss:  -1.9352\n",
      "################################  1218  ################################\n",
      "Total loss:  -1.4064 | PDE Loss:  -1.5572 | Function Loss:  -1.9391\n",
      "################################  1219  ################################\n",
      "Total loss:  -1.4066 | PDE Loss:  -1.559 | Function Loss:  -1.9354\n",
      "################################  1220  ################################\n",
      "Total loss:  -1.4068 | PDE Loss:  -1.5577 | Function Loss:  -1.9394\n",
      "################################  1221  ################################\n",
      "Total loss:  -1.4071 | PDE Loss:  -1.5595 | Function Loss:  -1.9357\n",
      "################################  1222  ################################\n",
      "Total loss:  -1.4073 | PDE Loss:  -1.5582 | Function Loss:  -1.9396\n",
      "################################  1223  ################################\n",
      "Total loss:  -1.4075 | PDE Loss:  -1.56 | Function Loss:  -1.9359\n",
      "################################  1224  ################################\n",
      "Total loss:  -1.4077 | PDE Loss:  -1.5587 | Function Loss:  -1.9399\n",
      "################################  1225  ################################\n",
      "Total loss:  -1.4079 | PDE Loss:  -1.5605 | Function Loss:  -1.9362\n",
      "################################  1226  ################################\n",
      "Total loss:  -1.4081 | PDE Loss:  -1.5592 | Function Loss:  -1.9401\n",
      "################################  1227  ################################\n",
      "Total loss:  -1.4083 | PDE Loss:  -1.561 | Function Loss:  -1.9364\n",
      "################################  1228  ################################\n",
      "Total loss:  -1.4086 | PDE Loss:  -1.5597 | Function Loss:  -1.9404\n",
      "################################  1229  ################################\n",
      "Total loss:  -1.4088 | PDE Loss:  -1.5615 | Function Loss:  -1.9367\n",
      "################################  1230  ################################\n",
      "Total loss:  -1.409 | PDE Loss:  -1.5602 | Function Loss:  -1.9407\n",
      "################################  1231  ################################\n",
      "Total loss:  -1.4092 | PDE Loss:  -1.562 | Function Loss:  -1.937\n",
      "################################  1232  ################################\n",
      "Total loss:  -1.4094 | PDE Loss:  -1.5607 | Function Loss:  -1.941\n",
      "################################  1233  ################################\n",
      "Total loss:  -1.4096 | PDE Loss:  -1.5625 | Function Loss:  -1.9373\n",
      "################################  1234  ################################\n",
      "Total loss:  -1.4099 | PDE Loss:  -1.5612 | Function Loss:  -1.9412\n",
      "################################  1235  ################################\n",
      "Total loss:  -1.4101 | PDE Loss:  -1.563 | Function Loss:  -1.9375\n",
      "################################  1236  ################################\n",
      "Total loss:  -1.4103 | PDE Loss:  -1.5617 | Function Loss:  -1.9414\n",
      "################################  1237  ################################\n",
      "Total loss:  -1.4105 | PDE Loss:  -1.5635 | Function Loss:  -1.9377\n",
      "################################  1238  ################################\n",
      "Total loss:  -1.4107 | PDE Loss:  -1.5622 | Function Loss:  -1.9417\n",
      "################################  1239  ################################\n",
      "Total loss:  -1.4109 | PDE Loss:  -1.564 | Function Loss:  -1.938\n",
      "################################  1240  ################################\n",
      "Total loss:  -1.4111 | PDE Loss:  -1.5627 | Function Loss:  -1.942\n",
      "################################  1241  ################################\n",
      "Total loss:  -1.4113 | PDE Loss:  -1.5645 | Function Loss:  -1.9383\n",
      "################################  1242  ################################\n",
      "Total loss:  -1.4116 | PDE Loss:  -1.5632 | Function Loss:  -1.9423\n",
      "################################  1243  ################################\n",
      "Total loss:  -1.4118 | PDE Loss:  -1.565 | Function Loss:  -1.9385\n",
      "################################  1244  ################################\n",
      "Total loss:  -1.412 | PDE Loss:  -1.5636 | Function Loss:  -1.9425\n",
      "################################  1245  ################################\n",
      "Total loss:  -1.4122 | PDE Loss:  -1.5655 | Function Loss:  -1.9388\n",
      "################################  1246  ################################\n",
      "Total loss:  -1.4124 | PDE Loss:  -1.5641 | Function Loss:  -1.9427\n",
      "################################  1247  ################################\n",
      "Total loss:  -1.4126 | PDE Loss:  -1.566 | Function Loss:  -1.939\n",
      "################################  1248  ################################\n",
      "Total loss:  -1.4128 | PDE Loss:  -1.5646 | Function Loss:  -1.9429\n",
      "################################  1249  ################################\n",
      "Total loss:  -1.413 | PDE Loss:  -1.5665 | Function Loss:  -1.9392\n",
      "################################  1250  ################################\n",
      "Total loss:  -1.4132 | PDE Loss:  -1.5651 | Function Loss:  -1.9432\n",
      "################################  1251  ################################\n",
      "Total loss:  -1.4134 | PDE Loss:  -1.567 | Function Loss:  -1.9395\n",
      "################################  1252  ################################\n",
      "Total loss:  -1.4136 | PDE Loss:  -1.5656 | Function Loss:  -1.9434\n",
      "################################  1253  ################################\n",
      "Total loss:  -1.4139 | PDE Loss:  -1.5675 | Function Loss:  -1.9397\n",
      "################################  1254  ################################\n",
      "Total loss:  -1.4141 | PDE Loss:  -1.5661 | Function Loss:  -1.9437\n",
      "################################  1255  ################################\n",
      "Total loss:  -1.4143 | PDE Loss:  -1.568 | Function Loss:  -1.94\n",
      "################################  1256  ################################\n",
      "Total loss:  -1.4145 | PDE Loss:  -1.5666 | Function Loss:  -1.944\n",
      "################################  1257  ################################\n",
      "Total loss:  -1.4147 | PDE Loss:  -1.5685 | Function Loss:  -1.9402\n",
      "################################  1258  ################################\n",
      "Total loss:  -1.4149 | PDE Loss:  -1.5671 | Function Loss:  -1.9442\n",
      "################################  1259  ################################\n",
      "Total loss:  -1.4151 | PDE Loss:  -1.5689 | Function Loss:  -1.9405\n",
      "################################  1260  ################################\n",
      "Total loss:  -1.4153 | PDE Loss:  -1.5675 | Function Loss:  -1.9445\n",
      "################################  1261  ################################\n",
      "Total loss:  -1.4155 | PDE Loss:  -1.5694 | Function Loss:  -1.9407\n",
      "################################  1262  ################################\n",
      "Total loss:  -1.4157 | PDE Loss:  -1.568 | Function Loss:  -1.9447\n",
      "################################  1263  ################################\n",
      "Total loss:  -1.4159 | PDE Loss:  -1.5699 | Function Loss:  -1.9409\n",
      "################################  1264  ################################\n",
      "Total loss:  -1.4161 | PDE Loss:  -1.5685 | Function Loss:  -1.9449\n",
      "################################  1265  ################################\n",
      "Total loss:  -1.4163 | PDE Loss:  -1.5704 | Function Loss:  -1.9411\n",
      "################################  1266  ################################\n",
      "Total loss:  -1.4165 | PDE Loss:  -1.569 | Function Loss:  -1.9451\n",
      "################################  1267  ################################\n",
      "Total loss:  -1.4167 | PDE Loss:  -1.5709 | Function Loss:  -1.9414\n",
      "################################  1268  ################################\n",
      "Total loss:  -1.4169 | PDE Loss:  -1.5695 | Function Loss:  -1.9454\n",
      "################################  1269  ################################\n",
      "Total loss:  -1.4171 | PDE Loss:  -1.5714 | Function Loss:  -1.9416\n",
      "################################  1270  ################################\n",
      "Total loss:  -1.4173 | PDE Loss:  -1.57 | Function Loss:  -1.9456\n",
      "################################  1271  ################################\n",
      "Total loss:  -1.4176 | PDE Loss:  -1.5718 | Function Loss:  -1.9419\n",
      "################################  1272  ################################\n",
      "Total loss:  -1.4177 | PDE Loss:  -1.5704 | Function Loss:  -1.9458\n",
      "################################  1273  ################################\n",
      "Total loss:  -1.418 | PDE Loss:  -1.5723 | Function Loss:  -1.9421\n",
      "################################  1274  ################################\n",
      "Total loss:  -1.4181 | PDE Loss:  -1.5709 | Function Loss:  -1.9461\n",
      "################################  1275  ################################\n",
      "Total loss:  -1.4183 | PDE Loss:  -1.5728 | Function Loss:  -1.9423\n",
      "################################  1276  ################################\n",
      "Total loss:  -1.4185 | PDE Loss:  -1.5714 | Function Loss:  -1.9463\n",
      "################################  1277  ################################\n",
      "Total loss:  -1.4187 | PDE Loss:  -1.5733 | Function Loss:  -1.9425\n",
      "################################  1278  ################################\n",
      "Total loss:  -1.4189 | PDE Loss:  -1.5719 | Function Loss:  -1.9465\n",
      "################################  1279  ################################\n",
      "Total loss:  -1.4192 | PDE Loss:  -1.5738 | Function Loss:  -1.9427\n",
      "################################  1280  ################################\n",
      "Total loss:  -1.4194 | PDE Loss:  -1.5723 | Function Loss:  -1.9468\n",
      "################################  1281  ################################\n",
      "Total loss:  -1.4196 | PDE Loss:  -1.5742 | Function Loss:  -1.943\n",
      "################################  1282  ################################\n",
      "Total loss:  -1.4198 | PDE Loss:  -1.5728 | Function Loss:  -1.947\n",
      "################################  1283  ################################\n",
      "Total loss:  -1.42 | PDE Loss:  -1.5747 | Function Loss:  -1.9432\n",
      "################################  1284  ################################\n",
      "Total loss:  -1.4202 | PDE Loss:  -1.5733 | Function Loss:  -1.9472\n",
      "################################  1285  ################################\n",
      "Total loss:  -1.4204 | PDE Loss:  -1.5752 | Function Loss:  -1.9434\n",
      "################################  1286  ################################\n",
      "Total loss:  -1.4205 | PDE Loss:  -1.5737 | Function Loss:  -1.9474\n",
      "################################  1287  ################################\n",
      "Total loss:  -1.4207 | PDE Loss:  -1.5757 | Function Loss:  -1.9436\n",
      "################################  1288  ################################\n",
      "Total loss:  -1.4209 | PDE Loss:  -1.5742 | Function Loss:  -1.9476\n",
      "################################  1289  ################################\n",
      "Total loss:  -1.4211 | PDE Loss:  -1.5761 | Function Loss:  -1.9438\n",
      "################################  1290  ################################\n",
      "Total loss:  -1.4213 | PDE Loss:  -1.5747 | Function Loss:  -1.9479\n",
      "################################  1291  ################################\n",
      "Total loss:  -1.4215 | PDE Loss:  -1.5766 | Function Loss:  -1.944\n",
      "################################  1292  ################################\n",
      "Total loss:  -1.4217 | PDE Loss:  -1.5751 | Function Loss:  -1.9481\n",
      "################################  1293  ################################\n",
      "Total loss:  -1.4219 | PDE Loss:  -1.5771 | Function Loss:  -1.9442\n",
      "################################  1294  ################################\n",
      "Total loss:  -1.4221 | PDE Loss:  -1.5756 | Function Loss:  -1.9483\n",
      "################################  1295  ################################\n",
      "Total loss:  -1.4223 | PDE Loss:  -1.5776 | Function Loss:  -1.9445\n",
      "################################  1296  ################################\n",
      "Total loss:  -1.4225 | PDE Loss:  -1.5761 | Function Loss:  -1.9486\n",
      "################################  1297  ################################\n",
      "Total loss:  -1.4227 | PDE Loss:  -1.578 | Function Loss:  -1.9447\n",
      "################################  1298  ################################\n",
      "Total loss:  -1.4229 | PDE Loss:  -1.5766 | Function Loss:  -1.9488\n",
      "################################  1299  ################################\n",
      "Total loss:  -1.4231 | PDE Loss:  -1.5785 | Function Loss:  -1.9449\n",
      "################################  1300  ################################\n",
      "Total loss:  -1.4233 | PDE Loss:  -1.577 | Function Loss:  -1.9489\n",
      "################################  1301  ################################\n",
      "Total loss:  -1.4235 | PDE Loss:  -1.5789 | Function Loss:  -1.9451\n",
      "################################  1302  ################################\n",
      "Total loss:  -1.4237 | PDE Loss:  -1.5775 | Function Loss:  -1.9491\n",
      "################################  1303  ################################\n",
      "Total loss:  -1.4239 | PDE Loss:  -1.5794 | Function Loss:  -1.9453\n",
      "################################  1304  ################################\n",
      "Total loss:  -1.4241 | PDE Loss:  -1.578 | Function Loss:  -1.9493\n",
      "################################  1305  ################################\n",
      "Total loss:  -1.4243 | PDE Loss:  -1.5799 | Function Loss:  -1.9455\n",
      "################################  1306  ################################\n",
      "Total loss:  -1.4244 | PDE Loss:  -1.5784 | Function Loss:  -1.9495\n",
      "################################  1307  ################################\n",
      "Total loss:  -1.4246 | PDE Loss:  -1.5803 | Function Loss:  -1.9458\n",
      "################################  1308  ################################\n",
      "Total loss:  -1.4248 | PDE Loss:  -1.5789 | Function Loss:  -1.9497\n",
      "################################  1309  ################################\n",
      "Total loss:  -1.425 | PDE Loss:  -1.5808 | Function Loss:  -1.946\n",
      "################################  1310  ################################\n",
      "Total loss:  -1.4252 | PDE Loss:  -1.5794 | Function Loss:  -1.9499\n",
      "################################  1311  ################################\n",
      "Total loss:  -1.4254 | PDE Loss:  -1.5812 | Function Loss:  -1.9463\n",
      "################################  1312  ################################\n",
      "Total loss:  -1.4256 | PDE Loss:  -1.5798 | Function Loss:  -1.9501\n",
      "################################  1313  ################################\n",
      "Total loss:  -1.4258 | PDE Loss:  -1.5817 | Function Loss:  -1.9465\n",
      "################################  1314  ################################\n",
      "Total loss:  -1.426 | PDE Loss:  -1.5803 | Function Loss:  -1.9503\n",
      "################################  1315  ################################\n",
      "Total loss:  -1.4262 | PDE Loss:  -1.5821 | Function Loss:  -1.9467\n",
      "################################  1316  ################################\n",
      "Total loss:  -1.4264 | PDE Loss:  -1.5808 | Function Loss:  -1.9505\n",
      "################################  1317  ################################\n",
      "Total loss:  -1.4266 | PDE Loss:  -1.5826 | Function Loss:  -1.9469\n",
      "################################  1318  ################################\n",
      "Total loss:  -1.4268 | PDE Loss:  -1.5812 | Function Loss:  -1.9507\n",
      "################################  1319  ################################\n",
      "Total loss:  -1.427 | PDE Loss:  -1.583 | Function Loss:  -1.9471\n",
      "################################  1320  ################################\n",
      "Total loss:  -1.4272 | PDE Loss:  -1.5817 | Function Loss:  -1.951\n",
      "################################  1321  ################################\n",
      "Total loss:  -1.4274 | PDE Loss:  -1.5835 | Function Loss:  -1.9473\n",
      "################################  1322  ################################\n",
      "Total loss:  -1.4275 | PDE Loss:  -1.5821 | Function Loss:  -1.9512\n",
      "################################  1323  ################################\n",
      "Total loss:  -1.4277 | PDE Loss:  -1.584 | Function Loss:  -1.9475\n",
      "################################  1324  ################################\n",
      "Total loss:  -1.4279 | PDE Loss:  -1.5825 | Function Loss:  -1.9515\n",
      "################################  1325  ################################\n",
      "Total loss:  -1.4281 | PDE Loss:  -1.5845 | Function Loss:  -1.9476\n",
      "################################  1326  ################################\n",
      "Total loss:  -1.4283 | PDE Loss:  -1.5829 | Function Loss:  -1.9518\n",
      "################################  1327  ################################\n",
      "Total loss:  -1.4285 | PDE Loss:  -1.585 | Function Loss:  -1.9476\n",
      "################################  1328  ################################\n",
      "Total loss:  -1.4286 | PDE Loss:  -1.5833 | Function Loss:  -1.952\n",
      "################################  1329  ################################\n",
      "Total loss:  -1.4288 | PDE Loss:  -1.5855 | Function Loss:  -1.9475\n",
      "################################  1330  ################################\n",
      "Total loss:  -1.429 | PDE Loss:  -1.5837 | Function Loss:  -1.9523\n",
      "################################  1331  ################################\n",
      "Total loss:  -1.4291 | PDE Loss:  -1.586 | Function Loss:  -1.9474\n",
      "################################  1332  ################################\n",
      "Total loss:  -1.4293 | PDE Loss:  -1.5841 | Function Loss:  -1.9525\n",
      "################################  1333  ################################\n",
      "Total loss:  -1.4295 | PDE Loss:  -1.5866 | Function Loss:  -1.9473\n",
      "################################  1334  ################################\n",
      "Total loss:  -1.4297 | PDE Loss:  -1.5844 | Function Loss:  -1.9529\n",
      "################################  1335  ################################\n",
      "Total loss:  -1.4298 | PDE Loss:  -1.5871 | Function Loss:  -1.9473\n",
      "################################  1336  ################################\n",
      "Total loss:  -1.4301 | PDE Loss:  -1.5848 | Function Loss:  -1.9534\n",
      "################################  1337  ################################\n",
      "Total loss:  -1.4303 | PDE Loss:  -1.5876 | Function Loss:  -1.9476\n",
      "################################  1338  ################################\n",
      "Total loss:  -1.4306 | PDE Loss:  -1.5852 | Function Loss:  -1.9541\n",
      "################################  1339  ################################\n",
      "Total loss:  -1.4308 | PDE Loss:  -1.5881 | Function Loss:  -1.9483\n",
      "################################  1340  ################################\n",
      "Total loss:  -1.4312 | PDE Loss:  -1.5856 | Function Loss:  -1.9551\n",
      "################################  1341  ################################\n",
      "Total loss:  -1.4315 | PDE Loss:  -1.5885 | Function Loss:  -1.9495\n",
      "################################  1342  ################################\n",
      "Total loss:  -1.4318 | PDE Loss:  -1.5862 | Function Loss:  -1.9559\n",
      "################################  1343  ################################\n",
      "Total loss:  -1.4321 | PDE Loss:  -1.5889 | Function Loss:  -1.9505\n",
      "################################  1344  ################################\n",
      "Total loss:  -1.4322 | PDE Loss:  -1.5868 | Function Loss:  -1.9557\n",
      "################################  1345  ################################\n",
      "Total loss:  -1.4322 | PDE Loss:  -1.5891 | Function Loss:  -1.9505\n",
      "################################  1346  ################################\n",
      "Total loss:  -1.4321 | PDE Loss:  -1.5875 | Function Loss:  -1.9536\n",
      "################################  1347  ################################\n",
      "Total loss:  -1.4317 | PDE Loss:  -1.5893 | Function Loss:  -1.9485\n",
      "################################  1348  ################################\n",
      "Total loss:  -1.4313 | PDE Loss:  -1.5883 | Function Loss:  -1.9492\n",
      "################################  1349  ################################\n",
      "Total loss:  -1.4308 | PDE Loss:  -1.5893 | Function Loss:  -1.9453\n",
      "################################  1350  ################################\n",
      "Total loss:  -1.4304 | PDE Loss:  -1.5891 | Function Loss:  -1.9448\n",
      "################################  1351  ################################\n",
      "Total loss:  -1.4305 | PDE Loss:  -1.5893 | Function Loss:  -1.9443\n",
      "################################  1352  ################################\n",
      "Total loss:  -1.4311 | PDE Loss:  -1.5897 | Function Loss:  -1.9454\n",
      "################################  1353  ################################\n",
      "Total loss:  -1.4323 | PDE Loss:  -1.5896 | Function Loss:  -1.9498\n",
      "################################  1354  ################################\n",
      "Total loss:  -1.434 | PDE Loss:  -1.5901 | Function Loss:  -1.9542\n",
      "################################  1355  ################################\n",
      "Total loss:  -1.4357 | PDE Loss:  -1.5903 | Function Loss:  -1.9593\n",
      "################################  1356  ################################\n",
      "Total loss:  -1.4369 | PDE Loss:  -1.5901 | Function Loss:  -1.9639\n",
      "################################  1357  ################################\n",
      "Total loss:  -1.4374 | PDE Loss:  -1.5913 | Function Loss:  -1.9626\n",
      "################################  1358  ################################\n",
      "Total loss:  -1.4371 | PDE Loss:  -1.5899 | Function Loss:  -1.9648\n",
      "################################  1359  ################################\n",
      "Total loss:  -1.4361 | PDE Loss:  -1.5923 | Function Loss:  -1.9558\n",
      "################################  1360  ################################\n",
      "Total loss:  -1.4347 | PDE Loss:  -1.5898 | Function Loss:  -1.9572\n",
      "################################  1361  ################################\n",
      "Total loss:  -1.4335 | PDE Loss:  -1.5931 | Function Loss:  -1.9457\n",
      "################################  1362  ################################\n",
      "Total loss:  -1.4329 | PDE Loss:  -1.5902 | Function Loss:  -1.9502\n",
      "################################  1363  ################################\n",
      "Total loss:  -1.4329 | PDE Loss:  -1.5935 | Function Loss:  -1.9427\n",
      "################################  1364  ################################\n",
      "Total loss:  -1.4334 | PDE Loss:  -1.5911 | Function Loss:  -1.9497\n",
      "################################  1365  ################################\n",
      "Total loss:  -1.434 | PDE Loss:  -1.5935 | Function Loss:  -1.9464\n",
      "################################  1366  ################################\n",
      "Total loss:  -1.4346 | PDE Loss:  -1.5922 | Function Loss:  -1.9514\n",
      "################################  1367  ################################\n",
      "Total loss:  -1.4352 | PDE Loss:  -1.5934 | Function Loss:  -1.9503\n",
      "################################  1368  ################################\n",
      "Total loss:  -1.4358 | PDE Loss:  -1.5929 | Function Loss:  -1.9536\n",
      "################################  1369  ################################\n",
      "Total loss:  -1.4366 | PDE Loss:  -1.5937 | Function Loss:  -1.9544\n",
      "################################  1370  ################################\n",
      "Total loss:  -1.4374 | PDE Loss:  -1.5932 | Function Loss:  -1.958\n",
      "################################  1371  ################################\n",
      "Total loss:  -1.438 | PDE Loss:  -1.5943 | Function Loss:  -1.9577\n",
      "################################  1372  ################################\n",
      "Total loss:  -1.4383 | PDE Loss:  -1.5933 | Function Loss:  -1.961\n",
      "################################  1373  ################################\n",
      "Total loss:  -1.4381 | PDE Loss:  -1.5951 | Function Loss:  -1.9562\n",
      "################################  1374  ################################\n",
      "Total loss:  -1.4376 | PDE Loss:  -1.5932 | Function Loss:  -1.9588\n",
      "################################  1375  ################################\n",
      "Total loss:  -1.437 | PDE Loss:  -1.5958 | Function Loss:  -1.9507\n",
      "################################  1376  ################################\n",
      "Total loss:  -1.4364 | PDE Loss:  -1.5934 | Function Loss:  -1.9545\n",
      "################################  1377  ################################\n",
      "Total loss:  -1.4362 | PDE Loss:  -1.5963 | Function Loss:  -1.9473\n",
      "################################  1378  ################################\n",
      "Total loss:  -1.4364 | PDE Loss:  -1.5941 | Function Loss:  -1.9528\n",
      "################################  1379  ################################\n",
      "Total loss:  -1.4368 | PDE Loss:  -1.5966 | Function Loss:  -1.9485\n",
      "################################  1380  ################################\n",
      "Total loss:  -1.4372 | PDE Loss:  -1.5949 | Function Loss:  -1.9538\n",
      "################################  1381  ################################\n",
      "Total loss:  -1.4378 | PDE Loss:  -1.5967 | Function Loss:  -1.9514\n",
      "################################  1382  ################################\n",
      "Total loss:  -1.4383 | PDE Loss:  -1.5956 | Function Loss:  -1.9555\n",
      "################################  1383  ################################\n",
      "Total loss:  -1.4388 | PDE Loss:  -1.5969 | Function Loss:  -1.9543\n",
      "################################  1384  ################################\n",
      "Total loss:  -1.4394 | PDE Loss:  -1.5961 | Function Loss:  -1.958\n",
      "################################  1385  ################################\n",
      "Total loss:  -1.4398 | PDE Loss:  -1.5974 | Function Loss:  -1.9564\n",
      "################################  1386  ################################\n",
      "Total loss:  -1.4401 | PDE Loss:  -1.5963 | Function Loss:  -1.9598\n",
      "################################  1387  ################################\n",
      "Total loss:  -1.4401 | PDE Loss:  -1.5981 | Function Loss:  -1.9558\n",
      "################################  1388  ################################\n",
      "Total loss:  -1.4399 | PDE Loss:  -1.5964 | Function Loss:  -1.9591\n",
      "################################  1389  ################################\n",
      "Total loss:  -1.4397 | PDE Loss:  -1.5987 | Function Loss:  -1.953\n",
      "################################  1390  ################################\n",
      "Total loss:  -1.4394 | PDE Loss:  -1.5967 | Function Loss:  -1.9568\n",
      "################################  1391  ################################\n",
      "Total loss:  -1.4393 | PDE Loss:  -1.5992 | Function Loss:  -1.9507\n",
      "################################  1392  ################################\n",
      "Total loss:  -1.4394 | PDE Loss:  -1.5972 | Function Loss:  -1.9556\n",
      "################################  1393  ################################\n",
      "Total loss:  -1.4396 | PDE Loss:  -1.5995 | Function Loss:  -1.951\n",
      "################################  1394  ################################\n",
      "Total loss:  -1.4399 | PDE Loss:  -1.5978 | Function Loss:  -1.9559\n",
      "################################  1395  ################################\n",
      "Total loss:  -1.4403 | PDE Loss:  -1.5997 | Function Loss:  -1.9529\n",
      "################################  1396  ################################\n",
      "Total loss:  -1.4407 | PDE Loss:  -1.5984 | Function Loss:  -1.9572\n",
      "################################  1397  ################################\n",
      "Total loss:  -1.4412 | PDE Loss:  -1.6 | Function Loss:  -1.9549\n",
      "################################  1398  ################################\n",
      "Total loss:  -1.4415 | PDE Loss:  -1.5989 | Function Loss:  -1.9587\n",
      "################################  1399  ################################\n",
      "Total loss:  -1.4419 | PDE Loss:  -1.6005 | Function Loss:  -1.9562\n",
      "################################  1400  ################################\n",
      "Total loss:  -1.4421 | PDE Loss:  -1.5992 | Function Loss:  -1.9598\n",
      "################################  1401  ################################\n",
      "Total loss:  -1.4422 | PDE Loss:  -1.601 | Function Loss:  -1.9561\n",
      "################################  1402  ################################\n",
      "Total loss:  -1.4422 | PDE Loss:  -1.5995 | Function Loss:  -1.9596\n",
      "################################  1403  ################################\n",
      "Total loss:  -1.4422 | PDE Loss:  -1.6016 | Function Loss:  -1.9546\n",
      "################################  1404  ################################\n",
      "Total loss:  -1.4421 | PDE Loss:  -1.5998 | Function Loss:  -1.9585\n",
      "################################  1405  ################################\n",
      "Total loss:  -1.4421 | PDE Loss:  -1.6021 | Function Loss:  -1.9532\n",
      "################################  1406  ################################\n",
      "Total loss:  -1.4421 | PDE Loss:  -1.6002 | Function Loss:  -1.9577\n",
      "################################  1407  ################################\n",
      "Total loss:  -1.4423 | PDE Loss:  -1.6025 | Function Loss:  -1.9532\n",
      "################################  1408  ################################\n",
      "Total loss:  -1.4425 | PDE Loss:  -1.6007 | Function Loss:  -1.9579\n",
      "################################  1409  ################################\n",
      "Total loss:  -1.4429 | PDE Loss:  -1.6028 | Function Loss:  -1.9543\n",
      "################################  1410  ################################\n",
      "Total loss:  -1.4432 | PDE Loss:  -1.6013 | Function Loss:  -1.9587\n",
      "################################  1411  ################################\n",
      "Total loss:  -1.4435 | PDE Loss:  -1.6031 | Function Loss:  -1.9557\n",
      "################################  1412  ################################\n",
      "Total loss:  -1.4438 | PDE Loss:  -1.6017 | Function Loss:  -1.9597\n",
      "################################  1413  ################################\n",
      "Total loss:  -1.4441 | PDE Loss:  -1.6035 | Function Loss:  -1.9566\n",
      "################################  1414  ################################\n",
      "Total loss:  -1.4443 | PDE Loss:  -1.6021 | Function Loss:  -1.9603\n",
      "################################  1415  ################################\n",
      "Total loss:  -1.4444 | PDE Loss:  -1.6039 | Function Loss:  -1.9567\n",
      "################################  1416  ################################\n",
      "Total loss:  -1.4445 | PDE Loss:  -1.6025 | Function Loss:  -1.9603\n",
      "################################  1417  ################################\n",
      "Total loss:  -1.4446 | PDE Loss:  -1.6044 | Function Loss:  -1.956\n",
      "################################  1418  ################################\n",
      "Total loss:  -1.4446 | PDE Loss:  -1.6028 | Function Loss:  -1.9598\n",
      "################################  1419  ################################\n",
      "Total loss:  -1.4446 | PDE Loss:  -1.6049 | Function Loss:  -1.9552\n",
      "################################  1420  ################################\n",
      "Total loss:  -1.4447 | PDE Loss:  -1.6032 | Function Loss:  -1.9594\n",
      "################################  1421  ################################\n",
      "Total loss:  -1.4449 | PDE Loss:  -1.6054 | Function Loss:  -1.955\n",
      "################################  1422  ################################\n",
      "Total loss:  -1.4451 | PDE Loss:  -1.6036 | Function Loss:  -1.9596\n",
      "################################  1423  ################################\n",
      "Total loss:  -1.4453 | PDE Loss:  -1.6057 | Function Loss:  -1.9557\n",
      "################################  1424  ################################\n",
      "Total loss:  -1.4456 | PDE Loss:  -1.6041 | Function Loss:  -1.9602\n",
      "################################  1425  ################################\n",
      "Total loss:  -1.4459 | PDE Loss:  -1.6061 | Function Loss:  -1.9566\n",
      "################################  1426  ################################\n",
      "Total loss:  -1.4461 | PDE Loss:  -1.6046 | Function Loss:  -1.9608\n",
      "################################  1427  ################################\n",
      "Total loss:  -1.4463 | PDE Loss:  -1.6064 | Function Loss:  -1.9573\n",
      "################################  1428  ################################\n",
      "Total loss:  -1.4465 | PDE Loss:  -1.605 | Function Loss:  -1.9611\n",
      "################################  1429  ################################\n",
      "Total loss:  -1.4467 | PDE Loss:  -1.6068 | Function Loss:  -1.9575\n",
      "################################  1430  ################################\n",
      "Total loss:  -1.4468 | PDE Loss:  -1.6054 | Function Loss:  -1.9611\n",
      "################################  1431  ################################\n",
      "Total loss:  -1.4469 | PDE Loss:  -1.6073 | Function Loss:  -1.9572\n",
      "################################  1432  ################################\n",
      "Total loss:  -1.447 | PDE Loss:  -1.6058 | Function Loss:  -1.961\n",
      "################################  1433  ################################\n",
      "Total loss:  -1.4471 | PDE Loss:  -1.6078 | Function Loss:  -1.9568\n",
      "################################  1434  ################################\n",
      "Total loss:  -1.4472 | PDE Loss:  -1.6061 | Function Loss:  -1.9609\n",
      "################################  1435  ################################\n",
      "Total loss:  -1.4474 | PDE Loss:  -1.6082 | Function Loss:  -1.9567\n",
      "################################  1436  ################################\n",
      "Total loss:  -1.4475 | PDE Loss:  -1.6065 | Function Loss:  -1.961\n",
      "################################  1437  ################################\n",
      "Total loss:  -1.4477 | PDE Loss:  -1.6086 | Function Loss:  -1.957\n",
      "################################  1438  ################################\n",
      "Total loss:  -1.448 | PDE Loss:  -1.6069 | Function Loss:  -1.9615\n",
      "################################  1439  ################################\n",
      "Total loss:  -1.4482 | PDE Loss:  -1.609 | Function Loss:  -1.9576\n",
      "################################  1440  ################################\n",
      "Total loss:  -1.4484 | PDE Loss:  -1.6074 | Function Loss:  -1.9619\n",
      "################################  1441  ################################\n",
      "Total loss:  -1.4486 | PDE Loss:  -1.6094 | Function Loss:  -1.9582\n",
      "################################  1442  ################################\n",
      "Total loss:  -1.4488 | PDE Loss:  -1.6078 | Function Loss:  -1.9621\n",
      "################################  1443  ################################\n",
      "Total loss:  -1.4489 | PDE Loss:  -1.6097 | Function Loss:  -1.9584\n",
      "################################  1444  ################################\n",
      "Total loss:  -1.4491 | PDE Loss:  -1.6083 | Function Loss:  -1.9621\n",
      "################################  1445  ################################\n",
      "Total loss:  -1.4492 | PDE Loss:  -1.6101 | Function Loss:  -1.9583\n",
      "################################  1446  ################################\n",
      "Total loss:  -1.4493 | PDE Loss:  -1.6087 | Function Loss:  -1.962\n",
      "################################  1447  ################################\n",
      "Total loss:  -1.4494 | PDE Loss:  -1.6106 | Function Loss:  -1.9581\n",
      "################################  1448  ################################\n",
      "Total loss:  -1.4496 | PDE Loss:  -1.609 | Function Loss:  -1.9621\n",
      "################################  1449  ################################\n",
      "Total loss:  -1.4497 | PDE Loss:  -1.611 | Function Loss:  -1.9581\n",
      "################################  1450  ################################\n",
      "Total loss:  -1.4499 | PDE Loss:  -1.6094 | Function Loss:  -1.9623\n",
      "################################  1451  ################################\n",
      "Total loss:  -1.4501 | PDE Loss:  -1.6114 | Function Loss:  -1.9584\n",
      "################################  1452  ################################\n",
      "Total loss:  -1.4503 | PDE Loss:  -1.6098 | Function Loss:  -1.9627\n",
      "################################  1453  ################################\n",
      "Total loss:  -1.4505 | PDE Loss:  -1.6118 | Function Loss:  -1.9588\n",
      "################################  1454  ################################\n",
      "Total loss:  -1.4507 | PDE Loss:  -1.6102 | Function Loss:  -1.963\n",
      "################################  1455  ################################\n",
      "Total loss:  -1.4509 | PDE Loss:  -1.6122 | Function Loss:  -1.9591\n",
      "################################  1456  ################################\n",
      "Total loss:  -1.4511 | PDE Loss:  -1.6106 | Function Loss:  -1.9632\n",
      "################################  1457  ################################\n",
      "Total loss:  -1.4512 | PDE Loss:  -1.6126 | Function Loss:  -1.9593\n",
      "################################  1458  ################################\n",
      "Total loss:  -1.4514 | PDE Loss:  -1.6111 | Function Loss:  -1.9632\n",
      "################################  1459  ################################\n",
      "Total loss:  -1.4515 | PDE Loss:  -1.613 | Function Loss:  -1.9593\n",
      "################################  1460  ################################\n",
      "Total loss:  -1.4516 | PDE Loss:  -1.6115 | Function Loss:  -1.9632\n",
      "################################  1461  ################################\n",
      "Total loss:  -1.4518 | PDE Loss:  -1.6134 | Function Loss:  -1.9593\n",
      "################################  1462  ################################\n",
      "Total loss:  -1.4519 | PDE Loss:  -1.6119 | Function Loss:  -1.9632\n",
      "################################  1463  ################################\n",
      "Total loss:  -1.4521 | PDE Loss:  -1.6138 | Function Loss:  -1.9594\n",
      "################################  1464  ################################\n",
      "Total loss:  -1.4522 | PDE Loss:  -1.6123 | Function Loss:  -1.9634\n",
      "################################  1465  ################################\n",
      "Total loss:  -1.4524 | PDE Loss:  -1.6142 | Function Loss:  -1.9596\n",
      "################################  1466  ################################\n",
      "Total loss:  -1.4526 | PDE Loss:  -1.6126 | Function Loss:  -1.9637\n",
      "################################  1467  ################################\n",
      "Total loss:  -1.4528 | PDE Loss:  -1.6146 | Function Loss:  -1.9599\n",
      "################################  1468  ################################\n",
      "Total loss:  -1.453 | PDE Loss:  -1.613 | Function Loss:  -1.9641\n",
      "################################  1469  ################################\n",
      "Total loss:  -1.4532 | PDE Loss:  -1.615 | Function Loss:  -1.9602\n",
      "################################  1470  ################################\n",
      "Total loss:  -1.4533 | PDE Loss:  -1.6134 | Function Loss:  -1.9643\n",
      "################################  1471  ################################\n",
      "Total loss:  -1.4535 | PDE Loss:  -1.6154 | Function Loss:  -1.9603\n",
      "################################  1472  ################################\n",
      "Total loss:  -1.4536 | PDE Loss:  -1.6138 | Function Loss:  -1.9644\n",
      "################################  1473  ################################\n",
      "Total loss:  -1.4538 | PDE Loss:  -1.6158 | Function Loss:  -1.9604\n",
      "################################  1474  ################################\n",
      "Total loss:  -1.4539 | PDE Loss:  -1.6142 | Function Loss:  -1.9644\n",
      "################################  1475  ################################\n",
      "Total loss:  -1.4541 | PDE Loss:  -1.6162 | Function Loss:  -1.9605\n",
      "################################  1476  ################################\n",
      "Total loss:  -1.4542 | PDE Loss:  -1.6147 | Function Loss:  -1.9644\n",
      "################################  1477  ################################\n",
      "Total loss:  -1.4544 | PDE Loss:  -1.6166 | Function Loss:  -1.9606\n",
      "################################  1478  ################################\n",
      "Total loss:  -1.4545 | PDE Loss:  -1.6151 | Function Loss:  -1.9646\n",
      "################################  1479  ################################\n",
      "Total loss:  -1.4547 | PDE Loss:  -1.617 | Function Loss:  -1.9608\n",
      "################################  1480  ################################\n",
      "Total loss:  -1.4549 | PDE Loss:  -1.6155 | Function Loss:  -1.9648\n",
      "################################  1481  ################################\n",
      "Total loss:  -1.4551 | PDE Loss:  -1.6174 | Function Loss:  -1.961\n",
      "################################  1482  ################################\n",
      "Total loss:  -1.4552 | PDE Loss:  -1.6159 | Function Loss:  -1.9651\n",
      "################################  1483  ################################\n",
      "Total loss:  -1.4554 | PDE Loss:  -1.6178 | Function Loss:  -1.9613\n",
      "################################  1484  ################################\n",
      "Total loss:  -1.4556 | PDE Loss:  -1.6162 | Function Loss:  -1.9653\n",
      "################################  1485  ################################\n",
      "Total loss:  -1.4557 | PDE Loss:  -1.6182 | Function Loss:  -1.9614\n",
      "################################  1486  ################################\n",
      "Total loss:  -1.4559 | PDE Loss:  -1.6166 | Function Loss:  -1.9654\n",
      "################################  1487  ################################\n",
      "Total loss:  -1.456 | PDE Loss:  -1.6186 | Function Loss:  -1.9615\n",
      "################################  1488  ################################\n",
      "Total loss:  -1.4562 | PDE Loss:  -1.617 | Function Loss:  -1.9655\n",
      "################################  1489  ################################\n",
      "Total loss:  -1.4563 | PDE Loss:  -1.619 | Function Loss:  -1.9616\n",
      "################################  1490  ################################\n",
      "Total loss:  -1.4565 | PDE Loss:  -1.6174 | Function Loss:  -1.9656\n",
      "################################  1491  ################################\n",
      "Total loss:  -1.4567 | PDE Loss:  -1.6194 | Function Loss:  -1.9617\n",
      "################################  1492  ################################\n",
      "Total loss:  -1.4568 | PDE Loss:  -1.6178 | Function Loss:  -1.9658\n",
      "################################  1493  ################################\n",
      "Total loss:  -1.457 | PDE Loss:  -1.6198 | Function Loss:  -1.9619\n",
      "################################  1494  ################################\n",
      "Total loss:  -1.4571 | PDE Loss:  -1.6182 | Function Loss:  -1.9659\n",
      "################################  1495  ################################\n",
      "Total loss:  -1.4573 | PDE Loss:  -1.6202 | Function Loss:  -1.9621\n",
      "################################  1496  ################################\n",
      "Total loss:  -1.4575 | PDE Loss:  -1.6186 | Function Loss:  -1.9661\n",
      "################################  1497  ################################\n",
      "Total loss:  -1.4576 | PDE Loss:  -1.6206 | Function Loss:  -1.9623\n",
      "################################  1498  ################################\n",
      "Total loss:  -1.4578 | PDE Loss:  -1.619 | Function Loss:  -1.9663\n",
      "################################  1499  ################################\n",
      "Total loss:  -1.458 | PDE Loss:  -1.621 | Function Loss:  -1.9625\n",
      "################################  1500  ################################\n",
      "Total loss:  -1.4581 | PDE Loss:  -1.6194 | Function Loss:  -1.9664\n",
      "################################  1501  ################################\n",
      "Total loss:  -1.4583 | PDE Loss:  -1.6214 | Function Loss:  -1.9626\n",
      "################################  1502  ################################\n",
      "Total loss:  -1.4584 | PDE Loss:  -1.6198 | Function Loss:  -1.9666\n",
      "################################  1503  ################################\n",
      "Total loss:  -1.4586 | PDE Loss:  -1.6218 | Function Loss:  -1.9627\n",
      "################################  1504  ################################\n",
      "Total loss:  -1.4587 | PDE Loss:  -1.6202 | Function Loss:  -1.9667\n",
      "################################  1505  ################################\n",
      "Total loss:  -1.4589 | PDE Loss:  -1.6222 | Function Loss:  -1.9629\n",
      "################################  1506  ################################\n",
      "Total loss:  -1.4591 | PDE Loss:  -1.6206 | Function Loss:  -1.9669\n",
      "################################  1507  ################################\n",
      "Total loss:  -1.4592 | PDE Loss:  -1.6226 | Function Loss:  -1.963\n",
      "################################  1508  ################################\n",
      "Total loss:  -1.4594 | PDE Loss:  -1.6209 | Function Loss:  -1.9671\n",
      "################################  1509  ################################\n",
      "Total loss:  -1.4595 | PDE Loss:  -1.6229 | Function Loss:  -1.9632\n",
      "################################  1510  ################################\n",
      "Total loss:  -1.4597 | PDE Loss:  -1.6213 | Function Loss:  -1.9673\n",
      "################################  1511  ################################\n",
      "Total loss:  -1.4599 | PDE Loss:  -1.6233 | Function Loss:  -1.9634\n",
      "################################  1512  ################################\n",
      "Total loss:  -1.46 | PDE Loss:  -1.6217 | Function Loss:  -1.9674\n",
      "################################  1513  ################################\n",
      "Total loss:  -1.4602 | PDE Loss:  -1.6237 | Function Loss:  -1.9636\n",
      "################################  1514  ################################\n",
      "Total loss:  -1.4603 | PDE Loss:  -1.6221 | Function Loss:  -1.9676\n",
      "################################  1515  ################################\n",
      "Total loss:  -1.4605 | PDE Loss:  -1.6241 | Function Loss:  -1.9637\n",
      "################################  1516  ################################\n",
      "Total loss:  -1.4606 | PDE Loss:  -1.6225 | Function Loss:  -1.9677\n",
      "################################  1517  ################################\n",
      "Total loss:  -1.4608 | PDE Loss:  -1.6245 | Function Loss:  -1.9639\n",
      "################################  1518  ################################\n",
      "Total loss:  -1.461 | PDE Loss:  -1.6229 | Function Loss:  -1.9678\n",
      "################################  1519  ################################\n",
      "Total loss:  -1.4611 | PDE Loss:  -1.6249 | Function Loss:  -1.964\n",
      "################################  1520  ################################\n",
      "Total loss:  -1.4613 | PDE Loss:  -1.6233 | Function Loss:  -1.968\n",
      "################################  1521  ################################\n",
      "Total loss:  -1.4614 | PDE Loss:  -1.6253 | Function Loss:  -1.9642\n",
      "################################  1522  ################################\n",
      "Total loss:  -1.4616 | PDE Loss:  -1.6237 | Function Loss:  -1.9681\n",
      "################################  1523  ################################\n",
      "Total loss:  -1.4618 | PDE Loss:  -1.6257 | Function Loss:  -1.9643\n",
      "################################  1524  ################################\n",
      "Total loss:  -1.4619 | PDE Loss:  -1.6241 | Function Loss:  -1.9683\n",
      "################################  1525  ################################\n",
      "Total loss:  -1.4621 | PDE Loss:  -1.626 | Function Loss:  -1.9645\n",
      "################################  1526  ################################\n",
      "Total loss:  -1.4622 | PDE Loss:  -1.6245 | Function Loss:  -1.9685\n",
      "################################  1527  ################################\n",
      "Total loss:  -1.4624 | PDE Loss:  -1.6264 | Function Loss:  -1.9647\n",
      "################################  1528  ################################\n",
      "Total loss:  -1.4626 | PDE Loss:  -1.6248 | Function Loss:  -1.9687\n",
      "################################  1529  ################################\n",
      "Total loss:  -1.4627 | PDE Loss:  -1.6268 | Function Loss:  -1.9648\n",
      "################################  1530  ################################\n",
      "Total loss:  -1.4629 | PDE Loss:  -1.6252 | Function Loss:  -1.9688\n",
      "################################  1531  ################################\n",
      "Total loss:  -1.463 | PDE Loss:  -1.6272 | Function Loss:  -1.9649\n",
      "################################  1532  ################################\n",
      "Total loss:  -1.4632 | PDE Loss:  -1.6256 | Function Loss:  -1.9689\n",
      "################################  1533  ################################\n",
      "Total loss:  -1.4633 | PDE Loss:  -1.6276 | Function Loss:  -1.9651\n",
      "################################  1534  ################################\n",
      "Total loss:  -1.4635 | PDE Loss:  -1.626 | Function Loss:  -1.9691\n",
      "################################  1535  ################################\n",
      "Total loss:  -1.4636 | PDE Loss:  -1.628 | Function Loss:  -1.9652\n",
      "################################  1536  ################################\n",
      "Total loss:  -1.4638 | PDE Loss:  -1.6264 | Function Loss:  -1.9692\n",
      "################################  1537  ################################\n",
      "Total loss:  -1.464 | PDE Loss:  -1.6284 | Function Loss:  -1.9654\n",
      "################################  1538  ################################\n",
      "Total loss:  -1.4641 | PDE Loss:  -1.6268 | Function Loss:  -1.9694\n",
      "################################  1539  ################################\n",
      "Total loss:  -1.4643 | PDE Loss:  -1.6287 | Function Loss:  -1.9656\n",
      "################################  1540  ################################\n",
      "Total loss:  -1.4644 | PDE Loss:  -1.6272 | Function Loss:  -1.9696\n",
      "################################  1541  ################################\n",
      "Total loss:  -1.4646 | PDE Loss:  -1.6291 | Function Loss:  -1.9658\n",
      "################################  1542  ################################\n",
      "Total loss:  -1.4647 | PDE Loss:  -1.6275 | Function Loss:  -1.9697\n",
      "################################  1543  ################################\n",
      "Total loss:  -1.4649 | PDE Loss:  -1.6295 | Function Loss:  -1.9659\n",
      "################################  1544  ################################\n",
      "Total loss:  -1.4651 | PDE Loss:  -1.6279 | Function Loss:  -1.9699\n",
      "################################  1545  ################################\n",
      "Total loss:  -1.4652 | PDE Loss:  -1.6299 | Function Loss:  -1.9661\n",
      "################################  1546  ################################\n",
      "Total loss:  -1.4654 | PDE Loss:  -1.6283 | Function Loss:  -1.97\n",
      "################################  1547  ################################\n",
      "Total loss:  -1.4655 | PDE Loss:  -1.6303 | Function Loss:  -1.9662\n",
      "################################  1548  ################################\n",
      "Total loss:  -1.4657 | PDE Loss:  -1.6287 | Function Loss:  -1.9702\n",
      "################################  1549  ################################\n",
      "Total loss:  -1.4658 | PDE Loss:  -1.6307 | Function Loss:  -1.9664\n",
      "################################  1550  ################################\n",
      "Total loss:  -1.466 | PDE Loss:  -1.6291 | Function Loss:  -1.9704\n",
      "################################  1551  ################################\n",
      "Total loss:  -1.4662 | PDE Loss:  -1.6311 | Function Loss:  -1.9665\n",
      "################################  1552  ################################\n",
      "Total loss:  -1.4663 | PDE Loss:  -1.6294 | Function Loss:  -1.9705\n",
      "################################  1553  ################################\n",
      "Total loss:  -1.4665 | PDE Loss:  -1.6314 | Function Loss:  -1.9667\n",
      "################################  1554  ################################\n",
      "Total loss:  -1.4666 | PDE Loss:  -1.6298 | Function Loss:  -1.9707\n",
      "################################  1555  ################################\n",
      "Total loss:  -1.4668 | PDE Loss:  -1.6318 | Function Loss:  -1.9669\n",
      "################################  1556  ################################\n",
      "Total loss:  -1.4669 | PDE Loss:  -1.6302 | Function Loss:  -1.9709\n",
      "################################  1557  ################################\n",
      "Total loss:  -1.4671 | PDE Loss:  -1.6322 | Function Loss:  -1.967\n",
      "################################  1558  ################################\n",
      "Total loss:  -1.4672 | PDE Loss:  -1.6306 | Function Loss:  -1.971\n",
      "################################  1559  ################################\n",
      "Total loss:  -1.4674 | PDE Loss:  -1.6326 | Function Loss:  -1.9671\n",
      "################################  1560  ################################\n",
      "Total loss:  -1.4675 | PDE Loss:  -1.631 | Function Loss:  -1.9711\n",
      "################################  1561  ################################\n",
      "Total loss:  -1.4677 | PDE Loss:  -1.633 | Function Loss:  -1.9673\n",
      "################################  1562  ################################\n",
      "Total loss:  -1.4679 | PDE Loss:  -1.6314 | Function Loss:  -1.9713\n",
      "################################  1563  ################################\n",
      "Total loss:  -1.468 | PDE Loss:  -1.6333 | Function Loss:  -1.9675\n",
      "################################  1564  ################################\n",
      "Total loss:  -1.4682 | PDE Loss:  -1.6317 | Function Loss:  -1.9715\n",
      "################################  1565  ################################\n",
      "Total loss:  -1.4683 | PDE Loss:  -1.6337 | Function Loss:  -1.9677\n",
      "################################  1566  ################################\n",
      "Total loss:  -1.4685 | PDE Loss:  -1.6321 | Function Loss:  -1.9716\n",
      "################################  1567  ################################\n",
      "Total loss:  -1.4686 | PDE Loss:  -1.6341 | Function Loss:  -1.9678\n",
      "################################  1568  ################################\n",
      "Total loss:  -1.4688 | PDE Loss:  -1.6325 | Function Loss:  -1.9718\n",
      "################################  1569  ################################\n",
      "Total loss:  -1.4689 | PDE Loss:  -1.6345 | Function Loss:  -1.968\n",
      "################################  1570  ################################\n",
      "Total loss:  -1.4691 | PDE Loss:  -1.6329 | Function Loss:  -1.9719\n",
      "################################  1571  ################################\n",
      "Total loss:  -1.4693 | PDE Loss:  -1.6349 | Function Loss:  -1.9681\n",
      "################################  1572  ################################\n",
      "Total loss:  -1.4694 | PDE Loss:  -1.6333 | Function Loss:  -1.9721\n",
      "################################  1573  ################################\n",
      "Total loss:  -1.4696 | PDE Loss:  -1.6353 | Function Loss:  -1.9683\n",
      "################################  1574  ################################\n",
      "Total loss:  -1.4697 | PDE Loss:  -1.6336 | Function Loss:  -1.9722\n",
      "################################  1575  ################################\n",
      "Total loss:  -1.4699 | PDE Loss:  -1.6356 | Function Loss:  -1.9684\n",
      "################################  1576  ################################\n",
      "Total loss:  -1.47 | PDE Loss:  -1.634 | Function Loss:  -1.9724\n",
      "################################  1577  ################################\n",
      "Total loss:  -1.4702 | PDE Loss:  -1.636 | Function Loss:  -1.9686\n",
      "################################  1578  ################################\n",
      "Total loss:  -1.4703 | PDE Loss:  -1.6344 | Function Loss:  -1.9726\n",
      "################################  1579  ################################\n",
      "Total loss:  -1.4705 | PDE Loss:  -1.6364 | Function Loss:  -1.9688\n",
      "################################  1580  ################################\n",
      "Total loss:  -1.4707 | PDE Loss:  -1.6348 | Function Loss:  -1.9728\n",
      "################################  1581  ################################\n",
      "Total loss:  -1.4708 | PDE Loss:  -1.6368 | Function Loss:  -1.9689\n",
      "################################  1582  ################################\n",
      "Total loss:  -1.471 | PDE Loss:  -1.6352 | Function Loss:  -1.9729\n",
      "################################  1583  ################################\n",
      "Total loss:  -1.4711 | PDE Loss:  -1.6372 | Function Loss:  -1.9691\n",
      "################################  1584  ################################\n",
      "Total loss:  -1.4713 | PDE Loss:  -1.6355 | Function Loss:  -1.9731\n",
      "################################  1585  ################################\n",
      "Total loss:  -1.4714 | PDE Loss:  -1.6375 | Function Loss:  -1.9692\n",
      "################################  1586  ################################\n",
      "Total loss:  -1.4716 | PDE Loss:  -1.6359 | Function Loss:  -1.9732\n",
      "################################  1587  ################################\n",
      "Total loss:  -1.4717 | PDE Loss:  -1.6379 | Function Loss:  -1.9694\n",
      "################################  1588  ################################\n",
      "Total loss:  -1.4719 | PDE Loss:  -1.6363 | Function Loss:  -1.9734\n",
      "################################  1589  ################################\n",
      "Total loss:  -1.472 | PDE Loss:  -1.6383 | Function Loss:  -1.9695\n",
      "################################  1590  ################################\n",
      "Total loss:  -1.4722 | PDE Loss:  -1.6367 | Function Loss:  -1.9735\n",
      "################################  1591  ################################\n",
      "Total loss:  -1.4723 | PDE Loss:  -1.6387 | Function Loss:  -1.9697\n",
      "################################  1592  ################################\n",
      "Total loss:  -1.4725 | PDE Loss:  -1.6371 | Function Loss:  -1.9737\n",
      "################################  1593  ################################\n",
      "Total loss:  -1.4727 | PDE Loss:  -1.639 | Function Loss:  -1.9699\n",
      "################################  1594  ################################\n",
      "Total loss:  -1.4728 | PDE Loss:  -1.6374 | Function Loss:  -1.9738\n",
      "################################  1595  ################################\n",
      "Total loss:  -1.473 | PDE Loss:  -1.6394 | Function Loss:  -1.97\n",
      "################################  1596  ################################\n",
      "Total loss:  -1.4731 | PDE Loss:  -1.6378 | Function Loss:  -1.974\n",
      "################################  1597  ################################\n",
      "Total loss:  -1.4733 | PDE Loss:  -1.6398 | Function Loss:  -1.9702\n",
      "################################  1598  ################################\n",
      "Total loss:  -1.4734 | PDE Loss:  -1.6382 | Function Loss:  -1.9741\n",
      "################################  1599  ################################\n",
      "Total loss:  -1.4736 | PDE Loss:  -1.6402 | Function Loss:  -1.9704\n",
      "################################  1600  ################################\n",
      "Total loss:  -1.4737 | PDE Loss:  -1.6386 | Function Loss:  -1.9743\n",
      "################################  1601  ################################\n",
      "Total loss:  -1.4739 | PDE Loss:  -1.6405 | Function Loss:  -1.9705\n",
      "################################  1602  ################################\n",
      "Total loss:  -1.474 | PDE Loss:  -1.6389 | Function Loss:  -1.9745\n",
      "################################  1603  ################################\n",
      "Total loss:  -1.4742 | PDE Loss:  -1.6409 | Function Loss:  -1.9707\n",
      "################################  1604  ################################\n",
      "Total loss:  -1.4744 | PDE Loss:  -1.6393 | Function Loss:  -1.9746\n",
      "################################  1605  ################################\n",
      "Total loss:  -1.4745 | PDE Loss:  -1.6413 | Function Loss:  -1.9708\n",
      "################################  1606  ################################\n",
      "Total loss:  -1.4747 | PDE Loss:  -1.6397 | Function Loss:  -1.9748\n",
      "################################  1607  ################################\n",
      "Total loss:  -1.4748 | PDE Loss:  -1.6417 | Function Loss:  -1.971\n",
      "################################  1608  ################################\n",
      "Total loss:  -1.475 | PDE Loss:  -1.64 | Function Loss:  -1.975\n",
      "################################  1609  ################################\n",
      "Total loss:  -1.4751 | PDE Loss:  -1.6421 | Function Loss:  -1.9711\n",
      "################################  1610  ################################\n",
      "Total loss:  -1.4753 | PDE Loss:  -1.6404 | Function Loss:  -1.9751\n",
      "################################  1611  ################################\n",
      "Total loss:  -1.4754 | PDE Loss:  -1.6424 | Function Loss:  -1.9713\n",
      "################################  1612  ################################\n",
      "Total loss:  -1.4756 | PDE Loss:  -1.6408 | Function Loss:  -1.9753\n",
      "################################  1613  ################################\n",
      "Total loss:  -1.4757 | PDE Loss:  -1.6428 | Function Loss:  -1.9714\n",
      "################################  1614  ################################\n",
      "Total loss:  -1.4759 | PDE Loss:  -1.6412 | Function Loss:  -1.9754\n",
      "################################  1615  ################################\n",
      "Total loss:  -1.476 | PDE Loss:  -1.6432 | Function Loss:  -1.9716\n",
      "################################  1616  ################################\n",
      "Total loss:  -1.4762 | PDE Loss:  -1.6415 | Function Loss:  -1.9756\n",
      "################################  1617  ################################\n",
      "Total loss:  -1.4763 | PDE Loss:  -1.6436 | Function Loss:  -1.9717\n",
      "################################  1618  ################################\n",
      "Total loss:  -1.4765 | PDE Loss:  -1.6419 | Function Loss:  -1.9758\n",
      "################################  1619  ################################\n",
      "Total loss:  -1.4766 | PDE Loss:  -1.6439 | Function Loss:  -1.9719\n",
      "################################  1620  ################################\n",
      "Total loss:  -1.4768 | PDE Loss:  -1.6423 | Function Loss:  -1.9759\n",
      "################################  1621  ################################\n",
      "Total loss:  -1.477 | PDE Loss:  -1.6443 | Function Loss:  -1.9721\n",
      "################################  1622  ################################\n",
      "Total loss:  -1.4771 | PDE Loss:  -1.6427 | Function Loss:  -1.9761\n",
      "################################  1623  ################################\n",
      "Total loss:  -1.4773 | PDE Loss:  -1.6447 | Function Loss:  -1.9723\n",
      "################################  1624  ################################\n",
      "Total loss:  -1.4774 | PDE Loss:  -1.6431 | Function Loss:  -1.9762\n",
      "################################  1625  ################################\n",
      "Total loss:  -1.4776 | PDE Loss:  -1.6451 | Function Loss:  -1.9725\n",
      "################################  1626  ################################\n",
      "Total loss:  -1.4777 | PDE Loss:  -1.6434 | Function Loss:  -1.9764\n",
      "################################  1627  ################################\n",
      "Total loss:  -1.4779 | PDE Loss:  -1.6454 | Function Loss:  -1.9726\n",
      "################################  1628  ################################\n",
      "Total loss:  -1.478 | PDE Loss:  -1.6438 | Function Loss:  -1.9765\n",
      "################################  1629  ################################\n",
      "Total loss:  -1.4782 | PDE Loss:  -1.6458 | Function Loss:  -1.9728\n",
      "################################  1630  ################################\n",
      "Total loss:  -1.4783 | PDE Loss:  -1.6442 | Function Loss:  -1.9766\n",
      "################################  1631  ################################\n",
      "Total loss:  -1.4785 | PDE Loss:  -1.6462 | Function Loss:  -1.973\n",
      "################################  1632  ################################\n",
      "Total loss:  -1.4786 | PDE Loss:  -1.6446 | Function Loss:  -1.9768\n",
      "################################  1633  ################################\n",
      "Total loss:  -1.4788 | PDE Loss:  -1.6465 | Function Loss:  -1.9732\n",
      "################################  1634  ################################\n",
      "Total loss:  -1.479 | PDE Loss:  -1.645 | Function Loss:  -1.977\n",
      "################################  1635  ################################\n",
      "Total loss:  -1.4791 | PDE Loss:  -1.6469 | Function Loss:  -1.9733\n",
      "################################  1636  ################################\n",
      "Total loss:  -1.4793 | PDE Loss:  -1.6453 | Function Loss:  -1.9772\n",
      "################################  1637  ################################\n",
      "Total loss:  -1.4794 | PDE Loss:  -1.6473 | Function Loss:  -1.9735\n",
      "################################  1638  ################################\n",
      "Total loss:  -1.4796 | PDE Loss:  -1.6457 | Function Loss:  -1.9773\n",
      "################################  1639  ################################\n",
      "Total loss:  -1.4797 | PDE Loss:  -1.6477 | Function Loss:  -1.9736\n",
      "################################  1640  ################################\n",
      "Total loss:  -1.4799 | PDE Loss:  -1.646 | Function Loss:  -1.9775\n",
      "################################  1641  ################################\n",
      "Total loss:  -1.48 | PDE Loss:  -1.6481 | Function Loss:  -1.9737\n",
      "################################  1642  ################################\n",
      "Total loss:  -1.4802 | PDE Loss:  -1.6464 | Function Loss:  -1.9777\n",
      "################################  1643  ################################\n",
      "Total loss:  -1.4803 | PDE Loss:  -1.6485 | Function Loss:  -1.9738\n",
      "################################  1644  ################################\n",
      "Total loss:  -1.4805 | PDE Loss:  -1.6468 | Function Loss:  -1.9779\n",
      "################################  1645  ################################\n",
      "Total loss:  -1.4806 | PDE Loss:  -1.6489 | Function Loss:  -1.9739\n",
      "################################  1646  ################################\n",
      "Total loss:  -1.4808 | PDE Loss:  -1.6471 | Function Loss:  -1.9781\n",
      "################################  1647  ################################\n",
      "Total loss:  -1.4809 | PDE Loss:  -1.6492 | Function Loss:  -1.974\n",
      "################################  1648  ################################\n",
      "Total loss:  -1.4811 | PDE Loss:  -1.6475 | Function Loss:  -1.9783\n",
      "################################  1649  ################################\n",
      "Total loss:  -1.4812 | PDE Loss:  -1.6496 | Function Loss:  -1.9742\n",
      "################################  1650  ################################\n",
      "Total loss:  -1.4814 | PDE Loss:  -1.6478 | Function Loss:  -1.9785\n",
      "################################  1651  ################################\n",
      "Total loss:  -1.4816 | PDE Loss:  -1.65 | Function Loss:  -1.9743\n",
      "################################  1652  ################################\n",
      "Total loss:  -1.4817 | PDE Loss:  -1.6482 | Function Loss:  -1.9787\n",
      "################################  1653  ################################\n",
      "Total loss:  -1.4819 | PDE Loss:  -1.6504 | Function Loss:  -1.9745\n",
      "################################  1654  ################################\n",
      "Total loss:  -1.482 | PDE Loss:  -1.6486 | Function Loss:  -1.9789\n",
      "################################  1655  ################################\n",
      "Total loss:  -1.4822 | PDE Loss:  -1.6508 | Function Loss:  -1.9746\n",
      "################################  1656  ################################\n",
      "Total loss:  -1.4823 | PDE Loss:  -1.6489 | Function Loss:  -1.979\n",
      "################################  1657  ################################\n",
      "Total loss:  -1.4825 | PDE Loss:  -1.6511 | Function Loss:  -1.9748\n",
      "################################  1658  ################################\n",
      "Total loss:  -1.4826 | PDE Loss:  -1.6493 | Function Loss:  -1.9791\n",
      "################################  1659  ################################\n",
      "Total loss:  -1.4828 | PDE Loss:  -1.6515 | Function Loss:  -1.975\n",
      "################################  1660  ################################\n",
      "Total loss:  -1.4829 | PDE Loss:  -1.6498 | Function Loss:  -1.9791\n",
      "################################  1661  ################################\n",
      "Total loss:  -1.4831 | PDE Loss:  -1.6518 | Function Loss:  -1.9753\n",
      "################################  1662  ################################\n",
      "Total loss:  -1.4832 | PDE Loss:  -1.6502 | Function Loss:  -1.9791\n",
      "################################  1663  ################################\n",
      "Total loss:  -1.4833 | PDE Loss:  -1.6521 | Function Loss:  -1.9755\n",
      "################################  1664  ################################\n",
      "Total loss:  -1.4835 | PDE Loss:  -1.6506 | Function Loss:  -1.9791\n",
      "################################  1665  ################################\n",
      "Total loss:  -1.4836 | PDE Loss:  -1.6524 | Function Loss:  -1.9758\n",
      "################################  1666  ################################\n",
      "Total loss:  -1.4838 | PDE Loss:  -1.6511 | Function Loss:  -1.979\n",
      "################################  1667  ################################\n",
      "Total loss:  -1.4839 | PDE Loss:  -1.6527 | Function Loss:  -1.9761\n",
      "################################  1668  ################################\n",
      "Total loss:  -1.4841 | PDE Loss:  -1.6515 | Function Loss:  -1.979\n",
      "################################  1669  ################################\n",
      "Total loss:  -1.4842 | PDE Loss:  -1.653 | Function Loss:  -1.9765\n",
      "################################  1670  ################################\n",
      "Total loss:  -1.4844 | PDE Loss:  -1.652 | Function Loss:  -1.9791\n",
      "################################  1671  ################################\n",
      "Total loss:  -1.4846 | PDE Loss:  -1.6533 | Function Loss:  -1.9769\n",
      "################################  1672  ################################\n",
      "Total loss:  -1.4848 | PDE Loss:  -1.6524 | Function Loss:  -1.9794\n",
      "################################  1673  ################################\n",
      "Total loss:  -1.485 | PDE Loss:  -1.6536 | Function Loss:  -1.9775\n",
      "################################  1674  ################################\n",
      "Total loss:  -1.4852 | PDE Loss:  -1.6528 | Function Loss:  -1.9799\n",
      "################################  1675  ################################\n",
      "Total loss:  -1.4854 | PDE Loss:  -1.654 | Function Loss:  -1.9781\n",
      "################################  1676  ################################\n",
      "Total loss:  -1.4857 | PDE Loss:  -1.6532 | Function Loss:  -1.9805\n",
      "################################  1677  ################################\n",
      "Total loss:  -1.4859 | PDE Loss:  -1.6544 | Function Loss:  -1.9785\n",
      "################################  1678  ################################\n",
      "Total loss:  -1.486 | PDE Loss:  -1.6534 | Function Loss:  -1.9811\n",
      "################################  1679  ################################\n",
      "Total loss:  -1.4862 | PDE Loss:  -1.6549 | Function Loss:  -1.9784\n",
      "################################  1680  ################################\n",
      "Total loss:  -1.4863 | PDE Loss:  -1.6536 | Function Loss:  -1.9814\n",
      "################################  1681  ################################\n",
      "Total loss:  -1.4863 | PDE Loss:  -1.6555 | Function Loss:  -1.9775\n",
      "################################  1682  ################################\n",
      "Total loss:  -1.4862 | PDE Loss:  -1.6538 | Function Loss:  -1.9811\n",
      "################################  1683  ################################\n",
      "Total loss:  -1.4862 | PDE Loss:  -1.6561 | Function Loss:  -1.9758\n",
      "################################  1684  ################################\n",
      "Total loss:  -1.4861 | PDE Loss:  -1.6538 | Function Loss:  -1.9804\n",
      "################################  1685  ################################\n",
      "Total loss:  -1.486 | PDE Loss:  -1.6567 | Function Loss:  -1.974\n",
      "################################  1686  ################################\n",
      "Total loss:  -1.486 | PDE Loss:  -1.6539 | Function Loss:  -1.9799\n",
      "################################  1687  ################################\n",
      "Total loss:  -1.4861 | PDE Loss:  -1.6573 | Function Loss:  -1.973\n",
      "################################  1688  ################################\n",
      "Total loss:  -1.4863 | PDE Loss:  -1.654 | Function Loss:  -1.9807\n",
      "################################  1689  ################################\n",
      "Total loss:  -1.4868 | PDE Loss:  -1.6578 | Function Loss:  -1.9741\n",
      "################################  1690  ################################\n",
      "Total loss:  -1.4874 | PDE Loss:  -1.6544 | Function Loss:  -1.9833\n",
      "################################  1691  ################################\n",
      "Total loss:  -1.4882 | PDE Loss:  -1.6582 | Function Loss:  -1.9777\n",
      "################################  1692  ################################\n",
      "Total loss:  -1.489 | PDE Loss:  -1.655 | Function Loss:  -1.9869\n",
      "################################  1693  ################################\n",
      "Total loss:  -1.4896 | PDE Loss:  -1.6583 | Function Loss:  -1.982\n",
      "################################  1694  ################################\n",
      "Total loss:  -1.49 | PDE Loss:  -1.6558 | Function Loss:  -1.9887\n",
      "################################  1695  ################################\n",
      "Total loss:  -1.4901 | PDE Loss:  -1.6583 | Function Loss:  -1.9832\n",
      "################################  1696  ################################\n",
      "Total loss:  -1.4896 | PDE Loss:  -1.6566 | Function Loss:  -1.9857\n",
      "################################  1697  ################################\n",
      "Total loss:  -1.4888 | PDE Loss:  -1.6583 | Function Loss:  -1.9794\n",
      "################################  1698  ################################\n",
      "Total loss:  -1.4877 | PDE Loss:  -1.6573 | Function Loss:  -1.9783\n",
      "################################  1699  ################################\n",
      "Total loss:  -1.4868 | PDE Loss:  -1.6583 | Function Loss:  -1.9732\n",
      "################################  1700  ################################\n",
      "Total loss:  -1.4863 | PDE Loss:  -1.6578 | Function Loss:  -1.9727\n",
      "################################  1701  ################################\n",
      "Total loss:  -1.4865 | PDE Loss:  -1.6585 | Function Loss:  -1.972\n",
      "################################  1702  ################################\n",
      "Total loss:  -1.4875 | PDE Loss:  -1.6582 | Function Loss:  -1.9756\n",
      "################################  1703  ################################\n",
      "Total loss:  -1.4888 | PDE Loss:  -1.659 | Function Loss:  -1.9781\n",
      "################################  1704  ################################\n",
      "Total loss:  -1.4902 | PDE Loss:  -1.6583 | Function Loss:  -1.9838\n",
      "################################  1705  ################################\n",
      "Total loss:  -1.4913 | PDE Loss:  -1.6597 | Function Loss:  -1.9843\n",
      "################################  1706  ################################\n",
      "Total loss:  -1.4919 | PDE Loss:  -1.6583 | Function Loss:  -1.9891\n",
      "################################  1707  ################################\n",
      "Total loss:  -1.492 | PDE Loss:  -1.6604 | Function Loss:  -1.985\n",
      "################################  1708  ################################\n",
      "Total loss:  -1.4917 | PDE Loss:  -1.6583 | Function Loss:  -1.9886\n",
      "################################  1709  ################################\n",
      "Total loss:  -1.4912 | PDE Loss:  -1.6611 | Function Loss:  -1.981\n",
      "################################  1710  ################################\n",
      "Total loss:  -1.4905 | PDE Loss:  -1.6585 | Function Loss:  -1.9845\n",
      "################################  1711  ################################\n",
      "Total loss:  -1.49 | PDE Loss:  -1.6616 | Function Loss:  -1.9764\n",
      "################################  1712  ################################\n",
      "Total loss:  -1.4897 | PDE Loss:  -1.6589 | Function Loss:  -1.9811\n",
      "################################  1713  ################################\n",
      "Total loss:  -1.4897 | PDE Loss:  -1.6618 | Function Loss:  -1.975\n",
      "################################  1714  ################################\n",
      "Total loss:  -1.4899 | PDE Loss:  -1.6596 | Function Loss:  -1.9802\n",
      "################################  1715  ################################\n",
      "Total loss:  -1.4903 | PDE Loss:  -1.6619 | Function Loss:  -1.9766\n",
      "################################  1716  ################################\n",
      "Total loss:  -1.4907 | PDE Loss:  -1.6604 | Function Loss:  -1.9809\n",
      "################################  1717  ################################\n",
      "Total loss:  -1.4911 | PDE Loss:  -1.6619 | Function Loss:  -1.9791\n",
      "################################  1718  ################################\n",
      "Total loss:  -1.4916 | PDE Loss:  -1.661 | Function Loss:  -1.9824\n",
      "################################  1719  ################################\n",
      "Total loss:  -1.4921 | PDE Loss:  -1.6621 | Function Loss:  -1.9816\n",
      "################################  1720  ################################\n",
      "Total loss:  -1.4925 | PDE Loss:  -1.6614 | Function Loss:  -1.9845\n",
      "################################  1721  ################################\n",
      "Total loss:  -1.4929 | PDE Loss:  -1.6625 | Function Loss:  -1.9834\n",
      "################################  1722  ################################\n",
      "Total loss:  -1.4932 | PDE Loss:  -1.6616 | Function Loss:  -1.9862\n",
      "################################  1723  ################################\n",
      "Total loss:  -1.4933 | PDE Loss:  -1.6631 | Function Loss:  -1.9832\n",
      "################################  1724  ################################\n",
      "Total loss:  -1.4931 | PDE Loss:  -1.6616 | Function Loss:  -1.9859\n",
      "################################  1725  ################################\n",
      "Total loss:  -1.4929 | PDE Loss:  -1.6638 | Function Loss:  -1.9806\n",
      "################################  1726  ################################\n",
      "Total loss:  -1.4925 | PDE Loss:  -1.6617 | Function Loss:  -1.9839\n",
      "################################  1727  ################################\n",
      "Total loss:  -1.4923 | PDE Loss:  -1.6643 | Function Loss:  -1.9777\n",
      "################################  1728  ################################\n",
      "Total loss:  -1.4923 | PDE Loss:  -1.6619 | Function Loss:  -1.9826\n",
      "################################  1729  ################################\n",
      "Total loss:  -1.4925 | PDE Loss:  -1.6647 | Function Loss:  -1.9774\n",
      "################################  1730  ################################\n",
      "Total loss:  -1.4929 | PDE Loss:  -1.6624 | Function Loss:  -1.9834\n",
      "################################  1731  ################################\n",
      "Total loss:  -1.4934 | PDE Loss:  -1.665 | Function Loss:  -1.9797\n",
      "################################  1732  ################################\n",
      "Total loss:  -1.4939 | PDE Loss:  -1.663 | Function Loss:  -1.9853\n",
      "################################  1733  ################################\n",
      "Total loss:  -1.4943 | PDE Loss:  -1.6651 | Function Loss:  -1.9823\n",
      "################################  1734  ################################\n",
      "Total loss:  -1.4946 | PDE Loss:  -1.6637 | Function Loss:  -1.9863\n",
      "################################  1735  ################################\n",
      "Total loss:  -1.4948 | PDE Loss:  -1.6653 | Function Loss:  -1.9833\n",
      "################################  1736  ################################\n",
      "Total loss:  -1.4949 | PDE Loss:  -1.6641 | Function Loss:  -1.9859\n",
      "################################  1737  ################################\n",
      "Total loss:  -1.4948 | PDE Loss:  -1.6656 | Function Loss:  -1.9828\n",
      "################################  1738  ################################\n",
      "Total loss:  -1.4948 | PDE Loss:  -1.6645 | Function Loss:  -1.9851\n",
      "################################  1739  ################################\n",
      "Total loss:  -1.4948 | PDE Loss:  -1.6661 | Function Loss:  -1.9817\n",
      "################################  1740  ################################\n",
      "Total loss:  -1.4948 | PDE Loss:  -1.6647 | Function Loss:  -1.9846\n",
      "################################  1741  ################################\n",
      "Total loss:  -1.4949 | PDE Loss:  -1.6666 | Function Loss:  -1.9808\n",
      "################################  1742  ################################\n",
      "Total loss:  -1.495 | PDE Loss:  -1.6649 | Function Loss:  -1.9847\n",
      "################################  1743  ################################\n",
      "Total loss:  -1.4951 | PDE Loss:  -1.6671 | Function Loss:  -1.9806\n",
      "################################  1744  ################################\n",
      "Total loss:  -1.4953 | PDE Loss:  -1.6651 | Function Loss:  -1.9854\n",
      "################################  1745  ################################\n",
      "Total loss:  -1.4956 | PDE Loss:  -1.6676 | Function Loss:  -1.9811\n",
      "################################  1746  ################################\n",
      "Total loss:  -1.4959 | PDE Loss:  -1.6655 | Function Loss:  -1.9864\n",
      "################################  1747  ################################\n",
      "Total loss:  -1.4962 | PDE Loss:  -1.6679 | Function Loss:  -1.9822\n",
      "################################  1748  ################################\n",
      "Total loss:  -1.4965 | PDE Loss:  -1.6659 | Function Loss:  -1.9873\n",
      "################################  1749  ################################\n",
      "Total loss:  -1.4967 | PDE Loss:  -1.6682 | Function Loss:  -1.9832\n",
      "################################  1750  ################################\n",
      "Total loss:  -1.4969 | PDE Loss:  -1.6664 | Function Loss:  -1.9874\n",
      "################################  1751  ################################\n",
      "Total loss:  -1.497 | PDE Loss:  -1.6685 | Function Loss:  -1.9833\n",
      "################################  1752  ################################\n",
      "Total loss:  -1.497 | PDE Loss:  -1.6669 | Function Loss:  -1.9867\n",
      "################################  1753  ################################\n",
      "Total loss:  -1.497 | PDE Loss:  -1.6688 | Function Loss:  -1.9827\n",
      "################################  1754  ################################\n",
      "Total loss:  -1.497 | PDE Loss:  -1.6673 | Function Loss:  -1.9858\n",
      "################################  1755  ################################\n",
      "Total loss:  -1.497 | PDE Loss:  -1.6691 | Function Loss:  -1.9823\n",
      "################################  1756  ################################\n",
      "Total loss:  -1.4972 | PDE Loss:  -1.6677 | Function Loss:  -1.9856\n",
      "################################  1757  ################################\n",
      "Total loss:  -1.4974 | PDE Loss:  -1.6695 | Function Loss:  -1.9825\n",
      "################################  1758  ################################\n",
      "Total loss:  -1.4976 | PDE Loss:  -1.668 | Function Loss:  -1.9864\n",
      "################################  1759  ################################\n",
      "Total loss:  -1.4979 | PDE Loss:  -1.6699 | Function Loss:  -1.9832\n",
      "################################  1760  ################################\n",
      "Total loss:  -1.4982 | PDE Loss:  -1.6683 | Function Loss:  -1.9875\n",
      "################################  1761  ################################\n",
      "Total loss:  -1.4984 | PDE Loss:  -1.6704 | Function Loss:  -1.9838\n",
      "################################  1762  ################################\n",
      "Total loss:  -1.4986 | PDE Loss:  -1.6686 | Function Loss:  -1.9882\n",
      "################################  1763  ################################\n",
      "Total loss:  -1.4987 | PDE Loss:  -1.6708 | Function Loss:  -1.984\n",
      "################################  1764  ################################\n",
      "Total loss:  -1.4989 | PDE Loss:  -1.6689 | Function Loss:  -1.9884\n",
      "################################  1765  ################################\n",
      "Total loss:  -1.499 | PDE Loss:  -1.6712 | Function Loss:  -1.9838\n",
      "################################  1766  ################################\n",
      "Total loss:  -1.499 | PDE Loss:  -1.6693 | Function Loss:  -1.9881\n",
      "################################  1767  ################################\n",
      "Total loss:  -1.4991 | PDE Loss:  -1.6716 | Function Loss:  -1.9836\n",
      "################################  1768  ################################\n",
      "Total loss:  -1.4992 | PDE Loss:  -1.6697 | Function Loss:  -1.9877\n",
      "################################  1769  ################################\n",
      "Total loss:  -1.4993 | PDE Loss:  -1.6719 | Function Loss:  -1.9836\n",
      "################################  1770  ################################\n",
      "Total loss:  -1.4994 | PDE Loss:  -1.6701 | Function Loss:  -1.9875\n",
      "################################  1771  ################################\n",
      "Total loss:  -1.4996 | PDE Loss:  -1.6722 | Function Loss:  -1.9838\n",
      "################################  1772  ################################\n",
      "Total loss:  -1.4998 | PDE Loss:  -1.6706 | Function Loss:  -1.9877\n",
      "################################  1773  ################################\n",
      "Total loss:  -1.5 | PDE Loss:  -1.6725 | Function Loss:  -1.9844\n",
      "################################  1774  ################################\n",
      "Total loss:  -1.5002 | PDE Loss:  -1.671 | Function Loss:  -1.9882\n",
      "################################  1775  ################################\n",
      "Total loss:  -1.5004 | PDE Loss:  -1.6729 | Function Loss:  -1.985\n",
      "################################  1776  ################################\n",
      "Total loss:  -1.5006 | PDE Loss:  -1.6713 | Function Loss:  -1.9888\n",
      "################################  1777  ################################\n",
      "Total loss:  -1.5008 | PDE Loss:  -1.6733 | Function Loss:  -1.9853\n",
      "################################  1778  ################################\n",
      "Total loss:  -1.501 | PDE Loss:  -1.6716 | Function Loss:  -1.9891\n",
      "################################  1779  ################################\n",
      "Total loss:  -1.5011 | PDE Loss:  -1.6737 | Function Loss:  -1.9852\n",
      "################################  1780  ################################\n",
      "Total loss:  -1.5012 | PDE Loss:  -1.6719 | Function Loss:  -1.9891\n",
      "################################  1781  ################################\n",
      "Total loss:  -1.5013 | PDE Loss:  -1.6741 | Function Loss:  -1.9849\n",
      "################################  1782  ################################\n",
      "Total loss:  -1.5014 | PDE Loss:  -1.6723 | Function Loss:  -1.9891\n",
      "################################  1783  ################################\n",
      "Total loss:  -1.5015 | PDE Loss:  -1.6745 | Function Loss:  -1.9848\n",
      "################################  1784  ################################\n",
      "Total loss:  -1.5016 | PDE Loss:  -1.6726 | Function Loss:  -1.9891\n",
      "################################  1785  ################################\n",
      "Total loss:  -1.5018 | PDE Loss:  -1.6749 | Function Loss:  -1.9849\n",
      "################################  1786  ################################\n",
      "Total loss:  -1.502 | PDE Loss:  -1.673 | Function Loss:  -1.9894\n",
      "################################  1787  ################################\n",
      "Total loss:  -1.5022 | PDE Loss:  -1.6753 | Function Loss:  -1.9854\n",
      "################################  1788  ################################\n",
      "Total loss:  -1.5024 | PDE Loss:  -1.6734 | Function Loss:  -1.9897\n",
      "################################  1789  ################################\n",
      "Total loss:  -1.5026 | PDE Loss:  -1.6756 | Function Loss:  -1.9859\n",
      "################################  1790  ################################\n",
      "Total loss:  -1.5027 | PDE Loss:  -1.6739 | Function Loss:  -1.99\n",
      "################################  1791  ################################\n",
      "Total loss:  -1.5029 | PDE Loss:  -1.6759 | Function Loss:  -1.9862\n",
      "################################  1792  ################################\n",
      "Total loss:  -1.503 | PDE Loss:  -1.6743 | Function Loss:  -1.99\n",
      "################################  1793  ################################\n",
      "Total loss:  -1.5032 | PDE Loss:  -1.6763 | Function Loss:  -1.9863\n",
      "################################  1794  ################################\n",
      "Total loss:  -1.5033 | PDE Loss:  -1.6746 | Function Loss:  -1.99\n",
      "################################  1795  ################################\n",
      "Total loss:  -1.5034 | PDE Loss:  -1.6766 | Function Loss:  -1.9863\n",
      "################################  1796  ################################\n",
      "Total loss:  -1.5035 | PDE Loss:  -1.675 | Function Loss:  -1.99\n",
      "################################  1797  ################################\n",
      "Total loss:  -1.5037 | PDE Loss:  -1.677 | Function Loss:  -1.9863\n",
      "################################  1798  ################################\n",
      "Total loss:  -1.5038 | PDE Loss:  -1.6753 | Function Loss:  -1.9903\n",
      "################################  1799  ################################\n",
      "Total loss:  -1.504 | PDE Loss:  -1.6774 | Function Loss:  -1.9865\n",
      "################################  1800  ################################\n",
      "Total loss:  -1.5042 | PDE Loss:  -1.6757 | Function Loss:  -1.9906\n",
      "################################  1801  ################################\n",
      "Total loss:  -1.5043 | PDE Loss:  -1.6778 | Function Loss:  -1.9867\n",
      "################################  1802  ################################\n",
      "Total loss:  -1.5045 | PDE Loss:  -1.676 | Function Loss:  -1.991\n",
      "################################  1803  ################################\n",
      "Total loss:  -1.5047 | PDE Loss:  -1.6782 | Function Loss:  -1.9869\n",
      "################################  1804  ################################\n",
      "Total loss:  -1.5048 | PDE Loss:  -1.6764 | Function Loss:  -1.9912\n",
      "################################  1805  ################################\n",
      "Total loss:  -1.505 | PDE Loss:  -1.6786 | Function Loss:  -1.9871\n",
      "################################  1806  ################################\n",
      "Total loss:  -1.5051 | PDE Loss:  -1.6768 | Function Loss:  -1.9914\n",
      "################################  1807  ################################\n",
      "Total loss:  -1.5053 | PDE Loss:  -1.679 | Function Loss:  -1.9872\n",
      "################################  1808  ################################\n",
      "Total loss:  -1.5054 | PDE Loss:  -1.6771 | Function Loss:  -1.9914\n",
      "################################  1809  ################################\n",
      "Total loss:  -1.5056 | PDE Loss:  -1.6793 | Function Loss:  -1.9873\n",
      "################################  1810  ################################\n",
      "Total loss:  -1.5057 | PDE Loss:  -1.6775 | Function Loss:  -1.9914\n",
      "################################  1811  ################################\n",
      "Total loss:  -1.5058 | PDE Loss:  -1.6797 | Function Loss:  -1.9875\n",
      "################################  1812  ################################\n",
      "Total loss:  -1.506 | PDE Loss:  -1.678 | Function Loss:  -1.9915\n",
      "################################  1813  ################################\n",
      "Total loss:  -1.5061 | PDE Loss:  -1.68 | Function Loss:  -1.9877\n",
      "################################  1814  ################################\n",
      "Total loss:  -1.5063 | PDE Loss:  -1.6783 | Function Loss:  -1.9916\n",
      "################################  1815  ################################\n",
      "Total loss:  -1.5065 | PDE Loss:  -1.6804 | Function Loss:  -1.988\n",
      "################################  1816  ################################\n",
      "Total loss:  -1.5066 | PDE Loss:  -1.6787 | Function Loss:  -1.9919\n",
      "################################  1817  ################################\n",
      "Total loss:  -1.5068 | PDE Loss:  -1.6808 | Function Loss:  -1.9882\n",
      "################################  1818  ################################\n",
      "Total loss:  -1.507 | PDE Loss:  -1.6791 | Function Loss:  -1.9922\n",
      "################################  1819  ################################\n",
      "Total loss:  -1.5071 | PDE Loss:  -1.6812 | Function Loss:  -1.9884\n",
      "################################  1820  ################################\n",
      "Total loss:  -1.5073 | PDE Loss:  -1.6794 | Function Loss:  -1.9924\n",
      "################################  1821  ################################\n",
      "Total loss:  -1.5074 | PDE Loss:  -1.6816 | Function Loss:  -1.9885\n",
      "################################  1822  ################################\n",
      "Total loss:  -1.5076 | PDE Loss:  -1.6798 | Function Loss:  -1.9926\n",
      "################################  1823  ################################\n",
      "Total loss:  -1.5077 | PDE Loss:  -1.682 | Function Loss:  -1.9886\n",
      "################################  1824  ################################\n",
      "Total loss:  -1.5079 | PDE Loss:  -1.6801 | Function Loss:  -1.9927\n",
      "################################  1825  ################################\n",
      "Total loss:  -1.508 | PDE Loss:  -1.6824 | Function Loss:  -1.9886\n",
      "################################  1826  ################################\n",
      "Total loss:  -1.5082 | PDE Loss:  -1.6805 | Function Loss:  -1.9929\n",
      "################################  1827  ################################\n",
      "Total loss:  -1.5083 | PDE Loss:  -1.6827 | Function Loss:  -1.9888\n",
      "################################  1828  ################################\n",
      "Total loss:  -1.5085 | PDE Loss:  -1.6809 | Function Loss:  -1.9931\n",
      "################################  1829  ################################\n",
      "Total loss:  -1.5086 | PDE Loss:  -1.6831 | Function Loss:  -1.989\n",
      "################################  1830  ################################\n",
      "Total loss:  -1.5088 | PDE Loss:  -1.6813 | Function Loss:  -1.9933\n",
      "################################  1831  ################################\n",
      "Total loss:  -1.509 | PDE Loss:  -1.6835 | Function Loss:  -1.9892\n",
      "################################  1832  ################################\n",
      "Total loss:  -1.5091 | PDE Loss:  -1.6816 | Function Loss:  -1.9935\n",
      "################################  1833  ################################\n",
      "Total loss:  -1.5093 | PDE Loss:  -1.6838 | Function Loss:  -1.9895\n",
      "################################  1834  ################################\n",
      "Total loss:  -1.5094 | PDE Loss:  -1.682 | Function Loss:  -1.9936\n",
      "################################  1835  ################################\n",
      "Total loss:  -1.5096 | PDE Loss:  -1.6842 | Function Loss:  -1.9896\n",
      "################################  1836  ################################\n",
      "Total loss:  -1.5097 | PDE Loss:  -1.6824 | Function Loss:  -1.9936\n",
      "################################  1837  ################################\n",
      "Total loss:  -1.5099 | PDE Loss:  -1.6846 | Function Loss:  -1.9898\n",
      "################################  1838  ################################\n",
      "Total loss:  -1.51 | PDE Loss:  -1.6828 | Function Loss:  -1.9937\n",
      "################################  1839  ################################\n",
      "Total loss:  -1.5102 | PDE Loss:  -1.6849 | Function Loss:  -1.99\n",
      "################################  1840  ################################\n",
      "Total loss:  -1.5103 | PDE Loss:  -1.6832 | Function Loss:  -1.9939\n",
      "################################  1841  ################################\n",
      "Total loss:  -1.5105 | PDE Loss:  -1.6853 | Function Loss:  -1.9902\n",
      "################################  1842  ################################\n",
      "Total loss:  -1.5106 | PDE Loss:  -1.6836 | Function Loss:  -1.9942\n",
      "################################  1843  ################################\n",
      "Total loss:  -1.5108 | PDE Loss:  -1.6857 | Function Loss:  -1.9904\n",
      "################################  1844  ################################\n",
      "Total loss:  -1.511 | PDE Loss:  -1.6839 | Function Loss:  -1.9944\n",
      "################################  1845  ################################\n",
      "Total loss:  -1.5111 | PDE Loss:  -1.6861 | Function Loss:  -1.9905\n",
      "################################  1846  ################################\n",
      "Total loss:  -1.5113 | PDE Loss:  -1.6843 | Function Loss:  -1.9946\n",
      "################################  1847  ################################\n",
      "Total loss:  -1.5114 | PDE Loss:  -1.6865 | Function Loss:  -1.9906\n",
      "################################  1848  ################################\n",
      "Total loss:  -1.5116 | PDE Loss:  -1.6847 | Function Loss:  -1.9948\n",
      "################################  1849  ################################\n",
      "Total loss:  -1.5117 | PDE Loss:  -1.6869 | Function Loss:  -1.9907\n",
      "################################  1850  ################################\n",
      "Total loss:  -1.5119 | PDE Loss:  -1.685 | Function Loss:  -1.995\n",
      "################################  1851  ################################\n",
      "Total loss:  -1.512 | PDE Loss:  -1.6873 | Function Loss:  -1.9909\n",
      "################################  1852  ################################\n",
      "Total loss:  -1.5122 | PDE Loss:  -1.6854 | Function Loss:  -1.9952\n",
      "################################  1853  ################################\n",
      "Total loss:  -1.5123 | PDE Loss:  -1.6877 | Function Loss:  -1.991\n",
      "################################  1854  ################################\n",
      "Total loss:  -1.5125 | PDE Loss:  -1.6858 | Function Loss:  -1.9953\n",
      "################################  1855  ################################\n",
      "Total loss:  -1.5127 | PDE Loss:  -1.688 | Function Loss:  -1.9912\n",
      "################################  1856  ################################\n",
      "Total loss:  -1.5128 | PDE Loss:  -1.6861 | Function Loss:  -1.9955\n",
      "################################  1857  ################################\n",
      "Total loss:  -1.513 | PDE Loss:  -1.6884 | Function Loss:  -1.9914\n",
      "################################  1858  ################################\n",
      "Total loss:  -1.5131 | PDE Loss:  -1.6865 | Function Loss:  -1.9957\n",
      "################################  1859  ################################\n",
      "Total loss:  -1.5133 | PDE Loss:  -1.6888 | Function Loss:  -1.9916\n",
      "################################  1860  ################################\n",
      "Total loss:  -1.5134 | PDE Loss:  -1.6869 | Function Loss:  -1.9958\n",
      "################################  1861  ################################\n",
      "Total loss:  -1.5136 | PDE Loss:  -1.6891 | Function Loss:  -1.9918\n",
      "################################  1862  ################################\n",
      "Total loss:  -1.5137 | PDE Loss:  -1.6873 | Function Loss:  -1.9959\n",
      "################################  1863  ################################\n",
      "Total loss:  -1.5139 | PDE Loss:  -1.6895 | Function Loss:  -1.992\n",
      "################################  1864  ################################\n",
      "Total loss:  -1.514 | PDE Loss:  -1.6877 | Function Loss:  -1.996\n",
      "################################  1865  ################################\n",
      "Total loss:  -1.5142 | PDE Loss:  -1.6899 | Function Loss:  -1.9922\n",
      "################################  1866  ################################\n",
      "Total loss:  -1.5144 | PDE Loss:  -1.6881 | Function Loss:  -1.9962\n",
      "################################  1867  ################################\n",
      "Total loss:  -1.5145 | PDE Loss:  -1.6902 | Function Loss:  -1.9924\n",
      "################################  1868  ################################\n",
      "Total loss:  -1.5147 | PDE Loss:  -1.6885 | Function Loss:  -1.9964\n",
      "################################  1869  ################################\n",
      "Total loss:  -1.5148 | PDE Loss:  -1.6906 | Function Loss:  -1.9926\n",
      "################################  1870  ################################\n",
      "Total loss:  -1.515 | PDE Loss:  -1.6889 | Function Loss:  -1.9966\n",
      "################################  1871  ################################\n",
      "Total loss:  -1.5152 | PDE Loss:  -1.691 | Function Loss:  -1.9928\n",
      "################################  1872  ################################\n",
      "Total loss:  -1.5153 | PDE Loss:  -1.6892 | Function Loss:  -1.9968\n",
      "################################  1873  ################################\n",
      "Total loss:  -1.5155 | PDE Loss:  -1.6914 | Function Loss:  -1.9929\n",
      "################################  1874  ################################\n",
      "Total loss:  -1.5156 | PDE Loss:  -1.6896 | Function Loss:  -1.997\n",
      "################################  1875  ################################\n",
      "Total loss:  -1.5158 | PDE Loss:  -1.6918 | Function Loss:  -1.993\n",
      "################################  1876  ################################\n",
      "Total loss:  -1.5159 | PDE Loss:  -1.6899 | Function Loss:  -1.9972\n",
      "################################  1877  ################################\n",
      "Total loss:  -1.5161 | PDE Loss:  -1.6922 | Function Loss:  -1.9931\n",
      "################################  1878  ################################\n",
      "Total loss:  -1.5162 | PDE Loss:  -1.6903 | Function Loss:  -1.9974\n",
      "################################  1879  ################################\n",
      "Total loss:  -1.5164 | PDE Loss:  -1.6926 | Function Loss:  -1.9932\n",
      "################################  1880  ################################\n",
      "Total loss:  -1.5165 | PDE Loss:  -1.6907 | Function Loss:  -1.9976\n",
      "################################  1881  ################################\n",
      "Total loss:  -1.5167 | PDE Loss:  -1.693 | Function Loss:  -1.9933\n",
      "################################  1882  ################################\n",
      "Total loss:  -1.5168 | PDE Loss:  -1.691 | Function Loss:  -1.9978\n",
      "################################  1883  ################################\n",
      "Total loss:  -1.517 | PDE Loss:  -1.6934 | Function Loss:  -1.9935\n",
      "################################  1884  ################################\n",
      "Total loss:  -1.5172 | PDE Loss:  -1.6914 | Function Loss:  -1.998\n",
      "################################  1885  ################################\n",
      "Total loss:  -1.5173 | PDE Loss:  -1.6938 | Function Loss:  -1.9937\n",
      "################################  1886  ################################\n",
      "Total loss:  -1.5175 | PDE Loss:  -1.6918 | Function Loss:  -1.9982\n",
      "################################  1887  ################################\n",
      "Total loss:  -1.5176 | PDE Loss:  -1.6942 | Function Loss:  -1.9939\n",
      "################################  1888  ################################\n",
      "Total loss:  -1.5178 | PDE Loss:  -1.6922 | Function Loss:  -1.9983\n",
      "################################  1889  ################################\n",
      "Total loss:  -1.518 | PDE Loss:  -1.6945 | Function Loss:  -1.9941\n",
      "################################  1890  ################################\n",
      "Total loss:  -1.5181 | PDE Loss:  -1.6926 | Function Loss:  -1.9984\n",
      "################################  1891  ################################\n",
      "Total loss:  -1.5183 | PDE Loss:  -1.6949 | Function Loss:  -1.9943\n",
      "################################  1892  ################################\n",
      "Total loss:  -1.5184 | PDE Loss:  -1.693 | Function Loss:  -1.9985\n",
      "################################  1893  ################################\n",
      "Total loss:  -1.5186 | PDE Loss:  -1.6952 | Function Loss:  -1.9945\n",
      "################################  1894  ################################\n",
      "Total loss:  -1.5187 | PDE Loss:  -1.6934 | Function Loss:  -1.9986\n",
      "################################  1895  ################################\n",
      "Total loss:  -1.5189 | PDE Loss:  -1.6956 | Function Loss:  -1.9948\n",
      "################################  1896  ################################\n",
      "Total loss:  -1.519 | PDE Loss:  -1.6939 | Function Loss:  -1.9987\n",
      "################################  1897  ################################\n",
      "Total loss:  -1.5192 | PDE Loss:  -1.6959 | Function Loss:  -1.995\n",
      "################################  1898  ################################\n",
      "Total loss:  -1.5194 | PDE Loss:  -1.6943 | Function Loss:  -1.9988\n",
      "################################  1899  ################################\n",
      "Total loss:  -1.5195 | PDE Loss:  -1.6963 | Function Loss:  -1.9953\n",
      "################################  1900  ################################\n",
      "Total loss:  -1.5197 | PDE Loss:  -1.6947 | Function Loss:  -1.999\n",
      "################################  1901  ################################\n",
      "Total loss:  -1.5199 | PDE Loss:  -1.6967 | Function Loss:  -1.9955\n",
      "################################  1902  ################################\n",
      "Total loss:  -1.52 | PDE Loss:  -1.6951 | Function Loss:  -1.9992\n",
      "################################  1903  ################################\n",
      "Total loss:  -1.5202 | PDE Loss:  -1.6971 | Function Loss:  -1.9957\n",
      "################################  1904  ################################\n",
      "Total loss:  -1.5203 | PDE Loss:  -1.6954 | Function Loss:  -1.9995\n",
      "################################  1905  ################################\n",
      "Total loss:  -1.5205 | PDE Loss:  -1.6975 | Function Loss:  -1.9959\n",
      "################################  1906  ################################\n",
      "Total loss:  -1.5206 | PDE Loss:  -1.6958 | Function Loss:  -1.9997\n",
      "################################  1907  ################################\n",
      "Total loss:  -1.5208 | PDE Loss:  -1.6979 | Function Loss:  -1.9959\n",
      "################################  1908  ################################\n",
      "Total loss:  -1.5209 | PDE Loss:  -1.6961 | Function Loss:  -1.9999\n",
      "################################  1909  ################################\n",
      "Total loss:  -1.5211 | PDE Loss:  -1.6983 | Function Loss:  -1.9959\n",
      "################################  1910  ################################\n",
      "Total loss:  -1.5212 | PDE Loss:  -1.6964 | Function Loss:  -2.0001\n",
      "################################  1911  ################################\n",
      "Total loss:  -1.5214 | PDE Loss:  -1.6988 | Function Loss:  -1.9959\n",
      "################################  1912  ################################\n",
      "Total loss:  -1.5215 | PDE Loss:  -1.6967 | Function Loss:  -2.0004\n",
      "################################  1913  ################################\n",
      "Total loss:  -1.5217 | PDE Loss:  -1.6993 | Function Loss:  -1.9958\n",
      "################################  1914  ################################\n",
      "Total loss:  -1.5218 | PDE Loss:  -1.697 | Function Loss:  -2.0007\n",
      "################################  1915  ################################\n",
      "Total loss:  -1.522 | PDE Loss:  -1.6997 | Function Loss:  -1.9958\n",
      "################################  1916  ################################\n",
      "Total loss:  -1.5221 | PDE Loss:  -1.6974 | Function Loss:  -2.001\n",
      "################################  1917  ################################\n",
      "Total loss:  -1.5223 | PDE Loss:  -1.7002 | Function Loss:  -1.9959\n",
      "################################  1918  ################################\n",
      "Total loss:  -1.5225 | PDE Loss:  -1.6977 | Function Loss:  -2.0014\n",
      "################################  1919  ################################\n",
      "Total loss:  -1.5227 | PDE Loss:  -1.7006 | Function Loss:  -1.9961\n",
      "################################  1920  ################################\n",
      "Total loss:  -1.5229 | PDE Loss:  -1.698 | Function Loss:  -2.0018\n",
      "################################  1921  ################################\n",
      "Total loss:  -1.5231 | PDE Loss:  -1.701 | Function Loss:  -1.9965\n",
      "################################  1922  ################################\n",
      "Total loss:  -1.5233 | PDE Loss:  -1.6984 | Function Loss:  -2.0023\n",
      "################################  1923  ################################\n",
      "Total loss:  -1.5235 | PDE Loss:  -1.7014 | Function Loss:  -1.997\n",
      "################################  1924  ################################\n",
      "Total loss:  -1.5236 | PDE Loss:  -1.6989 | Function Loss:  -2.0025\n",
      "################################  1925  ################################\n",
      "Total loss:  -1.5238 | PDE Loss:  -1.7017 | Function Loss:  -1.9974\n",
      "################################  1926  ################################\n",
      "Total loss:  -1.524 | PDE Loss:  -1.6994 | Function Loss:  -2.0024\n",
      "################################  1927  ################################\n",
      "Total loss:  -1.5241 | PDE Loss:  -1.702 | Function Loss:  -1.9976\n",
      "################################  1928  ################################\n",
      "Total loss:  -1.5241 | PDE Loss:  -1.6999 | Function Loss:  -2.0019\n",
      "################################  1929  ################################\n",
      "Total loss:  -1.5242 | PDE Loss:  -1.7022 | Function Loss:  -1.9975\n",
      "################################  1930  ################################\n",
      "Total loss:  -1.5242 | PDE Loss:  -1.7005 | Function Loss:  -2.001\n",
      "################################  1931  ################################\n",
      "Total loss:  -1.5242 | PDE Loss:  -1.7024 | Function Loss:  -1.9973\n",
      "################################  1932  ################################\n",
      "Total loss:  -1.5243 | PDE Loss:  -1.7011 | Function Loss:  -2.0\n",
      "################################  1933  ################################\n",
      "Total loss:  -1.5244 | PDE Loss:  -1.7026 | Function Loss:  -1.9974\n",
      "################################  1934  ################################\n",
      "Total loss:  -1.5245 | PDE Loss:  -1.7017 | Function Loss:  -1.9996\n",
      "################################  1935  ################################\n",
      "Total loss:  -1.5248 | PDE Loss:  -1.7027 | Function Loss:  -1.9981\n",
      "################################  1936  ################################\n",
      "Total loss:  -1.525 | PDE Loss:  -1.7022 | Function Loss:  -2.0\n",
      "################################  1937  ################################\n",
      "Total loss:  -1.5254 | PDE Loss:  -1.703 | Function Loss:  -1.9996\n",
      "################################  1938  ################################\n",
      "Total loss:  -1.5258 | PDE Loss:  -1.7027 | Function Loss:  -2.0015\n",
      "################################  1939  ################################\n",
      "Total loss:  -1.5263 | PDE Loss:  -1.7033 | Function Loss:  -2.0016\n",
      "################################  1940  ################################\n",
      "Total loss:  -1.5268 | PDE Loss:  -1.703 | Function Loss:  -2.0035\n",
      "################################  1941  ################################\n",
      "Total loss:  -1.5271 | PDE Loss:  -1.7038 | Function Loss:  -2.0031\n",
      "################################  1942  ################################\n",
      "Total loss:  -1.5274 | PDE Loss:  -1.7033 | Function Loss:  -2.005\n",
      "################################  1943  ################################\n",
      "Total loss:  -1.5275 | PDE Loss:  -1.7045 | Function Loss:  -2.0028\n",
      "################################  1944  ################################\n",
      "Total loss:  -1.5274 | PDE Loss:  -1.7033 | Function Loss:  -2.0049\n",
      "################################  1945  ################################\n",
      "Total loss:  -1.5271 | PDE Loss:  -1.7053 | Function Loss:  -2.0001\n",
      "################################  1946  ################################\n",
      "Total loss:  -1.5266 | PDE Loss:  -1.7033 | Function Loss:  -2.0026\n",
      "################################  1947  ################################\n",
      "Total loss:  -1.5261 | PDE Loss:  -1.706 | Function Loss:  -1.9958\n",
      "################################  1948  ################################\n",
      "Total loss:  -1.5258 | PDE Loss:  -1.7032 | Function Loss:  -2.0001\n",
      "################################  1949  ################################\n",
      "Total loss:  -1.5257 | PDE Loss:  -1.7067 | Function Loss:  -1.993\n",
      "################################  1950  ################################\n",
      "Total loss:  -1.5259 | PDE Loss:  -1.7034 | Function Loss:  -2.0003\n",
      "################################  1951  ################################\n",
      "Total loss:  -1.5266 | PDE Loss:  -1.7072 | Function Loss:  -1.9947\n",
      "################################  1952  ################################\n",
      "Total loss:  -1.5275 | PDE Loss:  -1.7038 | Function Loss:  -2.0042\n",
      "################################  1953  ################################\n",
      "Total loss:  -1.5286 | PDE Loss:  -1.7076 | Function Loss:  -1.9999\n",
      "################################  1954  ################################\n",
      "Total loss:  -1.5295 | PDE Loss:  -1.7045 | Function Loss:  -2.0089\n",
      "################################  1955  ################################\n",
      "Total loss:  -1.5302 | PDE Loss:  -1.7077 | Function Loss:  -2.0046\n",
      "################################  1956  ################################\n",
      "Total loss:  -1.5306 | PDE Loss:  -1.7052 | Function Loss:  -2.0106\n",
      "################################  1957  ################################\n",
      "Total loss:  -1.5305 | PDE Loss:  -1.7078 | Function Loss:  -2.0051\n",
      "################################  1958  ################################\n",
      "Total loss:  -1.5299 | PDE Loss:  -1.706 | Function Loss:  -2.0072\n",
      "################################  1959  ################################\n",
      "Total loss:  -1.5291 | PDE Loss:  -1.7079 | Function Loss:  -2.0007\n",
      "################################  1960  ################################\n",
      "Total loss:  -1.5282 | PDE Loss:  -1.7066 | Function Loss:  -2.0007\n",
      "################################  1961  ################################\n",
      "Total loss:  -1.5275 | PDE Loss:  -1.7081 | Function Loss:  -1.9957\n",
      "################################  1962  ################################\n",
      "Total loss:  -1.5273 | PDE Loss:  -1.707 | Function Loss:  -1.9973\n",
      "################################  1963  ################################\n",
      "Total loss:  -1.5277 | PDE Loss:  -1.7084 | Function Loss:  -1.9958\n",
      "################################  1964  ################################\n",
      "Total loss:  -1.5287 | PDE Loss:  -1.7074 | Function Loss:  -2.0006\n",
      "################################  1965  ################################\n",
      "Total loss:  -1.5298 | PDE Loss:  -1.7089 | Function Loss:  -2.0009\n",
      "################################  1966  ################################\n",
      "Total loss:  -1.5308 | PDE Loss:  -1.7076 | Function Loss:  -2.0067\n",
      "################################  1967  ################################\n",
      "Total loss:  -1.5316 | PDE Loss:  -1.7095 | Function Loss:  -2.0052\n",
      "################################  1968  ################################\n",
      "Total loss:  -1.532 | PDE Loss:  -1.7077 | Function Loss:  -2.01\n",
      "################################  1969  ################################\n",
      "Total loss:  -1.532 | PDE Loss:  -1.7102 | Function Loss:  -2.0051\n",
      "################################  1970  ################################\n",
      "Total loss:  -1.5318 | PDE Loss:  -1.7078 | Function Loss:  -2.0089\n",
      "################################  1971  ################################\n",
      "Total loss:  -1.5313 | PDE Loss:  -1.7108 | Function Loss:  -2.0016\n",
      "################################  1972  ################################\n",
      "Total loss:  -1.5308 | PDE Loss:  -1.708 | Function Loss:  -2.0055\n",
      "################################  1973  ################################\n",
      "Total loss:  -1.5304 | PDE Loss:  -1.7113 | Function Loss:  -1.9981\n",
      "################################  1974  ################################\n",
      "Total loss:  -1.5303 | PDE Loss:  -1.7085 | Function Loss:  -2.0032\n",
      "################################  1975  ################################\n",
      "Total loss:  -1.5305 | PDE Loss:  -1.7116 | Function Loss:  -1.9977\n",
      "################################  1976  ################################\n",
      "Total loss:  -1.5309 | PDE Loss:  -1.7091 | Function Loss:  -2.0038\n",
      "################################  1977  ################################\n",
      "Total loss:  -1.5314 | PDE Loss:  -1.7118 | Function Loss:  -2.0002\n",
      "################################  1978  ################################\n",
      "Total loss:  -1.532 | PDE Loss:  -1.7098 | Function Loss:  -2.0056\n",
      "################################  1979  ################################\n",
      "Total loss:  -1.5324 | PDE Loss:  -1.7119 | Function Loss:  -2.0029\n",
      "################################  1980  ################################\n",
      "Total loss:  -1.5328 | PDE Loss:  -1.7105 | Function Loss:  -2.0068\n",
      "################################  1981  ################################\n",
      "Total loss:  -1.533 | PDE Loss:  -1.7121 | Function Loss:  -2.0041\n",
      "################################  1982  ################################\n",
      "Total loss:  -1.5331 | PDE Loss:  -1.7109 | Function Loss:  -2.0068\n",
      "################################  1983  ################################\n",
      "Total loss:  -1.5332 | PDE Loss:  -1.7125 | Function Loss:  -2.004\n",
      "################################  1984  ################################\n",
      "Total loss:  -1.5332 | PDE Loss:  -1.7113 | Function Loss:  -2.0065\n",
      "################################  1985  ################################\n",
      "Total loss:  -1.5332 | PDE Loss:  -1.713 | Function Loss:  -2.0032\n",
      "################################  1986  ################################\n",
      "Total loss:  -1.5333 | PDE Loss:  -1.7115 | Function Loss:  -2.0061\n",
      "################################  1987  ################################\n",
      "Total loss:  -1.5333 | PDE Loss:  -1.7136 | Function Loss:  -2.0021\n",
      "################################  1988  ################################\n",
      "Total loss:  -1.5333 | PDE Loss:  -1.7116 | Function Loss:  -2.0059\n",
      "################################  1989  ################################\n",
      "Total loss:  -1.5334 | PDE Loss:  -1.7142 | Function Loss:  -2.0012\n",
      "################################  1990  ################################\n",
      "Total loss:  -1.5335 | PDE Loss:  -1.7118 | Function Loss:  -2.0062\n",
      "################################  1991  ################################\n",
      "Total loss:  -1.5337 | PDE Loss:  -1.7147 | Function Loss:  -2.0013\n",
      "################################  1992  ################################\n",
      "Total loss:  -1.534 | PDE Loss:  -1.7121 | Function Loss:  -2.0072\n",
      "################################  1993  ################################\n",
      "Total loss:  -1.5344 | PDE Loss:  -1.7151 | Function Loss:  -2.0024\n",
      "################################  1994  ################################\n",
      "Total loss:  -1.5348 | PDE Loss:  -1.7126 | Function Loss:  -2.0085\n",
      "################################  1995  ################################\n",
      "Total loss:  -1.5351 | PDE Loss:  -1.7155 | Function Loss:  -2.0039\n",
      "################################  1996  ################################\n",
      "Total loss:  -1.5354 | PDE Loss:  -1.7131 | Function Loss:  -2.0093\n",
      "################################  1997  ################################\n",
      "Total loss:  -1.5356 | PDE Loss:  -1.7158 | Function Loss:  -2.0046\n",
      "################################  1998  ################################\n",
      "Total loss:  -1.5356 | PDE Loss:  -1.7137 | Function Loss:  -2.0087\n",
      "################################  1999  ################################\n",
      "Total loss:  -1.5356 | PDE Loss:  -1.716 | Function Loss:  -2.0041\n",
      "################################  2000  ################################\n",
      "Total loss:  -1.5355 | PDE Loss:  -1.7143 | Function Loss:  -2.0073\n",
      "################################  2001  ################################\n",
      "Total loss:  -1.5354 | PDE Loss:  -1.7163 | Function Loss:  -2.0031\n",
      "################################  2002  ################################\n",
      "Total loss:  -1.5354 | PDE Loss:  -1.7147 | Function Loss:  -2.0063\n",
      "################################  2003  ################################\n",
      "Total loss:  -1.5356 | PDE Loss:  -1.7167 | Function Loss:  -2.003\n",
      "################################  2004  ################################\n",
      "Total loss:  -1.5359 | PDE Loss:  -1.7151 | Function Loss:  -2.0068\n",
      "################################  2005  ################################\n",
      "Total loss:  -1.5362 | PDE Loss:  -1.7171 | Function Loss:  -2.004\n",
      "################################  2006  ################################\n",
      "Total loss:  -1.5366 | PDE Loss:  -1.7154 | Function Loss:  -2.0083\n",
      "################################  2007  ################################\n",
      "Total loss:  -1.537 | PDE Loss:  -1.7176 | Function Loss:  -2.0053\n",
      "################################  2008  ################################\n",
      "Total loss:  -1.5373 | PDE Loss:  -1.7157 | Function Loss:  -2.0097\n",
      "################################  2009  ################################\n",
      "Total loss:  -1.5374 | PDE Loss:  -1.7181 | Function Loss:  -2.0056\n",
      "################################  2010  ################################\n",
      "Total loss:  -1.5375 | PDE Loss:  -1.716 | Function Loss:  -2.01\n",
      "################################  2011  ################################\n",
      "Total loss:  -1.5375 | PDE Loss:  -1.7186 | Function Loss:  -2.0048\n",
      "################################  2012  ################################\n",
      "Total loss:  -1.5375 | PDE Loss:  -1.7163 | Function Loss:  -2.0094\n",
      "################################  2013  ################################\n",
      "Total loss:  -1.5375 | PDE Loss:  -1.7191 | Function Loss:  -2.0039\n",
      "################################  2014  ################################\n",
      "Total loss:  -1.5376 | PDE Loss:  -1.7166 | Function Loss:  -2.0089\n",
      "################################  2015  ################################\n",
      "Total loss:  -1.5377 | PDE Loss:  -1.7195 | Function Loss:  -2.0037\n",
      "################################  2016  ################################\n",
      "Total loss:  -1.538 | PDE Loss:  -1.7171 | Function Loss:  -2.0091\n",
      "################################  2017  ################################\n",
      "Total loss:  -1.5382 | PDE Loss:  -1.7199 | Function Loss:  -2.0045\n",
      "################################  2018  ################################\n",
      "Total loss:  -1.5385 | PDE Loss:  -1.7176 | Function Loss:  -2.0097\n",
      "################################  2019  ################################\n",
      "Total loss:  -1.5388 | PDE Loss:  -1.7202 | Function Loss:  -2.0056\n",
      "################################  2020  ################################\n",
      "Total loss:  -1.539 | PDE Loss:  -1.7182 | Function Loss:  -2.0102\n",
      "################################  2021  ################################\n",
      "Total loss:  -1.5392 | PDE Loss:  -1.7204 | Function Loss:  -2.0063\n",
      "################################  2022  ################################\n",
      "Total loss:  -1.5393 | PDE Loss:  -1.7187 | Function Loss:  -2.0101\n",
      "################################  2023  ################################\n",
      "Total loss:  -1.5394 | PDE Loss:  -1.7208 | Function Loss:  -2.0063\n",
      "################################  2024  ################################\n",
      "Total loss:  -1.5395 | PDE Loss:  -1.7191 | Function Loss:  -2.0098\n",
      "################################  2025  ################################\n",
      "Total loss:  -1.5396 | PDE Loss:  -1.7212 | Function Loss:  -2.006\n",
      "################################  2026  ################################\n",
      "Total loss:  -1.5397 | PDE Loss:  -1.7195 | Function Loss:  -2.0097\n",
      "################################  2027  ################################\n",
      "Total loss:  -1.5399 | PDE Loss:  -1.7216 | Function Loss:  -2.006\n",
      "################################  2028  ################################\n",
      "Total loss:  -1.5401 | PDE Loss:  -1.7198 | Function Loss:  -2.01\n",
      "################################  2029  ################################\n",
      "Total loss:  -1.5403 | PDE Loss:  -1.7221 | Function Loss:  -2.0063\n",
      "################################  2030  ################################\n",
      "Total loss:  -1.5405 | PDE Loss:  -1.7201 | Function Loss:  -2.0107\n",
      "################################  2031  ################################\n",
      "Total loss:  -1.5407 | PDE Loss:  -1.7226 | Function Loss:  -2.0065\n",
      "################################  2032  ################################\n",
      "Total loss:  -1.5409 | PDE Loss:  -1.7204 | Function Loss:  -2.0112\n",
      "################################  2033  ################################\n",
      "Total loss:  -1.541 | PDE Loss:  -1.7231 | Function Loss:  -2.0066\n",
      "################################  2034  ################################\n",
      "Total loss:  -1.5412 | PDE Loss:  -1.7208 | Function Loss:  -2.0115\n",
      "################################  2035  ################################\n",
      "Total loss:  -1.5413 | PDE Loss:  -1.7235 | Function Loss:  -2.0065\n",
      "################################  2036  ################################\n",
      "Total loss:  -1.5415 | PDE Loss:  -1.7211 | Function Loss:  -2.0116\n",
      "################################  2037  ################################\n",
      "Total loss:  -1.5416 | PDE Loss:  -1.724 | Function Loss:  -2.0066\n",
      "################################  2038  ################################\n",
      "Total loss:  -1.5418 | PDE Loss:  -1.7216 | Function Loss:  -2.0117\n",
      "################################  2039  ################################\n",
      "Total loss:  -1.542 | PDE Loss:  -1.7243 | Function Loss:  -2.0069\n",
      "################################  2040  ################################\n",
      "Total loss:  -1.5422 | PDE Loss:  -1.722 | Function Loss:  -2.0119\n",
      "################################  2041  ################################\n",
      "Total loss:  -1.5424 | PDE Loss:  -1.7247 | Function Loss:  -2.0073\n",
      "################################  2042  ################################\n",
      "Total loss:  -1.5425 | PDE Loss:  -1.7225 | Function Loss:  -2.0119\n",
      "################################  2043  ################################\n",
      "Total loss:  -1.5427 | PDE Loss:  -1.725 | Function Loss:  -2.0076\n",
      "################################  2044  ################################\n",
      "Total loss:  -1.5428 | PDE Loss:  -1.723 | Function Loss:  -2.0118\n",
      "################################  2045  ################################\n",
      "Total loss:  -1.543 | PDE Loss:  -1.7253 | Function Loss:  -2.0078\n",
      "################################  2046  ################################\n",
      "Total loss:  -1.5431 | PDE Loss:  -1.7235 | Function Loss:  -2.0117\n",
      "################################  2047  ################################\n",
      "Total loss:  -1.5433 | PDE Loss:  -1.7257 | Function Loss:  -2.008\n",
      "################################  2048  ################################\n",
      "Total loss:  -1.5434 | PDE Loss:  -1.724 | Function Loss:  -2.0119\n",
      "################################  2049  ################################\n",
      "Total loss:  -1.5436 | PDE Loss:  -1.7261 | Function Loss:  -2.0083\n",
      "################################  2050  ################################\n",
      "Total loss:  -1.5438 | PDE Loss:  -1.7243 | Function Loss:  -2.0122\n",
      "################################  2051  ################################\n",
      "Total loss:  -1.544 | PDE Loss:  -1.7265 | Function Loss:  -2.0086\n",
      "################################  2052  ################################\n",
      "Total loss:  -1.5442 | PDE Loss:  -1.7247 | Function Loss:  -2.0127\n",
      "################################  2053  ################################\n",
      "Total loss:  -1.5444 | PDE Loss:  -1.727 | Function Loss:  -2.0088\n",
      "################################  2054  ################################\n",
      "Total loss:  -1.5446 | PDE Loss:  -1.725 | Function Loss:  -2.0131\n",
      "################################  2055  ################################\n",
      "Total loss:  -1.5447 | PDE Loss:  -1.7275 | Function Loss:  -2.0087\n",
      "################################  2056  ################################\n",
      "Total loss:  -1.5448 | PDE Loss:  -1.7254 | Function Loss:  -2.0132\n",
      "################################  2057  ################################\n",
      "Total loss:  -1.5449 | PDE Loss:  -1.728 | Function Loss:  -2.0085\n",
      "################################  2058  ################################\n",
      "Total loss:  -1.5451 | PDE Loss:  -1.7257 | Function Loss:  -2.0133\n",
      "################################  2059  ################################\n",
      "Total loss:  -1.5452 | PDE Loss:  -1.7285 | Function Loss:  -2.0083\n",
      "################################  2060  ################################\n",
      "Total loss:  -1.5454 | PDE Loss:  -1.7261 | Function Loss:  -2.0135\n",
      "################################  2061  ################################\n",
      "Total loss:  -1.5456 | PDE Loss:  -1.7289 | Function Loss:  -2.0086\n",
      "################################  2062  ################################\n",
      "Total loss:  -1.5458 | PDE Loss:  -1.7265 | Function Loss:  -2.0139\n",
      "################################  2063  ################################\n",
      "Total loss:  -1.546 | PDE Loss:  -1.7293 | Function Loss:  -2.0091\n",
      "################################  2064  ################################\n",
      "Total loss:  -1.5463 | PDE Loss:  -1.7269 | Function Loss:  -2.0144\n",
      "################################  2065  ################################\n",
      "Total loss:  -1.5465 | PDE Loss:  -1.7297 | Function Loss:  -2.0096\n",
      "################################  2066  ################################\n",
      "Total loss:  -1.5466 | PDE Loss:  -1.7274 | Function Loss:  -2.0146\n",
      "################################  2067  ################################\n",
      "Total loss:  -1.5468 | PDE Loss:  -1.7301 | Function Loss:  -2.0099\n",
      "################################  2068  ################################\n",
      "Total loss:  -1.5469 | PDE Loss:  -1.7279 | Function Loss:  -2.0144\n",
      "################################  2069  ################################\n",
      "Total loss:  -1.547 | PDE Loss:  -1.7304 | Function Loss:  -2.0099\n",
      "################################  2070  ################################\n",
      "Total loss:  -1.5471 | PDE Loss:  -1.7284 | Function Loss:  -2.0141\n",
      "################################  2071  ################################\n",
      "Total loss:  -1.5472 | PDE Loss:  -1.7307 | Function Loss:  -2.0099\n",
      "################################  2072  ################################\n",
      "Total loss:  -1.5474 | PDE Loss:  -1.7289 | Function Loss:  -2.0139\n",
      "################################  2073  ################################\n",
      "Total loss:  -1.5476 | PDE Loss:  -1.7311 | Function Loss:  -2.0101\n",
      "################################  2074  ################################\n",
      "Total loss:  -1.5478 | PDE Loss:  -1.7293 | Function Loss:  -2.0141\n",
      "################################  2075  ################################\n",
      "Total loss:  -1.548 | PDE Loss:  -1.7315 | Function Loss:  -2.0106\n",
      "################################  2076  ################################\n",
      "Total loss:  -1.5482 | PDE Loss:  -1.7298 | Function Loss:  -2.0146\n",
      "################################  2077  ################################\n",
      "Total loss:  -1.5484 | PDE Loss:  -1.7319 | Function Loss:  -2.0112\n",
      "################################  2078  ################################\n",
      "Total loss:  -1.5486 | PDE Loss:  -1.7301 | Function Loss:  -2.0152\n",
      "################################  2079  ################################\n",
      "Total loss:  -1.5488 | PDE Loss:  -1.7324 | Function Loss:  -2.0114\n",
      "################################  2080  ################################\n",
      "Total loss:  -1.549 | PDE Loss:  -1.7305 | Function Loss:  -2.0154\n",
      "################################  2081  ################################\n",
      "Total loss:  -1.5491 | PDE Loss:  -1.7329 | Function Loss:  -2.0113\n",
      "################################  2082  ################################\n",
      "Total loss:  -1.5492 | PDE Loss:  -1.7308 | Function Loss:  -2.0155\n",
      "################################  2083  ################################\n",
      "Total loss:  -1.5493 | PDE Loss:  -1.7334 | Function Loss:  -2.0109\n",
      "################################  2084  ################################\n",
      "Total loss:  -1.5494 | PDE Loss:  -1.7311 | Function Loss:  -2.0155\n",
      "################################  2085  ################################\n",
      "Total loss:  -1.5495 | PDE Loss:  -1.7339 | Function Loss:  -2.0106\n",
      "################################  2086  ################################\n",
      "Total loss:  -1.5497 | PDE Loss:  -1.7315 | Function Loss:  -2.0157\n",
      "################################  2087  ################################\n",
      "Total loss:  -1.5499 | PDE Loss:  -1.7344 | Function Loss:  -2.0106\n",
      "################################  2088  ################################\n",
      "Total loss:  -1.5501 | PDE Loss:  -1.7318 | Function Loss:  -2.0162\n",
      "################################  2089  ################################\n",
      "Total loss:  -1.5503 | PDE Loss:  -1.7349 | Function Loss:  -2.0111\n",
      "################################  2090  ################################\n",
      "Total loss:  -1.5506 | PDE Loss:  -1.7322 | Function Loss:  -2.0169\n",
      "################################  2091  ################################\n",
      "Total loss:  -1.5508 | PDE Loss:  -1.7353 | Function Loss:  -2.0117\n",
      "################################  2092  ################################\n",
      "Total loss:  -1.5511 | PDE Loss:  -1.7327 | Function Loss:  -2.0174\n",
      "################################  2093  ################################\n",
      "Total loss:  -1.5513 | PDE Loss:  -1.7357 | Function Loss:  -2.0122\n",
      "################################  2094  ################################\n",
      "Total loss:  -1.5514 | PDE Loss:  -1.7331 | Function Loss:  -2.0175\n",
      "################################  2095  ################################\n",
      "Total loss:  -1.5515 | PDE Loss:  -1.736 | Function Loss:  -2.0123\n",
      "################################  2096  ################################\n",
      "Total loss:  -1.5517 | PDE Loss:  -1.7337 | Function Loss:  -2.0172\n",
      "################################  2097  ################################\n",
      "Total loss:  -1.5517 | PDE Loss:  -1.7364 | Function Loss:  -2.0123\n",
      "################################  2098  ################################\n",
      "Total loss:  -1.5518 | PDE Loss:  -1.7342 | Function Loss:  -2.0166\n",
      "################################  2099  ################################\n",
      "Total loss:  -1.5519 | PDE Loss:  -1.7367 | Function Loss:  -2.0122\n",
      "################################  2100  ################################\n",
      "Total loss:  -1.5521 | PDE Loss:  -1.7348 | Function Loss:  -2.0162\n",
      "################################  2101  ################################\n",
      "Total loss:  -1.5522 | PDE Loss:  -1.737 | Function Loss:  -2.0125\n",
      "################################  2102  ################################\n",
      "Total loss:  -1.5524 | PDE Loss:  -1.7353 | Function Loss:  -2.0162\n",
      "################################  2103  ################################\n",
      "Total loss:  -1.5526 | PDE Loss:  -1.7373 | Function Loss:  -2.0131\n",
      "################################  2104  ################################\n",
      "Total loss:  -1.5529 | PDE Loss:  -1.7358 | Function Loss:  -2.0167\n",
      "################################  2105  ################################\n",
      "Total loss:  -1.5532 | PDE Loss:  -1.7377 | Function Loss:  -2.0139\n",
      "################################  2106  ################################\n",
      "Total loss:  -1.5534 | PDE Loss:  -1.7363 | Function Loss:  -2.0174\n",
      "################################  2107  ################################\n",
      "Total loss:  -1.5537 | PDE Loss:  -1.7381 | Function Loss:  -2.0146\n",
      "################################  2108  ################################\n",
      "Total loss:  -1.5539 | PDE Loss:  -1.7367 | Function Loss:  -2.0179\n",
      "################################  2109  ################################\n",
      "Total loss:  -1.554 | PDE Loss:  -1.7386 | Function Loss:  -2.0147\n",
      "################################  2110  ################################\n",
      "Total loss:  -1.5541 | PDE Loss:  -1.737 | Function Loss:  -2.0181\n",
      "################################  2111  ################################\n",
      "Total loss:  -1.5542 | PDE Loss:  -1.7391 | Function Loss:  -2.0143\n",
      "################################  2112  ################################\n",
      "Total loss:  -1.5543 | PDE Loss:  -1.7373 | Function Loss:  -2.018\n",
      "################################  2113  ################################\n",
      "Total loss:  -1.5544 | PDE Loss:  -1.7397 | Function Loss:  -2.0135\n",
      "################################  2114  ################################\n",
      "Total loss:  -1.5544 | PDE Loss:  -1.7375 | Function Loss:  -2.0179\n",
      "################################  2115  ################################\n",
      "Total loss:  -1.5545 | PDE Loss:  -1.7403 | Function Loss:  -2.0128\n",
      "################################  2116  ################################\n",
      "Total loss:  -1.5546 | PDE Loss:  -1.7377 | Function Loss:  -2.018\n",
      "################################  2117  ################################\n",
      "Total loss:  -1.5548 | PDE Loss:  -1.7409 | Function Loss:  -2.0125\n",
      "################################  2118  ################################\n",
      "Total loss:  -1.555 | PDE Loss:  -1.738 | Function Loss:  -2.0186\n",
      "################################  2119  ################################\n",
      "Total loss:  -1.5552 | PDE Loss:  -1.7414 | Function Loss:  -2.0128\n",
      "################################  2120  ################################\n",
      "Total loss:  -1.5555 | PDE Loss:  -1.7383 | Function Loss:  -2.0196\n",
      "################################  2121  ################################\n",
      "Total loss:  -1.5559 | PDE Loss:  -1.7419 | Function Loss:  -2.0137\n",
      "################################  2122  ################################\n",
      "Total loss:  -1.5562 | PDE Loss:  -1.7387 | Function Loss:  -2.0208\n",
      "################################  2123  ################################\n",
      "Total loss:  -1.5566 | PDE Loss:  -1.7424 | Function Loss:  -2.0149\n",
      "################################  2124  ################################\n",
      "Total loss:  -1.5569 | PDE Loss:  -1.7392 | Function Loss:  -2.0218\n",
      "################################  2125  ################################\n",
      "Total loss:  -1.5571 | PDE Loss:  -1.7427 | Function Loss:  -2.0159\n",
      "################################  2126  ################################\n",
      "Total loss:  -1.5573 | PDE Loss:  -1.7399 | Function Loss:  -2.0218\n",
      "################################  2127  ################################\n",
      "Total loss:  -1.5573 | PDE Loss:  -1.743 | Function Loss:  -2.016\n",
      "################################  2128  ################################\n",
      "Total loss:  -1.5573 | PDE Loss:  -1.7405 | Function Loss:  -2.0204\n",
      "################################  2129  ################################\n",
      "Total loss:  -1.5571 | PDE Loss:  -1.7432 | Function Loss:  -2.015\n",
      "################################  2130  ################################\n",
      "Total loss:  -1.5569 | PDE Loss:  -1.7412 | Function Loss:  -2.0181\n",
      "################################  2131  ################################\n",
      "Total loss:  -1.5568 | PDE Loss:  -1.7434 | Function Loss:  -2.0137\n",
      "################################  2132  ################################\n",
      "Total loss:  -1.5568 | PDE Loss:  -1.7419 | Function Loss:  -2.0165\n",
      "################################  2133  ################################\n",
      "Total loss:  -1.557 | PDE Loss:  -1.7435 | Function Loss:  -2.014\n",
      "################################  2134  ################################\n",
      "Total loss:  -1.5574 | PDE Loss:  -1.7425 | Function Loss:  -2.0171\n",
      "################################  2135  ################################\n",
      "Total loss:  -1.558 | PDE Loss:  -1.7438 | Function Loss:  -2.0163\n",
      "################################  2136  ################################\n",
      "Total loss:  -1.5587 | PDE Loss:  -1.743 | Function Loss:  -2.0198\n",
      "################################  2137  ################################\n",
      "Total loss:  -1.5593 | PDE Loss:  -1.7443 | Function Loss:  -2.0192\n",
      "################################  2138  ################################\n",
      "Total loss:  -1.5598 | PDE Loss:  -1.7434 | Function Loss:  -2.0223\n",
      "################################  2139  ################################\n",
      "Total loss:  -1.5601 | PDE Loss:  -1.7448 | Function Loss:  -2.0204\n",
      "################################  2140  ################################\n",
      "Total loss:  -1.5602 | PDE Loss:  -1.7436 | Function Loss:  -2.023\n",
      "################################  2141  ################################\n",
      "Total loss:  -1.56 | PDE Loss:  -1.7455 | Function Loss:  -2.0188\n",
      "################################  2142  ################################\n",
      "Total loss:  -1.5597 | PDE Loss:  -1.7437 | Function Loss:  -2.0213\n",
      "################################  2143  ################################\n",
      "Total loss:  -1.5592 | PDE Loss:  -1.7463 | Function Loss:  -2.0152\n",
      "################################  2144  ################################\n",
      "Total loss:  -1.5588 | PDE Loss:  -1.7438 | Function Loss:  -2.0188\n",
      "################################  2145  ################################\n",
      "Total loss:  -1.5587 | PDE Loss:  -1.747 | Function Loss:  -2.0123\n",
      "################################  2146  ################################\n",
      "Total loss:  -1.5588 | PDE Loss:  -1.744 | Function Loss:  -2.0183\n",
      "################################  2147  ################################\n",
      "Total loss:  -1.5592 | PDE Loss:  -1.7476 | Function Loss:  -2.0128\n",
      "################################  2148  ################################\n",
      "Total loss:  -1.5599 | PDE Loss:  -1.7443 | Function Loss:  -2.0209\n",
      "################################  2149  ################################\n",
      "Total loss:  -1.5608 | PDE Loss:  -1.748 | Function Loss:  -2.0163\n",
      "################################  2150  ################################\n",
      "Total loss:  -1.5616 | PDE Loss:  -1.7449 | Function Loss:  -2.0245\n",
      "################################  2151  ################################\n",
      "Total loss:  -1.5622 | PDE Loss:  -1.7484 | Function Loss:  -2.0199\n",
      "################################  2152  ################################\n",
      "Total loss:  -1.5626 | PDE Loss:  -1.7456 | Function Loss:  -2.0264\n",
      "################################  2153  ################################\n",
      "Total loss:  -1.5627 | PDE Loss:  -1.7486 | Function Loss:  -2.0208\n",
      "################################  2154  ################################\n",
      "Total loss:  -1.5625 | PDE Loss:  -1.7462 | Function Loss:  -2.0248\n",
      "################################  2155  ################################\n",
      "Total loss:  -1.5621 | PDE Loss:  -1.7489 | Function Loss:  -2.0185\n",
      "################################  2156  ################################\n",
      "Total loss:  -1.5615 | PDE Loss:  -1.7469 | Function Loss:  -2.0207\n",
      "################################  2157  ################################\n",
      "Total loss:  -1.5611 | PDE Loss:  -1.7492 | Function Loss:  -2.0151\n",
      "################################  2158  ################################\n",
      "Total loss:  -1.5608 | PDE Loss:  -1.7474 | Function Loss:  -2.0177\n",
      "################################  2159  ################################\n",
      "Total loss:  -1.561 | PDE Loss:  -1.7494 | Function Loss:  -2.0145\n",
      "################################  2160  ################################\n",
      "Total loss:  -1.5616 | PDE Loss:  -1.748 | Function Loss:  -2.0188\n",
      "################################  2161  ################################\n",
      "Total loss:  -1.5624 | PDE Loss:  -1.7498 | Function Loss:  -2.0177\n",
      "################################  2162  ################################\n",
      "Total loss:  -1.5633 | PDE Loss:  -1.7484 | Function Loss:  -2.0228\n",
      "################################  2163  ################################\n",
      "Total loss:  -1.564 | PDE Loss:  -1.7503 | Function Loss:  -2.0215\n",
      "################################  2164  ################################\n",
      "Total loss:  -1.5646 | PDE Loss:  -1.7487 | Function Loss:  -2.0259\n",
      "################################  2165  ################################\n",
      "Total loss:  -1.5648 | PDE Loss:  -1.7509 | Function Loss:  -2.0225\n",
      "################################  2166  ################################\n",
      "Total loss:  -1.5647 | PDE Loss:  -1.749 | Function Loss:  -2.0259\n",
      "################################  2167  ################################\n",
      "Total loss:  -1.5643 | PDE Loss:  -1.7515 | Function Loss:  -2.0201\n",
      "################################  2168  ################################\n",
      "Total loss:  -1.5639 | PDE Loss:  -1.7491 | Function Loss:  -2.0233\n",
      "################################  2169  ################################\n",
      "Total loss:  -1.5634 | PDE Loss:  -1.7522 | Function Loss:  -2.0162\n",
      "################################  2170  ################################\n",
      "Total loss:  -1.5632 | PDE Loss:  -1.7494 | Function Loss:  -2.0208\n",
      "################################  2171  ################################\n",
      "Total loss:  -1.5633 | PDE Loss:  -1.7528 | Function Loss:  -2.0147\n",
      "################################  2172  ################################\n",
      "Total loss:  -1.5637 | PDE Loss:  -1.7498 | Function Loss:  -2.0215\n",
      "################################  2173  ################################\n",
      "Total loss:  -1.5643 | PDE Loss:  -1.7532 | Function Loss:  -2.017\n",
      "################################  2174  ################################\n",
      "Total loss:  -1.5651 | PDE Loss:  -1.7503 | Function Loss:  -2.0246\n",
      "################################  2175  ################################\n",
      "Total loss:  -1.5659 | PDE Loss:  -1.7536 | Function Loss:  -2.0207\n",
      "################################  2176  ################################\n",
      "Total loss:  -1.5664 | PDE Loss:  -1.751 | Function Loss:  -2.0271\n",
      "################################  2177  ################################\n",
      "Total loss:  -1.5667 | PDE Loss:  -1.7539 | Function Loss:  -2.0225\n",
      "################################  2178  ################################\n",
      "Total loss:  -1.5667 | PDE Loss:  -1.7516 | Function Loss:  -2.0268\n",
      "################################  2179  ################################\n",
      "Total loss:  -1.5665 | PDE Loss:  -1.7542 | Function Loss:  -2.0214\n",
      "################################  2180  ################################\n",
      "Total loss:  -1.5662 | PDE Loss:  -1.7522 | Function Loss:  -2.0242\n",
      "################################  2181  ################################\n",
      "Total loss:  -1.5658 | PDE Loss:  -1.7545 | Function Loss:  -2.0189\n",
      "################################  2182  ################################\n",
      "Total loss:  -1.5656 | PDE Loss:  -1.7527 | Function Loss:  -2.0216\n",
      "################################  2183  ################################\n",
      "Total loss:  -1.5657 | PDE Loss:  -1.7549 | Function Loss:  -2.0177\n",
      "################################  2184  ################################\n",
      "Total loss:  -1.566 | PDE Loss:  -1.7532 | Function Loss:  -2.0218\n",
      "################################  2185  ################################\n",
      "Total loss:  -1.5665 | PDE Loss:  -1.7553 | Function Loss:  -2.0193\n",
      "################################  2186  ################################\n",
      "Total loss:  -1.5672 | PDE Loss:  -1.7536 | Function Loss:  -2.0244\n",
      "################################  2187  ################################\n",
      "Total loss:  -1.5678 | PDE Loss:  -1.7559 | Function Loss:  -2.0219\n",
      "################################  2188  ################################\n",
      "Total loss:  -1.5683 | PDE Loss:  -1.7539 | Function Loss:  -2.0269\n",
      "################################  2189  ################################\n",
      "Total loss:  -1.5685 | PDE Loss:  -1.7564 | Function Loss:  -2.023\n",
      "################################  2190  ################################\n",
      "Total loss:  -1.5686 | PDE Loss:  -1.7542 | Function Loss:  -2.0273\n",
      "################################  2191  ################################\n",
      "Total loss:  -1.5685 | PDE Loss:  -1.757 | Function Loss:  -2.0217\n",
      "################################  2192  ################################\n",
      "Total loss:  -1.5683 | PDE Loss:  -1.7544 | Function Loss:  -2.0259\n",
      "################################  2193  ################################\n",
      "Total loss:  -1.5681 | PDE Loss:  -1.7576 | Function Loss:  -2.0195\n",
      "################################  2194  ################################\n",
      "Total loss:  -1.568 | PDE Loss:  -1.7548 | Function Loss:  -2.0245\n",
      "################################  2195  ################################\n",
      "Total loss:  -1.5681 | PDE Loss:  -1.7581 | Function Loss:  -2.0185\n",
      "################################  2196  ################################\n",
      "Total loss:  -1.5684 | PDE Loss:  -1.7552 | Function Loss:  -2.0248\n",
      "################################  2197  ################################\n",
      "Total loss:  -1.5688 | PDE Loss:  -1.7586 | Function Loss:  -2.0199\n",
      "################################  2198  ################################\n",
      "Total loss:  -1.5694 | PDE Loss:  -1.7558 | Function Loss:  -2.0266\n",
      "################################  2199  ################################\n",
      "Total loss:  -1.5699 | PDE Loss:  -1.759 | Function Loss:  -2.0222\n",
      "################################  2200  ################################\n",
      "Total loss:  -1.5703 | PDE Loss:  -1.7564 | Function Loss:  -2.0281\n",
      "################################  2201  ################################\n",
      "Total loss:  -1.5706 | PDE Loss:  -1.7593 | Function Loss:  -2.0235\n",
      "################################  2202  ################################\n",
      "Total loss:  -1.5706 | PDE Loss:  -1.757 | Function Loss:  -2.0279\n",
      "################################  2203  ################################\n",
      "Total loss:  -1.5706 | PDE Loss:  -1.7596 | Function Loss:  -2.0229\n",
      "################################  2204  ################################\n",
      "Total loss:  -1.5705 | PDE Loss:  -1.7576 | Function Loss:  -2.0263\n",
      "################################  2205  ################################\n",
      "Total loss:  -1.5703 | PDE Loss:  -1.76 | Function Loss:  -2.0216\n",
      "################################  2206  ################################\n",
      "Total loss:  -1.5703 | PDE Loss:  -1.7581 | Function Loss:  -2.025\n",
      "################################  2207  ################################\n",
      "Total loss:  -1.5704 | PDE Loss:  -1.7604 | Function Loss:  -2.0211\n",
      "################################  2208  ################################\n",
      "Total loss:  -1.5707 | PDE Loss:  -1.7586 | Function Loss:  -2.0252\n",
      "################################  2209  ################################\n",
      "Total loss:  -1.5711 | PDE Loss:  -1.7608 | Function Loss:  -2.0222\n",
      "################################  2210  ################################\n",
      "Total loss:  -1.5716 | PDE Loss:  -1.759 | Function Loss:  -2.0269\n",
      "################################  2211  ################################\n",
      "Total loss:  -1.572 | PDE Loss:  -1.7613 | Function Loss:  -2.0238\n",
      "################################  2212  ################################\n",
      "Total loss:  -1.5723 | PDE Loss:  -1.7593 | Function Loss:  -2.0284\n",
      "################################  2213  ################################\n",
      "Total loss:  -1.5726 | PDE Loss:  -1.7619 | Function Loss:  -2.0243\n",
      "################################  2214  ################################\n",
      "Total loss:  -1.5726 | PDE Loss:  -1.7596 | Function Loss:  -2.0287\n",
      "################################  2215  ################################\n",
      "Total loss:  -1.5726 | PDE Loss:  -1.7625 | Function Loss:  -2.0234\n",
      "################################  2216  ################################\n",
      "Total loss:  -1.5725 | PDE Loss:  -1.7599 | Function Loss:  -2.0279\n",
      "################################  2217  ################################\n",
      "Total loss:  -1.5725 | PDE Loss:  -1.7631 | Function Loss:  -2.0219\n",
      "################################  2218  ################################\n",
      "Total loss:  -1.5725 | PDE Loss:  -1.7602 | Function Loss:  -2.0272\n",
      "################################  2219  ################################\n",
      "Total loss:  -1.5726 | PDE Loss:  -1.7636 | Function Loss:  -2.0214\n",
      "################################  2220  ################################\n",
      "Total loss:  -1.5729 | PDE Loss:  -1.7607 | Function Loss:  -2.0277\n",
      "################################  2221  ################################\n",
      "Total loss:  -1.5733 | PDE Loss:  -1.7641 | Function Loss:  -2.0225\n",
      "################################  2222  ################################\n",
      "Total loss:  -1.5738 | PDE Loss:  -1.7612 | Function Loss:  -2.0291\n",
      "################################  2223  ################################\n",
      "Total loss:  -1.5742 | PDE Loss:  -1.7645 | Function Loss:  -2.0242\n",
      "################################  2224  ################################\n",
      "Total loss:  -1.5746 | PDE Loss:  -1.7618 | Function Loss:  -2.0303\n",
      "################################  2225  ################################\n",
      "Total loss:  -1.5748 | PDE Loss:  -1.7649 | Function Loss:  -2.0252\n",
      "################################  2226  ################################\n",
      "Total loss:  -1.5749 | PDE Loss:  -1.7624 | Function Loss:  -2.0301\n",
      "################################  2227  ################################\n",
      "Total loss:  -1.5749 | PDE Loss:  -1.7652 | Function Loss:  -2.0249\n",
      "################################  2228  ################################\n",
      "Total loss:  -1.5748 | PDE Loss:  -1.763 | Function Loss:  -2.0288\n",
      "################################  2229  ################################\n",
      "Total loss:  -1.5748 | PDE Loss:  -1.7656 | Function Loss:  -2.0238\n",
      "################################  2230  ################################\n",
      "Total loss:  -1.5748 | PDE Loss:  -1.7635 | Function Loss:  -2.0275\n",
      "################################  2231  ################################\n",
      "Total loss:  -1.5749 | PDE Loss:  -1.7659 | Function Loss:  -2.0235\n",
      "################################  2232  ################################\n",
      "Total loss:  -1.5751 | PDE Loss:  -1.7641 | Function Loss:  -2.0276\n",
      "################################  2233  ################################\n",
      "Total loss:  -1.5755 | PDE Loss:  -1.7663 | Function Loss:  -2.0245\n",
      "################################  2234  ################################\n",
      "Total loss:  -1.5759 | PDE Loss:  -1.7646 | Function Loss:  -2.029\n",
      "################################  2235  ################################\n",
      "Total loss:  -1.5763 | PDE Loss:  -1.7668 | Function Loss:  -2.0261\n",
      "################################  2236  ################################\n",
      "Total loss:  -1.5767 | PDE Loss:  -1.765 | Function Loss:  -2.0304\n",
      "################################  2237  ################################\n",
      "Total loss:  -1.577 | PDE Loss:  -1.7673 | Function Loss:  -2.0268\n",
      "################################  2238  ################################\n",
      "Total loss:  -1.5771 | PDE Loss:  -1.7653 | Function Loss:  -2.0309\n",
      "################################  2239  ################################\n",
      "Total loss:  -1.5771 | PDE Loss:  -1.7679 | Function Loss:  -2.0262\n",
      "################################  2240  ################################\n",
      "Total loss:  -1.5771 | PDE Loss:  -1.7656 | Function Loss:  -2.0303\n",
      "################################  2241  ################################\n",
      "Total loss:  -1.577 | PDE Loss:  -1.7686 | Function Loss:  -2.0247\n",
      "################################  2242  ################################\n",
      "Total loss:  -1.577 | PDE Loss:  -1.7659 | Function Loss:  -2.0295\n",
      "################################  2243  ################################\n",
      "Total loss:  -1.577 | PDE Loss:  -1.7692 | Function Loss:  -2.0237\n",
      "################################  2244  ################################\n",
      "Total loss:  -1.5772 | PDE Loss:  -1.7662 | Function Loss:  -2.0296\n",
      "################################  2245  ################################\n",
      "Total loss:  -1.5776 | PDE Loss:  -1.7697 | Function Loss:  -2.0242\n",
      "################################  2246  ################################\n",
      "Total loss:  -1.578 | PDE Loss:  -1.7667 | Function Loss:  -2.031\n",
      "################################  2247  ################################\n",
      "Total loss:  -1.5784 | PDE Loss:  -1.7702 | Function Loss:  -2.0257\n",
      "################################  2248  ################################\n",
      "Total loss:  -1.5789 | PDE Loss:  -1.7672 | Function Loss:  -2.0325\n",
      "################################  2249  ################################\n",
      "Total loss:  -1.5792 | PDE Loss:  -1.7707 | Function Loss:  -2.0272\n",
      "################################  2250  ################################\n",
      "Total loss:  -1.5795 | PDE Loss:  -1.7677 | Function Loss:  -2.0332\n",
      "################################  2251  ################################\n",
      "Total loss:  -1.5796 | PDE Loss:  -1.771 | Function Loss:  -2.0275\n",
      "################################  2252  ################################\n",
      "Total loss:  -1.5796 | PDE Loss:  -1.7683 | Function Loss:  -2.0325\n",
      "################################  2253  ################################\n",
      "Total loss:  -1.5795 | PDE Loss:  -1.7714 | Function Loss:  -2.0267\n",
      "################################  2254  ################################\n",
      "Total loss:  -1.5795 | PDE Loss:  -1.769 | Function Loss:  -2.0309\n",
      "################################  2255  ################################\n",
      "Total loss:  -1.5794 | PDE Loss:  -1.7717 | Function Loss:  -2.0258\n",
      "################################  2256  ################################\n",
      "Total loss:  -1.5795 | PDE Loss:  -1.7696 | Function Loss:  -2.0298\n",
      "################################  2257  ################################\n",
      "Total loss:  -1.5797 | PDE Loss:  -1.7721 | Function Loss:  -2.0259\n",
      "################################  2258  ################################\n",
      "Total loss:  -1.58 | PDE Loss:  -1.7702 | Function Loss:  -2.0301\n",
      "################################  2259  ################################\n",
      "Total loss:  -1.5804 | PDE Loss:  -1.7724 | Function Loss:  -2.0273\n",
      "################################  2260  ################################\n",
      "Total loss:  -1.5808 | PDE Loss:  -1.7708 | Function Loss:  -2.0316\n",
      "################################  2261  ################################\n",
      "Total loss:  -1.5813 | PDE Loss:  -1.7729 | Function Loss:  -2.029\n",
      "################################  2262  ################################\n",
      "Total loss:  -1.5816 | PDE Loss:  -1.7712 | Function Loss:  -2.0329\n",
      "################################  2263  ################################\n",
      "Total loss:  -1.5819 | PDE Loss:  -1.7734 | Function Loss:  -2.0297\n",
      "################################  2264  ################################\n"
     ]
    }
   ],
   "source": [
    "n_epochs_A = 50000\n",
    "n_epochs_L = 2 \n",
    "\n",
    "hist_A = pinn.fit(num_epochs=n_epochs_A,\n",
    "                optimizer=optimizer_ADAM,\n",
    "                verbose=True)\n",
    "hist_L = pinn.fit(num_epochs=n_epochs_L,\n",
    "                optimizer=optimizer_LBFGS,\n",
    "                verbose=True)\n",
    "\n",
    "hist= [*hist_A, *hist_L]\n",
    "\n",
    "hist  = pinn.fit(num_epochs=n_epochs,\n",
    "                optimizer=optimizer_ADAM,\n",
    "                verbose=True)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HG9DQM5fQxN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pinn.plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJ3yDeqTOmKx"
   },
   "outputs": [],
   "source": [
    "\n",
    "output_data= pinn.approximate_solution(input_meas)\n",
    "output_Ts= output_data[:,1].view(-1,1)\n",
    "Task_II= torch.cat([input_meas,output_Ts],1)\n",
    "t_np = Task_II.to('cpu').detach().numpy() #convert to Numpy array\n",
    "df = pd.DataFrame(t_np) #convert to a dataframe\n",
    "df.columns = ['t','x','ts']\n",
    "df.to_csv(f'Data_Task_2_Regularizer_{Lambda}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{pinn.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.txt',index=False) #save to file\n",
    "files.download(f'Data_Task_2_Regularizer_{Lambda}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{pinn.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wDSkgxEDyD3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
