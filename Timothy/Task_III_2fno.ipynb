{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "WxBh0Qr54yYv",
   "metadata": {
    "executionInfo": {
     "elapsed": 4209,
     "status": "ok",
     "timestamp": 1686494578823,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "WxBh0Qr54yYv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim import LBFGS\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fad8e27-7326-4466-96c9-2a499af7766d",
   "metadata": {
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1686494594538,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "6fad8e27-7326-4466-96c9-2a499af7766d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def activation(name):\n",
    "    if name in ['tanh', 'Tanh']:\n",
    "        return nn.Tanh()\n",
    "    elif name in ['relu', 'ReLU']:\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif name in ['lrelu', 'LReLU']:\n",
    "        return nn.LeakyReLU(inplace=True)\n",
    "    elif name in ['sigmoid', 'Sigmoid']:\n",
    "        return nn.Sigmoid()\n",
    "    elif name in ['softplus', 'Softplus']:\n",
    "        return nn.Softplus(beta=4)\n",
    "    elif name in ['celu', 'CeLU']:\n",
    "        return nn.CELU()\n",
    "    elif name in ['elu']:\n",
    "        return nn.ELU()\n",
    "    elif name in ['mish']:\n",
    "        return nn.Mish()\n",
    "    else:\n",
    "        raise ValueError('Unknown activation function')\n",
    "\n",
    "################################################################\n",
    "#  1d fourier layer\n",
    "################################################################\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, input, weights):\n",
    "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == [batch_size, in_channels, number of grid points]\n",
    "        d = x.shape[2]\n",
    "        # Compute Fourier coefficients\n",
    "        x = torch.fft.rfft(x,dim=2)\n",
    "        # Multiply Fourier modes\n",
    "        x = self.compl_mul1d(x, self.weights1)\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft(x, n=d)\n",
    "        return x\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "class FNO1d(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(FNO1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        input: the solution of the initial condition and location (a(x), x)\n",
    "        input shape: (batchsize, x=s, c=2)\n",
    "        output: the solution of a later timestep\n",
    "        output shape: (batchsize, x=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes\n",
    "        self.width = width\n",
    "        self.padding = 1  # pad the domain if input is non-periodic\n",
    "        self.linear_p = nn.Linear(3, self.width)  # input channel is 2: (u0(x), x)\n",
    "\n",
    "        self.spect1 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.spect2 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.spect3 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.lin0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.lin1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.lin2 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "        self.linear_q = nn.Linear(self.width, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def fourier_layer(self, x, spectral_layer, conv_layer):\n",
    "       # return self.activation(spectral_layer(x))\n",
    "        return self.activation(spectral_layer(x) + conv_layer(x))\n",
    "        \n",
    "                       \n",
    "    def linear_layer(self, x, linear_transformation):\n",
    "        return self.activation(linear_transformation(x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # grid = self.get_grid(x.shape, x.device)\n",
    "        # x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.linear_p(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # x = F.pad(x, [0, self.padding])  # pad the domain if input is non-periodic\n",
    "\n",
    "        x = self.fourier_layer(x, self.spect1, self.lin0)\n",
    "        x = self.fourier_layer(x, self.spect2, self.lin1)\n",
    "        x = self.fourier_layer(x, self.spect3, self.lin2)\n",
    "\n",
    "        # x = x[..., :-self.padding]  # pad the domain if input is non-periodic\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self.linear_layer(x, self.linear_q)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f29c548-7606-4dfb-92bc-1756d6c2c996",
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1686495651357,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "7f29c548-7606-4dfb-92bc-1756d6c2c996",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetTask3(TensorDataset):\n",
    "    # https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "    # devide data into 5 input/outpus pairs, for cycle prediction\n",
    "    def __init__(self, tensor_data, window_len):\n",
    "        self.tensor_data = tensor_data\n",
    "        self.window_len = window_len    # size of input/output sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        # gives number of input and output pairs. In our case it is 5.\n",
    "        return int(len(self.tensor_data)/self.window_len) - 1\n",
    "        # return (len(self.data) // self.seq_length) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx is index of individual input-output pair\n",
    "        lower_end = idx*self.window_len\n",
    "        upper_end = (idx + 1)*self.window_len\n",
    "        inputs = self.tensor_data[lower_end:upper_end]\n",
    "        outputs = self.tensor_data[upper_end:upper_end+self.window_len,1:]\n",
    "        \n",
    "        return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95b1d3f3-7ce0-4d8f-a19e-937515ee93fe",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1686495651651,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "95b1d3f3-7ce0-4d8f-a19e-937515ee93fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\" mins and maxs for backconversion in lists\"\"\"\n",
    "    t= x[:,0]; Tf= x[:,1] ; Ts = x[:,2]\n",
    "    \n",
    "    max_t , max_Tf, max_Ts = t.max(), Tf.max(), Ts.max()\n",
    "    min_t , min_Tf, min_Ts = t.min(), Tf.min(), Ts.min()\n",
    "    \n",
    "    normalized_data = torch.zeros_like(x)\n",
    "    normalized_data[:, 0] = (t - min_t)/(max_t - min_t)\n",
    "    normalized_data[:, 1] = (Tf - min_Tf)/(max_Tf - min_Tf)\n",
    "    normalized_data[:, 2] = (Ts - min_Ts)/(max_Ts - min_Ts)\n",
    "\n",
    "    return normalized_data, [min_t , min_Tf, min_Ts], [max_t , max_Tf, max_Ts]\n",
    "\n",
    "def denormalize(x, min, max):\n",
    "    data = torch.zeros_like(x)\n",
    "    for i in range(len(min)):\n",
    "        data[:,i]= x[:,i]*(max[i]- min[i])+ min[i]\n",
    "    return data\n",
    "\n",
    "def regularization(model, order):\n",
    "    reg_loss = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            reg_loss = reg_loss + torch.norm(param, order)\n",
    "    return reg_loss\n",
    "\n",
    "def fit_(fno_f, fno_s,epochs, optimizer, training_set, regularization_p):  \n",
    "        history = list()\n",
    "        l = torch.nn.MSELoss()\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            train_mse = 0.0\n",
    "            for step, (input_batch, output_batch) in enumerate(training_set):\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    output_pred_batch = torch.cat([fno_f(input_batch),fno_s(input_batch)],dim=2).squeeze(2)\n",
    "                    loss = l(output_pred_batch, output_batch) # + regularization_p *regularization(fno, 2)\n",
    "                    loss.backward()\n",
    "                    history.append(loss.item())\n",
    "                    return loss\n",
    "  \n",
    "                optimizer.step(closure=closure)\n",
    "                train_mse += history[-1] #loss.item() \n",
    "                \n",
    "            train_mse /= len(training_set)\n",
    "        \n",
    "            scheduler.step()\n",
    "        \n",
    "            if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse)\n",
    "        Final_loss = round(history[-1],4)\n",
    "        print('Final Loss: ', history[-1])\n",
    "        return history\n",
    "  \n",
    "def fit(fno_f, fno_s,epochs, optimizer, training_set):  \n",
    "       # history = list()\n",
    "        l = torch.nn.MSELoss()\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            train_mse = 0.0\n",
    "            for step, (input_batch, output_batch) in enumerate(training_set):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output_pred_batch = torch.cat([fno_f(input_batch),fno_s(input_batch)],dim=2).squeeze(2)\n",
    "                loss = l(output_pred_batch, output_batch) \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #history_f.append(loss_f.item())\n",
    "                train_mse += loss.item()\n",
    "                \n",
    "            train_mse /= len(training_set)\n",
    "            scheduler.step()\n",
    "        \n",
    "            if epoch % freq_print == 0: print(\"######### Epoch:\", epoch, \" ######### Train Loss:\", train_mse)\n",
    "        #Final_loss = round(history[-1],4)\n",
    "        #print('Final Loss: ', history[-1])\n",
    "        #return history\n",
    "\n",
    "def plot_hist(hist):\n",
    "    plt.figure()\n",
    "    plt.grid(True, which=\"both\", ls=\":\")\n",
    "    plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0869ae-d86a-41e4-9292-746eef8bcaef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "error",
     "timestamp": 1686495749988,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "0d0869ae-d86a-41e4-9292-746eef8bcaef",
    "outputId": "bbd2534f-0a7f-4701-cffd-f9988a75ab59",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Epoch: 0  ######### Train Loss: 0.30213421434164045\n",
      "######### Epoch: 50  ######### Train Loss: 4.129579946265949e-06\n",
      "######### Epoch: 100  ######### Train Loss: 1.6255502629292095e-06\n",
      "######### Epoch: 150  ######### Train Loss: 1.0331160581245057e-06\n",
      "######### Epoch: 200  ######### Train Loss: 8.132235592483994e-07\n",
      "######### Epoch: 250  ######### Train Loss: 7.132041346835649e-07\n",
      "######### Epoch: 300  ######### Train Loss: 6.628114604723123e-07\n",
      "######### Epoch: 350  ######### Train Loss: 6.3600259636587e-07\n",
      "######### Epoch: 400  ######### Train Loss: 6.213870818783107e-07\n",
      "######### Epoch: 450  ######### Train Loss: 6.133409570452386e-07\n",
      "######### Epoch: 500  ######### Train Loss: 6.088402273007887e-07\n",
      "######### Epoch: 550  ######### Train Loss: 6.063799304456552e-07\n",
      "######### Epoch: 600  ######### Train Loss: 6.05030818690011e-07\n",
      "######### Epoch: 650  ######### Train Loss: 6.043046923309702e-07\n",
      "######### Epoch: 700  ######### Train Loss: 6.039092525611523e-07\n",
      "######### Epoch: 750  ######### Train Loss: 6.037434189920532e-07\n",
      "######### Epoch: 800  ######### Train Loss: 6.036473195081271e-07\n",
      "######### Epoch: 850  ######### Train Loss: 6.036066494630177e-07\n",
      "######### Epoch: 900  ######### Train Loss: 6.035921217062423e-07\n",
      "######### Epoch: 950  ######### Train Loss: 6.0359558062828e-07\n",
      "######### Epoch: 1000  ######### Train Loss: 6.035893875377952e-07\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('TrainingData.txt')\n",
    "train_data = torch.tensor(df[['t','tf0', 'ts0']].values, dtype=torch.float)\n",
    "train_data, mins, maxs = normalize(train_data)\n",
    "\n",
    "window_len = 35\n",
    "batch_size = 1\n",
    "dataset = DatasetTask3(train_data, window_len)\n",
    "training_set= torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=False)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 1500\n",
    "freq_print = 50\n",
    "modes = 18  # we do not truncate the fourier series, rDFT of vec 35 has length 18\n",
    "width = 256 \n",
    "\n",
    "fno_f = FNO1d(modes, width)\n",
    "fno_s = FNO1d(modes, width)\n",
    "\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "optimizer_Adam = Adam(list(fno_f.parameters()) + list(fno_s.parameters()) , lr=learning_rate, weight_decay= 0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_Adam, step_size=step_size, gamma=gamma)\n",
    "\n",
    "fit(fno_f, fno_s, epochs,optimizer_Adam, training_set) # LBFGS does not support complex valued computations\n",
    "#plot_hist(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc4870-391f-4939-8849-c84883b035fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1686494407369,
     "user": {
      "displayName": "timeo jazz",
      "userId": "05184510240855220717"
     },
     "user_tz": -120
    },
    "id": "3fcc4870-391f-4939-8849-c84883b035fc",
    "outputId": "c465268b-8e93-4c1a-e901-ccdbc80a54c5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = train_data[-window_len:,:].reshape(1,window_len,3)\n",
    "output = torch.cat([fno_f(test_set), fno_s(test_set)],dim=2).squeeze()\n",
    "\n",
    "input_meas = denormalize(train_data, mins, maxs)\n",
    "output[:,0] = (maxs[1]-mins[1])* output[:,0] + mins[1]\n",
    "output[:,1] = (maxs[2]-mins[2])* output[:,1] + mins[2]\n",
    "\n",
    "# output[:,0] = (maxs[1] - mins[1])*output[:,0] + mins[1]\n",
    "# output[:,1] = (maxs[2] - mins[1])*output[:,1] + mins[1]\n",
    "\n",
    "\n",
    "df = pd.read_csv('TestingData.txt')\n",
    "test_time_np = df['t'].to_numpy()\n",
    "test_time = torch.tensor(df['t'].values, dtype=torch.float)\n",
    "\n",
    "total_time = torch.cat([input_meas[:,0], test_time], 0)\n",
    "total_pred = torch.cat([input_meas[:,1:], output[:-1]], 0)\n",
    "\n",
    "print(total_pred[-window_len:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(input_meas[2:,0].detach(), input_meas[2:,1].detach(),label='meas Tf')\n",
    "plt.plot(input_meas[2:,0].detach(), input_meas[2:,2].detach(),label='meas Ts')\n",
    "plt.plot(total_time[-window_len:].detach(), total_pred[-window_len:,0].detach(), label = 'pred Tf',color='green')\n",
    "plt.plot(total_time[-window_len:].detach(), total_pred[-window_len:,1].detach(), label = 'pred Ts',color='red')\n",
    "plt.grid('True')\n",
    "plt.legend()\n",
    "plt.savefig(f'Data/task3_2fno_epochs_{epochs}_width_{width}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e9f626-0e82-4e6b-bb45-5896c25e30b1",
   "metadata": {
    "id": "d9e9f626-0e82-4e6b-bb45-5896c25e30b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'t': test_time_np, 'tf0': output[:-1,0].detach().numpy(), 'ts0': output[:-1,1].detach().numpy()})\n",
    "test_df.to_csv(f'Data/task3_2fno_epochs_{epochs}_width_{width}.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9a63c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deep_learning_env",
   "language": "python",
   "name": "deep_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
