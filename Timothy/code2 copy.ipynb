{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21900,"status":"ok","timestamp":1686840852224,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"n50ZuGOHY9Vn","outputId":"28e7b18c-48a2-495a-d642-f8891568154c"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5835,"status":"ok","timestamp":1686840875256,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"RxdKpwQRYSvB"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.optim as optim\n","import torch\n","from torch.utils.data import DataLoader\n","import sys\n","sys.path.append('/Users/timostroschein/Desktop/Deep Learning/DLSC')\n","from Common import NeuralNet, MultiVariatePoly\n","# from drive.MyDrive.DLSC.Common import NeuralNet, MultiVariatePoly\n","import time\n","torch.autograd.set_detect_anomaly(True)\n","torch.manual_seed(128)\n","import pandas as pd\n","import math\n","\n","dev = 'cpu'  # cuda on colab\n","\n","device =torch.device(dev)\n","torch.set_default_device(dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":29230,"status":"ok","timestamp":1686840907822,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"9_5n3RRMblXK","outputId":"4c312ebc-fdb6-41e6-a74b-54f199cbf3d5"},"outputs":[],"source":["from google.colab import files\n","uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":813,"status":"ok","timestamp":1686840923166,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"aJUXlW4QXKP1"},"outputs":[],"source":["#read data\n","df = pd.read_csv('DataSolution.txt')\n","input_meas = torch.tensor(df[['t', 'x']].values, dtype=torch.float)\n","output_meas = torch.tensor(df[['tf']].values, dtype=torch.float)\n","\n","#set constants\n","alpha_f = 0.005; h_f =5; Thot = 4; T0 = 1;  Tcold =1\n","\n","#set hyperparams\n","Lambda = 100; Data_reg = 100; Hidden_layers=8; Neurons=100\n","\n","#Training optimizer\n","Adam_opt = True; n_epochs_A = 500\n","LBFGS_opt = False; n_epochs_L = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1686840925293,"user":{"displayName":"timeo jazz","userId":"05184510240855220717"},"user_tz":-120},"id":"iWjc7brmXKP1"},"outputs":[],"source":["\n","class Pinns:\n","    def __init__(self, n_int_, n_sb_, n_tb_):\n","        self.n_int = n_int_\n","        self.n_sb = n_sb_\n","        self.n_tb = n_tb_\n","\n","        self.Final_loss = None;\n","        # Extrema of the solution domain (t,x) in [0,0.1]x[-1,1]\n","        self.domain_extrema = torch.tensor([[0, 8],  # Time dimension\n","                                            [0, 1]])  # Space dimension\n","\n","        # Number of space dimensions\n","        self.space_dimensions = 1\n","\n","        # Parameter to balance role of data and PDE\n","        self.lambda_u = Lambda\n","        self.data_regu = Data_reg\n","\n","        # F Dense NN to approximate the solution of the underlying heat equation\n","        self.approximate_solution = NeuralNet(input_dimension=self.domain_extrema.shape[0], output_dimension=2,\n","                                              n_hidden_layers=Hidden_layers,\n","                                              neurons=Neurons,\n","                                              regularization_param=0.,\n","                                              regularization_exp=2.,\n","                                              retrain_seed=42)\n","\n","        # Generator of Sobol sequences\n","        self.soboleng = torch.quasirandom.SobolEngine(dimension=self.domain_extrema.shape[0])\n","\n","        # Training sets S_sb, S_tb, S_int as torch dataloader\n","        self.training_set_sb, self.training_set_tb, self.training_set_int = self.assemble_datasets()\n","\n","    ################################################################################################\n","    # Function to linearly transform a tensor whose value are between 0 and 1\n","    # to a tensor whose values are between the domain extrema\n","    def convert(self, tens):\n","        assert (tens.shape[1] == self.domain_extrema.shape[0])\n","        tens =tens.to(device)\n","        return tens * (self.domain_extrema[:, 1] - self.domain_extrema[:, 0]) + self.domain_extrema[:, 0]\n","\n","    # Initial condition\n","    def initial_condition(self, batch_size):\n","        return torch.full((batch_size,1), T0)\n","\n","\n","    ################################################################################################\n","    # Function returning the input-output tensor required to assemble the training set S_tb corresponding to the temporal boundary\n","    def add_temporal_boundary_points(self):\n","        t0 = self.domain_extrema[0, 0]\n","        input_tb = self.convert(self.soboleng.draw(self.n_tb))\n","        input_tb[:, 0] = torch.full(input_tb[:, 0].shape, t0)\n","        output_tb = self.initial_condition(self.n_tb)\n","\n","        return input_tb, output_tb\n","\n","    # Use boolean tensors to implement spatial boundary conditions\n","    def sb_0(self, time):\n","        # Returns ones for point in charging phase, else zero. \n","        t = (time % 4).detach().float()\n","        sb_0 = torch.where(torch.isclose(t, torch.tensor([0.], dtype=torch.float32, device=t.device), atol=1e-6), torch.tensor([False], dtype=torch.bool, device=t.device), t<1)  # exclude t=0 -> initial condition\n","        return sb_0.view(-1,1)\n","\n","    def sb_L(self,time):\n","        # Returns ones in discharging phase.\n","        t = ( time %4 ).detach().clone()\n","        sb_L =  (t<3) & (t>=2)\n","        return sb_L.view(-1,1)\n","\n","\n","    # Function returning the input-output tensor required to assemble the training set S_sb corresponding to the spatial boundary\n","    def add_spatial_boundary_points(self):\n","        x0 = self.domain_extrema[1, 0]\n","        xL = self.domain_extrema[1, 1]\n","\n","        input_sb = self.convert(self.soboleng.draw(self.n_sb).to(device))\n","\n","        input_sb_0 = torch.clone(input_sb)\n","        input_sb_0[:, 1] = torch.full(input_sb_0[:, 1].shape, x0)\n","\n","        input_sb_L = torch.clone(input_sb)\n","        input_sb_L[:, 1] = torch.full(input_sb_L[:, 1].shape, xL)\n","\n","\n","        output_sb_0 = Thot* self.sb_0(input_sb[:,0].view(-1,1)).detach()   # charging phase \n","        output_sb_L = Tcold* self.sb_L(input_sb[:,0].view(-1,1)).detach()  # discharging phase\n","\n","        return torch.cat([input_sb_0, input_sb_L], 0), torch.cat([output_sb_0, output_sb_L], 0)\n","\n","    #  Function returning the input-output tensor required to assemble the training set S_int corresponding to the interior domain where the PDE is enforced\n","    def add_interior_points(self):\n","        input_int = self.convert(self.soboleng.draw(self.n_int)).to(device)\n","        output_int = torch.zeros((input_int.shape[0], 1))\n","        return input_int, output_int\n","\n","    # Function returning the training sets S_sb, S_tb, S_int as dataloader\n","    def assemble_datasets(self):\n","        input_sb, output_sb = self.add_spatial_boundary_points()   # S_sb\n","        input_tb, output_tb = self.add_temporal_boundary_points()  # S_tb\n","        input_int, output_int = self.add_interior_points()         # S_int\n","\n","        training_set_sb = DataLoader(torch.utils.data.TensorDataset(input_sb, output_sb), batch_size=2*self.space_dimensions*self.n_sb, shuffle=False)\n","        training_set_tb = DataLoader(torch.utils.data.TensorDataset(input_tb, output_tb), batch_size=self.n_tb, shuffle=False)\n","        training_set_int = DataLoader(torch.utils.data.TensorDataset(input_int, output_int), batch_size=self.n_int, shuffle=False)\n","\n","        return training_set_sb, training_set_tb, training_set_int\n","\n","    ################################################################################################\n","    # Function to compute the terms required in the definition of the TEMPORAL boundary residual\n","    def apply_initial_condition(self, input_tb):\n","        u_pred_tb = self.approximate_solution(input_tb)[:,0]\n","        return u_pred_tb.view(-1,1)\n","\n","\n","    # Function to compute the terms required in the definition of the SPATIAL boundary residual\n","    def apply_boundary_conditions(self, input_sb):\n","        # idea: work with boolean tensors and entry wise multiplication\n","        assert(int(input_sb.shape[0]/2) == self.n_sb)\n","        input_sb.requires_grad = True\n","        l = self.n_sb\n","        \n","        NN_output = self.approximate_solution(input_sb)\n","        Tf_pred_sb = NN_output[:,0] \n","\n","        grad_Tf= torch.autograd.grad(Tf_pred_sb.sum(), input_sb, create_graph=True)[0]\n","        grad_Tf_x = grad_Tf[:, 1].view(-1,1)\n","\n","        # Boundary at x=0\n","        t_0 = input_sb[:l,0].view(-1,1)\n","        grad_Tf_x_0 = grad_Tf_x[:l].view(-1,1)\n","        Tf_0 = Tf_pred_sb[:l].view(-1,1)\n","        bool_0 = self.sb_0(t_0).detach().float()              # picks all points in charging phase, zero else\n","        boundary_0= bool_0 * Tf_0 + (1-bool_0 )*grad_Tf_x_0   # apply dirichlet or Neumann conditions according to input time\n","\n","        # Boundary at x=L\n","        t_L = input_sb[l:,0].view(-1,1)\n","        grad_Tf_x_L = grad_Tf_x[l:].view(-1,1)\n","        Tf_L = Tf_pred_sb[l:].view(-1,1)\n","        bool_L = self.sb_L(t_L).detach().float()              # picks out discharging phase\n","        boundary_L = bool_L * Tf_L + (1-bool_L )* grad_Tf_x_L # apply dirichlet or Neumann conditions according to input time and boundary\n","\n","        boundary_points = torch.cat([boundary_0.view(-1,1),boundary_L.view(-1,1)],0)\n","        return boundary_points\n","\n","    # Implement velocity of fluid in different phases with boolean tensor\n","    def U(self, t):\n","        t = (t % 4).float().detach()\n","        u = (t <= 1).float() + (t <= 2).float() - (t <= 3).float()\n","        return u.view(-1, 1)\n","\n","    # Function to compute the PDE residuals\n","    def compute_pde_residual(self, input_int):\n","        input_int.requires_grad = True\n","        NN_output= self.approximate_solution(input_int)\n","        Tf = NN_output[:,0]\n","        Ts = NN_output[:,1]\n","\n","        grad_Tf= torch.autograd.grad(Tf.sum(), input_int, create_graph=True)[0]\n","        grad_Tf_x = grad_Tf[:, 1].view(-1,1)\n","        grad_Tf_t = grad_Tf[:, 0].view(-1,1)\n","        grad_Tf_xx= torch.autograd.grad( grad_Tf_x.sum(),input_int, create_graph=True)[0][:, 1].view(-1,1).to(device)\n","\n","        Vel_f = self.U(input_int[:,0])\n","        residual = grad_Tf_t + Vel_f * grad_Tf_x - alpha_f * grad_Tf_xx + h_f * (Tf - Ts)     # element-wise usage of boolean velocity tensor for state dependent PDE residual\n","\n","        return residual.reshape(-1, )\n","\n","    # Function to compute the total loss (weighted sum of spatial boundary loss, temporal boundary loss and interior loss)\n","    def compute_loss(self, inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=True):\n","        u_pred_sb = self.apply_boundary_conditions(inp_train_sb)\n","        u_pred_tb = self.apply_initial_condition(inp_train_tb)\n","\n","        u_pred_meas = self.approximate_solution(input_meas)[:,0].view(-1,1)\n","\n","        assert (u_pred_sb.shape[1] == u_train_sb.shape[1])\n","        assert (u_pred_tb.shape[1] == u_train_tb.shape[1])\n","        assert (u_pred_meas.shape[1] == output_meas.shape[1])\n","\n","        r_int = self.compute_pde_residual(inp_train_int)\n","        r_sb = u_train_sb - u_pred_sb\n","        r_tb = u_train_tb - u_pred_tb\n","        r_meas = output_meas - u_pred_meas\n","\n","        loss_sb = torch.mean(abs(r_sb) ** 2)\n","        loss_tb = torch.mean(abs(r_tb) ** 2)\n","        loss_int = torch.mean(abs(r_int) ** 2)\n","        loss_meas = torch.mean(abs(r_meas) ** 2)       # additional loss term from measured data\n","\n","        loss_u = loss_sb + loss_tb\n","\n","        loss = torch.log10(self.lambda_u * loss_u  + loss_int + self.data_regu * loss_meas)\n","        if verbose: print(\"Total loss: \", round(loss.item(), 4), \"| PDE Loss: \", round(torch.log10(loss_int).item(), 4), \"| Function Loss: \", round(torch.log10(loss_u).item(),4),\"| Meas Loss: \", round(torch.log10(loss_meas).item(), 4))\n","\n","        return loss\n","\n","    ################################################################################################\n","    def fit(self, num_epochs, optimizer, verbose=True):\n","        history = list()\n","\n","        # Loop over epochs\n","        for epoch in range(num_epochs):\n","            if verbose: print(\"################################ \", epoch, \" ################################\")\n","\n","            for j, ((inp_train_sb, u_train_sb), (inp_train_tb, u_train_tb), (inp_train_int, u_train_int)) in enumerate(zip(self.training_set_sb, self.training_set_tb, self.training_set_int)):\n","                def closure():\n","                    optimizer.zero_grad()\n","                    loss = self.compute_loss(inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=verbose)\n","                    loss.backward()\n","\n","                    history.append(loss.item())\n","                    return loss\n","\n","                optimizer.step(closure=closure)\n","\n","        self.Final_loss = round(history[-1],4)\n","        print('Final Loss: ', history[-1])\n","\n","        return history\n","\n","    ################################################################################################\n","    def plotting(self):\n","\n","\n","        inputs = self.soboleng.draw(100000)\n","        inputs = self.convert(inputs)\n","\n","        output = self.approximate_solution(inputs)\n","        output= output.to(\"cpu\")\n","        inputs = inputs.to(\"cpu\")\n","\n","        Tf = output[:,0].reshape(-1, )\n","        Ts = output[:,1].reshape(-1, )\n","\n","        fig, axs = plt.subplots(1,2,figsize=(16, 8), dpi=150)\n","        im1 = axs[0].scatter(inputs[:, 0].detach(), inputs[:, 1].detach(), c=Tf.detach(), cmap=\"jet\")\n","        axs[0].set_xlabel(\"t\")\n","        axs[0].set_ylabel(\"x\")\n","        plt.colorbar(im1, ax=axs[0])\n","        axs[0].grid(True, which=\"both\", ls=\":\")\n","        axs[0].set_title(\"Approximate Tf solution \")\n","\n","        im2 = axs[1].scatter(inputs[:, 0].detach(), inputs[:, 1].detach(), c=Ts.detach(), cmap=\"jet\")\n","        axs[1].set_xlabel(\"t\")\n","        axs[1].set_ylabel(\"x\")\n","        plt.colorbar(im2, ax=axs[1])\n","        axs[1].grid(True, which=\"both\", ls=\":\")\n","        axs[1].set_title(\"Approximate Ts solution \")\n","\n","        # plt.savefig(f'Task_2_Regularizer_{Lambda}_DataReg_{Data_reg}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{self.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.jpg')\n","        # files.download(f'Task_2_Regularizer_{Lambda}_DataReg_{Data_reg}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{self.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.jpg')\n","        plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZ5QSzs3XKP3","outputId":"833eeb0d-9df1-4449-852f-6e48a7e447c9"},"outputs":[],"source":["\n","n_int = 256 * 16\n","n_sb = 64 * 4\n","n_tb = 32\n","\n","pinn = Pinns(n_int, n_sb, n_tb)\n","\n","\n","def plot_hist(hist):\n","    plt.figure(dpi=150)\n","    plt.grid(True, which=\"both\", ls=\":\")\n","    plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n","    plt.xscale(\"log\")\n","    plt.legend()\n","\n","\n","optimizer_LBFGS = optim.LBFGS(pinn.approximate_solution.parameters(),\n","                              lr=float(0.5),\n","                              max_iter=1000,\n","                              max_eval=50000,\n","                              history_size=150,\n","                              line_search_fn=\"strong_wolfe\",\n","                              tolerance_change=1.0 * np.finfo(float).eps)\n","optimizer_ADAM = optim.Adam(pinn.approximate_solution.parameters(),\n","                            lr=float(0.001))\n","\n","\n","if Adam_opt:\n","\n","    hist_A = pinn.fit(num_epochs=n_epochs_A,\n","                    optimizer=optimizer_ADAM,\n","                    verbose=True)\n","    plot_hist(hist_A)\n","\n","if LBFGS_opt:\n","    hist_L = pinn.fit(num_epochs=n_epochs_L,\n","                    optimizer=optimizer_LBFGS,\n","                    verbose=True)\n","\n","    plot_hist(hist_L)\n","\n","pinn.plotting()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cK5HoS_Jcu4_"},"outputs":[],"source":["\n","df = pd.read_csv('DataSolution.txt')\n","testing_points = torch.tensor(df[['t', 'x']].values, dtype=torch.float)\n","\n","output_data= pinn.approximate_solution(testing_points).to('cpu')\n","\n","output_f_np = output_data[:,0].to('cpu').detach().numpy()\n","output_s_np = output_data[:,1].to('cpu').detach().numpy()\n","\n","test_df = pd.DataFrame({'t': testing_points[:,0].to('cpu'),'x': testing_points[:,1].to('cpu'),'ts': output_s_np})\n","test_df.to_csv(f'Task_2_Regularizer_{Lambda}_DataReg_{Data_reg}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{pinn.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.txt',index=False) #save to file\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNOtNyXo4TQJ"},"outputs":[],"source":["files.download(f'Task_2_Regularizer_{Lambda}_DataReg_{Data_reg}_hlayers_{Hidden_layers}_N_{Neurons}_FL_{pinn.Final_loss}_Adam_{Adam_opt*n_epochs_A}_LBFGS_{LBFGS_opt*n_epochs_L}.txt')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
